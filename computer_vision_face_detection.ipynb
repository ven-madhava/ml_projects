{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "One shot multiple face detection using deep FCN\n",
    "-----------------------------------------------\n",
    "\n",
    "1. We will use a FCN to directly draw bounding boxes on detected faces\n",
    "2. We are not using cascaded CNN methods for now.\n",
    "3. We are using WIDER dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# -------\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import csv\n",
    "import cv2\n",
    "import h5py\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from scipy.ndimage import label\n",
    "from skimage import measure\n",
    "import shutil\n",
    "import scipy\n",
    "\n",
    "# torch related imports\n",
    "# ---------------------\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import save_image\n",
    "import torch.optim as optim\n",
    "\n",
    "# local settings\n",
    "# --------------\n",
    "import warnings\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "%env JOBLIB_TEMP_FOLDER=/tmp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Format of training labels\n",
    "------------------------\n",
    "\n",
    "Attached the mappings between attribute names and label values.\n",
    "\n",
    "blur:\n",
    "  clear->0\n",
    "  normal blur->1\n",
    "  heavy blur->2\n",
    "\n",
    "expression:\n",
    "  typical expression->0\n",
    "  exaggerate expression->1\n",
    "\n",
    "illumination:\n",
    "  normal illumination->0\n",
    "  extreme illumination->1\n",
    "\n",
    "occlusion:\n",
    "  no occlusion->0\n",
    "  partial occlusion->1\n",
    "  heavy occlusion->2\n",
    "\n",
    "pose:\n",
    "  typical pose->0\n",
    "  atypical pose->1\n",
    "\n",
    "invalid:\n",
    "  false->0(valid image)\n",
    "  true->1(invalid image)\n",
    "\n",
    "The format of txt ground truth.\n",
    "File name\n",
    "Number of bounding box\n",
    "x1, y1, w, h, blur, expression, illumination, invalid, occlusion, pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pool function to create a dataset from input folder\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def create_dataset_from_folder_all(infolder,n_h,n_w):\n",
    "    \n",
    "    # 0. initialisations\n",
    "    # ------------------\n",
    "    image_list = [f for f in listdir(infolder) if isfile(join(infolder, f)) and '.jpg' in f.lower()]\n",
    "    assert len(image_list) > 0, 'No images found in the folder'\n",
    "    xout = np.zeros((len(image_list),n_h,n_w,3), dtype='uint8')\n",
    "    \n",
    "    # 1. building args\n",
    "    # ----------------\n",
    "    all_args = []\n",
    "    for i in range(xout.shape[0]):\n",
    "        all_args.append((i,xout,infolder,image_list,n_h,n_w))\n",
    "    \n",
    "    # 2. calling resize function across multiprocessing pool\n",
    "    # ------------------------------------------------------\n",
    "    pool = ThreadPool(5)\n",
    "    pool.starmap(create_dataset_from_folder_single, all_args)\n",
    "    print('Done creating a dataset with ' + str(xout.shape[0]) + ' images.')\n",
    "    \n",
    "    return xout\n",
    "\n",
    "    \n",
    "# FUNCTION 2\n",
    "# GENERIC FUNCTION - to resize a single image\n",
    "# ------------------------------------------\n",
    "def create_dataset_from_folder_single(i,xout,infolder,image_list,n_h,n_w):\n",
    "    \n",
    "    # snippet\n",
    "    # -------\n",
    "    name = image_list[i]\n",
    "    img = cv2.imread(join(infolder, name))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (n_w,n_h))\n",
    "    xout[i] = img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pool function to resize images\n",
    "# ------------------------------\n",
    "\n",
    "def resize_all(ximgs,n_h,n_w):\n",
    "    \n",
    "    # 0. initialisations\n",
    "    # ------------------\n",
    "    x_images_resized = np.zeros((ximgs.shape[0],new_h,new_w,3), dtype='uint8')\n",
    "    \n",
    "    # 1. building args\n",
    "    # ----------------\n",
    "    all_args = []\n",
    "    for i in range(ximgs.shape[0]):\n",
    "        all_args.append((i,ximgs,x_images_resized,n_h,n_w))\n",
    "    \n",
    "    # 2. calling resize function across multiprocessing pool\n",
    "    # ------------------------------------------------------\n",
    "    pool = ThreadPool(5)\n",
    "    pool.starmap(resize_image_single, all_args)\n",
    "    print('Done resizing ' + str(ximgs.shape[0]) + ' images.')\n",
    "    \n",
    "    return x_images_resized\n",
    "\n",
    "    \n",
    "# FUNCTION 2\n",
    "# GENERIC FUNCTION - to resize a single image\n",
    "# ------------------------------------------\n",
    "def resize_image_single(i,x_in,x_out,new_h,new_w):\n",
    "    \n",
    "    # simple code\n",
    "    # -----------\n",
    "    img = x_in[i]\n",
    "    img = cv2.resize(img, (new_w,new_h))\n",
    "    x_out[i] = img\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLE FUNTION TO CONVERT RGB TO GRAYSCALE\n",
    "# -------------------------------------------\n",
    "def rgb2gray(x):\n",
    "    \n",
    "\n",
    "    x[:,:,:,0] = x[:,:,:,0] * 0.2989\n",
    "    x[:,:,:,1] = x[:,:,:,0] * 0.5870\n",
    "    x[:,:,:,2] = x[:,:,:,0] * 0.1140\n",
    "    xout = np.sum(x,axis = 3)\n",
    "    \n",
    "\n",
    "    #r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    #gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "\n",
    "    return xout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return indices\n",
    "# --------------------------\n",
    "def split_sets(total_len, train_per, val_per):\n",
    "    \n",
    "    # 1. initialisations\n",
    "    # ------------------\n",
    "    trn_size = int(train_per * total_len)\n",
    "    val_size = int(val_per * total_len)\n",
    "    test_size = total_len - trn_size - val_size\n",
    "    assert trn_size + val_size + test_size == total_len\n",
    "\n",
    "    # 2. train set indices\n",
    "    # ---------------------\n",
    "    trn_strt = 0\n",
    "    trn_end = trn_strt + trn_size\n",
    "    \n",
    "    # 3. val set indices\n",
    "    # ------------------\n",
    "    val_strt = trn_end\n",
    "    val_end = val_strt + val_size\n",
    "    \n",
    "    # 4. train set indices\n",
    "    # --------------------\n",
    "    test_strt = val_end\n",
    "    test_end = total_len\n",
    "    \n",
    "    return trn_strt,trn_end,val_strt,val_end,test_strt,test_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function that just returns label dicts\n",
    "# --------------------------------------\n",
    "def create_labels_dict(csv_url,mast_img_url):\n",
    "\n",
    "    # 0. initialisations\n",
    "    # ------------------\n",
    "    d = {}\n",
    "    counter = 0\n",
    "    cats_folders = []\n",
    "    total_images = 0\n",
    "    \n",
    "    # 1. import csv into pd df\n",
    "    # ------------------------\n",
    "    df = pd.read_csv(csv_url)\n",
    "\n",
    "    \n",
    "    # 3. iterting through pd csv and populating output dict\n",
    "    # -----------------------------------------------------\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        # setting curr row value\n",
    "        # ----------------------\n",
    "        curr_row = str(row['label_data'])\n",
    "\n",
    "        # check if this is a new image\n",
    "        # ----------------------------\n",
    "        if '.jpg' in str(curr_row.lower()):\n",
    "\n",
    "            # local counters & flags\n",
    "            # ----------------------\n",
    "            local_img_counter = 0\n",
    "            total_images += 1\n",
    "\n",
    "            # getting curr folder & image name\n",
    "            # --------------------------------\n",
    "            curr_folder_name = curr_row.split('/')[0]\n",
    "            curr_img_name = curr_row.split('/')[1]\n",
    "\n",
    "            # populating image label data\n",
    "            # ---------------------------\n",
    "            try:\n",
    "                d[curr_folder_name][curr_img_name] = {}\n",
    "                d[curr_folder_name][curr_img_name]['path'] = curr_row\n",
    "\n",
    "            except:\n",
    "                d[curr_folder_name] = {}\n",
    "                d[curr_folder_name][curr_img_name] = {}\n",
    "                d[curr_folder_name][curr_img_name]['path'] = curr_row\n",
    "\n",
    "        else:\n",
    "\n",
    "            # checking to see if this the total faces detected counter\n",
    "            # --------------------------------------------------------\n",
    "            if local_img_counter == 0:\n",
    "                d[curr_folder_name][curr_img_name]['total'] = curr_row\n",
    "            else:\n",
    "                try:\n",
    "                    d[curr_folder_name][curr_img_name]['values'].append(curr_row)\n",
    "                except:\n",
    "                    d[curr_folder_name][curr_img_name]['values'] = []\n",
    "                    d[curr_folder_name][curr_img_name]['values'].append(curr_row)\n",
    "\n",
    "            # incrementing counter\n",
    "            # --------------------\n",
    "            local_img_counter += 1\n",
    "    \n",
    "\n",
    "    # final return\n",
    "    # ------------\n",
    "    return d\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multithreading to save images from URL \n",
    "# --------------------------------------\n",
    "# save_images_from_list_pool(img_urls,img_save_mode_in,local_folder,s_h,s_w)\n",
    "\n",
    "def final_bounding_box_dataset_pool(mast_img_url,d,new_h,new_w):\n",
    "    \n",
    "    # 1. initialisations\n",
    "    # ------------------\n",
    "    x_source_img_dict = {}\n",
    "    x_box_img_dict = {}\n",
    "    x_number_faces = {}\n",
    "    \n",
    "    \n",
    "    # 2. setting up input tuple to map function\n",
    "    # -----------------------------------------\n",
    "    all_args = []\n",
    "    for k1 in d.keys():\n",
    "        for k2 in d[k1].keys():\n",
    "            all_args.append((d,k1,k2,new_h,new_w,mast_img_url,x_source_img_dict,x_box_img_dict,x_number_faces))\n",
    "\n",
    "    \n",
    "    # 3. calling map function across multiprocessing pool\n",
    "    # ---------------------------------------------------\n",
    "    #print('>> Calling single pool function now..')\n",
    "    pool = ThreadPool(5) \n",
    "    pool.starmap(final_bounding_box_dataset_pool_single, all_args)\n",
    "    \n",
    "    \n",
    "    # 4. info print\n",
    "    # -------------\n",
    "    print('Done working on ' + str(len(x_source_img_dict.keys())) + ' images.')\n",
    "    \n",
    "    \n",
    "    # 5. converting dict to arrays\n",
    "    # ----------------------------\n",
    "    return x_source_img_dict,x_box_img_dict,x_number_faces\n",
    "    \n",
    "\n",
    "    \n",
    "# pool function - single download and save\n",
    "# ----------------------------------------\n",
    "def final_bounding_box_dataset_pool_single(d_in,k1,k2,new_h,new_w,mast_img_url,xs_dict,xb_dict,x_no_faces):\n",
    "    \n",
    "\n",
    "    # 1. actual ops\n",
    "    # -------------\n",
    "    \n",
    "    # checking condition\n",
    "    # ------------------\n",
    "    if len(d_in[k1][k2]['values']) == int(d_in[k1][k2]['total']):\n",
    "\n",
    "        # 1.1 getting source image\n",
    "        # -----------------------\n",
    "        curr_img_path = mast_img_url + d_in[k1][k2]['path']\n",
    "        curr_img = cv2.imread(curr_img_path)\n",
    "        curr_img = cv2.cvtColor(curr_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "        # 1.2 creating a base image\n",
    "        # ------------------------\n",
    "        curr_y_img = np.ones(curr_img.shape, dtype='uint8') * 255\n",
    "\n",
    "\n",
    "        # 2. plotting bouding boxes - one specific\n",
    "        # ----------------------------------------\n",
    "        for each in d_in[k1][k2]['values']:\n",
    "\n",
    "            # 2.1 list ops\n",
    "            # ------------\n",
    "            lm = each.split(' ')\n",
    "            try:\n",
    "                lm.pop(lm.index(''))\n",
    "            except:\n",
    "                pass\n",
    "            lm = [int(i) for i in lm]\n",
    "\n",
    "            # 2.2 bounding box ops\n",
    "            # --------------------\n",
    "            curr_x_cord = lm[0]\n",
    "            curr_y_cord = lm[1]\n",
    "            curr_wd = lm[2]\n",
    "            curr_ht = lm[3]\n",
    "\n",
    "            # 2.3 setting box\n",
    "            # ---------------\n",
    "            curr_y_img[curr_y_cord:curr_y_cord+curr_ht,curr_x_cord:curr_x_cord+curr_wd,:] = 0\n",
    "\n",
    "\n",
    "\n",
    "        # 1.3 Final resize and concat ops\n",
    "        # -------------------------------\n",
    "        curr_y_img = cv2.resize(curr_y_img, (new_w,new_h))\n",
    "        curr_y_img = curr_y_img.reshape(1,new_h,new_w,3)\n",
    "        xb_dict[k2] = curr_y_img\n",
    "\n",
    "        curr_img = cv2.resize(curr_img, (new_w,new_h))\n",
    "        curr_img = curr_img.reshape(1,new_h,new_w,3)\n",
    "        xs_dict[k2] = curr_img\n",
    "        \n",
    "        # saving number of faces as well\n",
    "        # ------------------------------\n",
    "        x_no_faces[k2] = int(d_in[k1][k2]['total'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create numpy arrays from dicts\n",
    "##\n",
    "\n",
    "def create_source_box_datasets_pool(x_source,x_box,x_number_of_faces):\n",
    "    \n",
    "    \n",
    "    # 0. sanity assetion\n",
    "    # ------------------\n",
    "    assert len(x_source.keys()) == len(x_box.keys()), 'Error - The lengths of keys do not match'\n",
    "    \n",
    "\n",
    "    # 1. initialisations\n",
    "    # ------------------\n",
    "    _,h,w,c = x_source[list(x_source.keys())[0]].shape\n",
    "    m = len(x_source.keys())\n",
    "    xs_out = np.zeros((m,h,w,c), dtype = 'uint8')\n",
    "    xb_out = np.zeros((m,h,w,c), dtype = 'uint8')\n",
    "    xn_out = np.zeros((m))\n",
    "    \n",
    "    \n",
    "    # 2. building args\n",
    "    # ----------------\n",
    "    all_args = []\n",
    "    for i in range(len(x_source.keys())):\n",
    "        all_args.append((i,list(x_source.keys())[i],x_source,xs_out,x_box,xb_out,x_number_of_faces,xn_out))\n",
    "    \n",
    "    \n",
    "    # 2. pool function\n",
    "    # ----------------\n",
    "    pool = ThreadPool(5) \n",
    "    pool.starmap(create_source_box_datasets_single, all_args)\n",
    "    print('Done.')\n",
    "    \n",
    "    \n",
    "    # 3. final return\n",
    "    # ---------------\n",
    "    return xs_out, xb_out, xn_out\n",
    "\n",
    "\n",
    "    \n",
    "# single function\n",
    "# --------------\n",
    "def create_source_box_datasets_single(i,key,xs_dict,xs,xb_dict,xb,xnf_dict,xn_array):\n",
    "    xs[i] = xs_dict[key]\n",
    "    xb[i] = xb_dict[key]\n",
    "    xn_array[i] = xnf_dict[key]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN related code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check accuracy on regression model\n",
    "# ----------------------------------------------\n",
    "\n",
    "def check_regression_accuracy(x_in,model_ae,direct_mode,model_num_face_net,y_target_in,proximity_percent):\n",
    "    \n",
    "    # 0. Some initialisations\n",
    "    # -----------------------\n",
    "    if direct_mode == False:\n",
    "        latent_xin = chunk_pass(x_in,model_ae,True,use_cuda,1)\n",
    "        pred_xin = chunk_pass(latent_xin,model_num_face_net,False,use_cuda,1)\n",
    "        y_out_np = pred_xin.data.cpu().numpy()\n",
    "    else:\n",
    "        pred_xin = chunk_pass(x_in,model_num_face_net,False,use_cuda,1)\n",
    "        y_out_np = pred_xin.data.cpu().numpy()\n",
    "        \n",
    "    y_target_np = y_target_in.reshape(y_out_np.shape)\n",
    "    \n",
    "    # 1. similarity ops\n",
    "    # -----------------\n",
    "    similarity = np.minimum(y_out_np,y_target_np)/np.maximum(y_out_np,y_target_np)\n",
    "    sim_thresheld = (similarity >= proximity_percent).astype('int')\n",
    "    total_got_right = np.sum(sim_thresheld)\n",
    "    avg_distance = np.sum(sim_thresheld*similarity)/total_got_right\n",
    "    percent_got_right = round((total_got_right/x_in.size()[0])*100,2)\n",
    "    \n",
    "    # info print\n",
    "    # ----------\n",
    "    print('The accuracy for given distance threshold is ' + str(percent_got_right) + ' %.')\n",
    "    \n",
    "    # 2. final return\n",
    "    # ---------------\n",
    "    return y_out_np, total_got_right, avg_distance\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple function to generate output from latent\n",
    "# ------------------------------------------------\n",
    "\n",
    "def generate_output(xin,model,start_ind,end_ind,print_images,use_cuda):\n",
    "    \n",
    "    \n",
    "    # 1. generating output\n",
    "    # --------------------\n",
    "    xout = chunk_pass(xin[start_ind:end_ind],model.eval(),False,use_cuda,1)\n",
    "    \n",
    "    # images dataset\n",
    "    # --------------\n",
    "    xout_gen = to_numpy_image(xout.cpu().data)#.astype('uint8')\n",
    "    xout_orig = to_numpy_image(xin[start_ind:end_ind].cpu().data).astype('uint8')\n",
    "        \n",
    " \n",
    "    # 4. priniting images\n",
    "    # -------------------\n",
    "    if print_images == True:\n",
    "        for i in range(xout_orig.shape[0]):\n",
    "            print('Example ' + str(i) + '..')\n",
    "            print('----------------------')\n",
    "            print('Original - ')\n",
    "            plt.figure(figsize=(5,5))\n",
    "            plt.imshow(xout_orig[i])\n",
    "            plt.show()\n",
    "            print('Generated - ')\n",
    "            plt.figure(figsize=(5,5))\n",
    "            plt.imshow(xout_gen[i])\n",
    "            plt.show()\n",
    "            print('\\n----------------\\n')\n",
    "    \n",
    "    # returns\n",
    "    # -------\n",
    "    return xout_orig, xout_gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super helpful chunker function that returns seq chunks correctly sized even at ends\n",
    "# -----------------------------------------------------------------------------------\n",
    "# GENERIC function to calculate conv outsize\n",
    "# ------------------------------------------\n",
    "def outsize_conv(n_H,n_W,f,s,pad):\n",
    "    \n",
    "    h = ((n_H - f + (2*pad))/s) + 1\n",
    "    w = ((n_W - f + (2*pad))/s) + 1\n",
    "    return h,w\n",
    "    \n",
    "    \n",
    "# GENERIC function to calculate upconv outsize\n",
    "# --------------------------------------------    \n",
    "def outsize_upconv(h,w,f,s,p):\n",
    "    hout = (h-1)*s - 2*p + f\n",
    "    wout = (w-1)*s - 2*p + f\n",
    "    return hout, wout\n",
    "\n",
    "\n",
    "\n",
    "def chunker(seq, size):\n",
    "    \n",
    "    # from http://stackoverflow.com/a/434328\n",
    "    # not touch this code\n",
    "    # -------------------\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "\n",
    "\n",
    "# GENERIC - initialises weights for a NN\n",
    "# --------------------------------------\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "    #    print(classname)\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    #elif classname.find('Linear') != -1:\n",
    "    #    print(classname)\n",
    "    #    m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "        \n",
    "        \n",
    "# GENERIC - change an torch image to numoy image\n",
    "# ----------------------------------------------\n",
    "def to_numpy_image(xin):\n",
    "    \n",
    "    try:\n",
    "        xin = xin.data.numpy()\n",
    "    except:\n",
    "        xin = xin.numpy()\n",
    "    \n",
    "    \n",
    "    xout = np.swapaxes(xin,1,2)\n",
    "    xout = np.swapaxes(xout,2,3)\n",
    "    \n",
    "    # returns axes swapped numpy images\n",
    "    # ---------------------------------\n",
    "    return xout       \n",
    "\n",
    "\n",
    "\n",
    "# GENERIC - converts numpy images to torch tensors for training\n",
    "# -------------------------------------------------------------\n",
    "def setup_image_tensor(xin):\n",
    "    xout = np.swapaxes(xin,1,3)\n",
    "    xout = np.swapaxes(xout,2,3)\n",
    "    \n",
    "    # returns axes swapped torch tensor\n",
    "    # ---------------------------------\n",
    "    xout = torch.from_numpy(xout)\n",
    "    return xout.float()\n",
    "\n",
    "\n",
    "# A functino to get linemarkings\n",
    "# -------------------------------\n",
    "\n",
    "def get_ae_output_image(x,net,use_cuda):\n",
    "    \n",
    "    # 0. Setting up input as torch\n",
    "    # ----------------------------\n",
    "    x_t = Variable(setup_image_tensor(x)).float()\n",
    "        \n",
    "        \n",
    "    # 1. Using chunk pass to get linemarkings\n",
    "    # ----------------------------------------\n",
    "    xout = chunk_pass(x_t,net.eval(),False,use_cuda,1)\n",
    "    xout = to_numpy_image(xout.cpu().data)\n",
    "    xout = (xout * 255).astype('uint8')\n",
    "    \n",
    "    # 2. final return\n",
    "    # ---------------\n",
    "    return xout\n",
    "    \n",
    "    \n",
    "# GENERIC class that inherits nn module and makes a sequential object a model\n",
    "# ---------------------------------------------------------------------------\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,sequencelist):\n",
    "        super().__init__() # Initializing nn.Module construtors\n",
    "        self.forwardpass = sequencelist\n",
    "        \n",
    "    def forward(self,x):\n",
    "        xout = self.forwardpass(x)\n",
    "        return xout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build a lineaf FC model\n",
    "# -----------------------------------\n",
    "\n",
    "def linear_fc(layers, nw_activations, target_activation, dropout_p):\n",
    "    \n",
    "    'The first value in the layers list is the input dimensions of the input'\n",
    "    \n",
    "    # 0. initialisations\n",
    "    # ------------------\n",
    "    seq_list = []\n",
    "    \n",
    "    # setting N/W activations\n",
    "    # -------------------\n",
    "    if nw_activations == 'relu':\n",
    "        nw_act = nn.ReLU()\n",
    "    elif nw_activations == 'lrelu':\n",
    "        nw_act = nn.LeakyReLU(0.2)\n",
    "    elif nw_activations == 'sigmoid':\n",
    "        nw_act = nn.Sigmoid()\n",
    "    elif nw_activations == 'tanh':\n",
    "        nw_act = nn.Tanh()\n",
    "    else:\n",
    "        nw_act = nn.ReLU()\n",
    "    \n",
    "    # setting target activations\n",
    "    # --------------------------\n",
    "    if target_activation == 'sigmoid':\n",
    "        target_act = nn.Sigmoid()\n",
    "    elif target_activation == 'softmax':\n",
    "        target_act = nn.Softmax()\n",
    "    else:\n",
    "        target_act = None\n",
    "    \n",
    "    # 1. building n/w's layer list\n",
    "    # ----------------------------\n",
    "    network = []\n",
    "    for k in range(len(layers)):\n",
    "        try:\n",
    "            network.append((layers[k],layers[k+1]))\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "\n",
    "    \n",
    "    # 2. constructing encoder n/w\n",
    "    # ----------------------------\n",
    "    for i in range(len(network)):\n",
    "        \n",
    "        # 2.1 adding linear layers to encoder\n",
    "        # ------------------------------------\n",
    "        curr_dims = network[i]\n",
    "        seq_mod = nn.Linear(curr_dims[0],curr_dims[1])\n",
    "        seq_list.append(seq_mod)\n",
    "        \n",
    "        # checking last layer or not\n",
    "        # --------------------------\n",
    "        if i+1 == len(network):\n",
    "            \n",
    "            # at last layer\n",
    "            # -------------\n",
    "            if target_act == None:\n",
    "                pass\n",
    "            else:\n",
    "                seq_list.append(target_act)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # batchnorm\n",
    "            # ---------\n",
    "            seq_list.append(nn.BatchNorm1d(curr_dims[1]))\n",
    "          \n",
    "            # non linear activation\n",
    "            # ---------------------\n",
    "            seq_list.append(nw_act)\n",
    "            \n",
    "            # dropout\n",
    "            # -------\n",
    "            seq_list.append(nn.Dropout(p = dropout_p))\n",
    "           \n",
    "            \n",
    "    \n",
    "    # 3. returning model\n",
    "    # ------------------\n",
    "    seq_list = nn.Sequential(*seq_list)\n",
    "    seq_list.apply(weights_init)\n",
    "\n",
    "    model = Net(seq_list)\n",
    "    model = model.train()\n",
    "    \n",
    "    return model\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERIC model function to train the networks\n",
    "# --------------------------------------------\n",
    "\n",
    "def model_train(xin,yin,xval,yval,load_mode,model,epochs,mbsize,loss_mode,use_cuda,save_state,path):\n",
    "    \n",
    "    # 0. initialisations\n",
    "    # ------------------\n",
    "    loss_train = []\n",
    "    loss_val = []\n",
    "    norm_flag = 0\n",
    "\n",
    "    \n",
    "\n",
    "    # normalising input to 0-1 while making sure this is an image\n",
    "    # -----------------------------------------------------------\n",
    "    if len(xin.size()) > 3:\n",
    "            \n",
    "        # if the input and output are images - try will go through with the statement\n",
    "        # ----------------------------------------------------------------------------\n",
    "        if len(xin.size()) > 3 and len(yin.size()) > 3:\n",
    "\n",
    "            assert torch.mean(xin).item() > 1 and torch.mean(yin).item() > 1, 'Input data is already in range 0-1. Not consistent with flow.'\n",
    "            \n",
    "\n",
    "            # both need to be normalised\n",
    "            # --------------------------\n",
    "            #xin = xin/255\n",
    "            #yin = yin/255\n",
    "            norm_flag = 1\n",
    "            print('Input and Output dataset will be normalised to 0-1')\n",
    "\n",
    "        \n",
    "        # incase input and output both are NOT images\n",
    "        # -------------------------------------------\n",
    "        else:\n",
    "\n",
    "            assert torch.mean(xin).item() > 1, 'Input data is already in range 0-1. Not consistent with flow.'\n",
    "\n",
    "            # normalising input\n",
    "            # -----------------\n",
    "            #xin = xin/255\n",
    "            norm_flag = 2\n",
    "            print('Input dataset will be normalised to 0-1')\n",
    "            \n",
    "            \n",
    "    \n",
    "    # ensuring xval and yval are None\n",
    "    # -------------------------------\n",
    "    assert xval == None and yval == None, 'xval and yval provided, but there is no code to normalise'\n",
    "    \n",
    "    \n",
    "    if load_mode == 'from saved':\n",
    "        \n",
    "        # loading from saved\n",
    "        # ------------------\n",
    "        model,optimizer,saved_epoch,saved_loss,saved_loss_mode = load_saved_model_function(path,use_cuda)\n",
    "        model = model.train()\n",
    "        loss_mode = saved_loss_mode\n",
    "        print('Loading model from saved state...')\n",
    "        print('Last saved loss - ' + str(saved_loss))\n",
    "        print('Last saved epoch - ' + str(saved_epoch))\n",
    "        epochs += int(saved_epoch)\n",
    "        start_epoch = int(saved_epoch)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # building new\n",
    "        # ------------\n",
    "        start_epoch = 1\n",
    "        model = model.train()\n",
    "        optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad,model.parameters()))\n",
    "        #optimizer = torch.optim.Adadelta(filter(lambda p: p.requires_grad,model.parameters()))\n",
    "        #optimizer = torch.optim.RMSprop(filter(lambda p: p.requires_grad,model.parameters()))\n",
    "        #optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad,model.parameters()), lr=0.1, momentum=0.9)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    # model set up as per cuda\n",
    "    # ------------------------\n",
    "    if use_cuda == True:\n",
    "        torch.cuda.empty_cache()\n",
    "        model = model.cuda()        \n",
    "    \n",
    "    \n",
    "    # setting loss criterion\n",
    "    # ----------------------\n",
    "    if loss_mode == 'MSE':\n",
    "        criterion = nn.MSELoss()\n",
    "    elif loss_mode == 'BCE':\n",
    "        criterion = nn.BCELoss()\n",
    "    elif loss_mode == 'NLL':\n",
    "        criterion = nn.NLLLoss()\n",
    "    elif loss_mode == 'crossentropy':\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        yin = torch.max(yin.long(),1)[1]\n",
    "    else:\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "    \n",
    "    # 1. Setting up minibatch features\n",
    "    # --------------------------------\n",
    "    m = xin.size()[0]\n",
    "    mb_list = []\n",
    "    mb_list = list(range(int(m/mbsize)))\n",
    "    if m % mbsize == 0: # if the minibatches can be split up perfectly.\n",
    "        'do nothing'\n",
    "    else:\n",
    "        mb_list.append(mb_list[len(mb_list)-1] + 1)\n",
    "        \n",
    "    # 2. Actual iters\n",
    "    # ----------------\n",
    "    for i in range(start_epoch,epochs+1):\n",
    "            \n",
    "        for p in mb_list:\n",
    "            \n",
    "            # Mini batch operations\n",
    "            # ---------------------\n",
    "            start_index = p*mbsize\n",
    "            end_index = m if p == mb_list[len(mb_list)-1] else p*mbsize + mbsize\n",
    "            m_curr = end_index - start_index\n",
    "            \n",
    "            Xin_mb = xin[start_index:end_index]\n",
    "            Yin_mb = yin[start_index:end_index]\n",
    "            \n",
    "            if use_cuda == True:\n",
    "                Xin_mb = Xin_mb.cuda()\n",
    "                Yin_mb = Yin_mb.cuda()\n",
    "                \n",
    "            # normalising ops\n",
    "            # --------------\n",
    "            if norm_flag == 1:\n",
    "                \n",
    "                # normalise both input and target\n",
    "                # -------------------------------\n",
    "                Xin_mb = copy.deepcopy(Xin_mb)/255\n",
    "                Yin_mb = copy.deepcopy(Yin_mb)/255\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                # normalise only input\n",
    "                # --------------------\n",
    "                Xin_mb = copy.deepcopy(Xin_mb)/255\n",
    "                \n",
    "                \n",
    "            # Network ops\n",
    "            # -----------\n",
    "            model_out = model(Xin_mb)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model_out, Yin_mb) # loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train.append(loss.item())\n",
    "            \n",
    "            # deleting curr variables\n",
    "            # -----------------------\n",
    "            if use_cuda == True:\n",
    "                Xin_mb = Xin_mb.cpu()\n",
    "                Yin_mb = Yin_mb.cpu()\n",
    "                model_out = model_out.cpu()\n",
    "                \n",
    "                del Xin_mb\n",
    "                del Yin_mb\n",
    "                del model_out\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            # printing loss\n",
    "            # -------------\n",
    "            print('Epoch ' + str(i) + ', minibatch ' + str(p+1) + ' of '  +  str(len(mb_list)) + ' -- Model loss: ' + str(loss.item()))\n",
    "            \n",
    "\n",
    "    # 3. outside for loop saving model state\n",
    "    # --------------------------------------\n",
    "    if save_state == True and epochs+1 > start_epoch:\n",
    "        \n",
    "        # 3.1 initialising save dict\n",
    "        # --------------------------\n",
    "        save_dict = {}\n",
    "        save_dict['epoch'] = str(i)\n",
    "        save_dict['model_state_dict'] = model.cpu().state_dict()\n",
    "        save_dict['optimizer_state_dict'] = optimizer.state_dict()\n",
    "        save_dict['loss'] = str(loss.cpu().item())\n",
    "        save_dict['loss_mode'] = loss_mode\n",
    "        \n",
    "        \n",
    "        # 3.2 saving\n",
    "        # ----------\n",
    "        torch.save(save_dict,path)\n",
    "        \n",
    "        # saving full model to initialise a new model later on\n",
    "        # ----------------------------------------------------\n",
    "        torch.save(model.cpu(),path.replace('.tar','_MODEL.tar'))\n",
    "        \n",
    "        print('Saved.')\n",
    "        \n",
    "    \n",
    "    # 4. return model in order to use elsewhere in the code\n",
    "    # -----------------------------------------------------\n",
    "    return model\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to load a saved model\n",
    "# --------------------------------\n",
    "\n",
    "def load_saved_model_function(path, use_cuda):\n",
    "    \n",
    "    \n",
    "    ''' path = /folder1/folder2/model_ae.tar format'''\n",
    "    \n",
    "    # 1. loading full model\n",
    "    # ---------------------\n",
    "    model = torch.load(path.replace('.tar','_MODEL.tar'))\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad,model.parameters()))\n",
    "    \n",
    "    # 2. Applying state dict\n",
    "    # ----------------------\n",
    "    if use_cuda == True:\n",
    "        \n",
    "        # loads to GPU\n",
    "        # ------------\n",
    "        checkpoint = torch.load(path)\n",
    "        \n",
    "    else:\n",
    "        # loads to CPU\n",
    "        # ------------\n",
    "        checkpoint = torch.load(path, map_location=lambda storage, loc: storage)\n",
    "        \n",
    "        \n",
    "    # loading checkpoint\n",
    "    # -------------------\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # loading optimizer\n",
    "    # -----------------\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    if use_cuda == True:\n",
    "        for state in optimizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    state[k] = v.cuda()\n",
    "            \n",
    "            \n",
    "            \n",
    "    # loading other stuff\n",
    "    # -------------------\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    loss_mode = checkpoint['loss_mode']\n",
    "    \n",
    "    return model, optimizer, epoch, loss, loss_mode\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function to do a forward pass by chunks\n",
    "# ----------------------------------------------\n",
    "\n",
    "def chunk_pass(xin,model,latent,use_cuda,chunksize):\n",
    "    \n",
    "    # 0. some initialisations\n",
    "    # -----------------------\n",
    "    model = model.eval()\n",
    "    if use_cuda == True:\n",
    "        torch.cuda.empty_cache()\n",
    "        model = model.cuda()\n",
    "        \n",
    "    \n",
    "    # sanity assertion\n",
    "    # ----------------\n",
    "    if len(xin.size()) > 3:\n",
    "        \n",
    "        # normalising data\n",
    "        # ----------------\n",
    "        assert torch.mean(xin).data[0] > 1, 'Input data is already in range 0-1. Not consistent with flow.'\n",
    "        xin = xin/255\n",
    "        print(\"Normalised data to 0-1\")\n",
    "       \n",
    "        \n",
    "\n",
    "        \n",
    "    # 1. chuck loop\n",
    "    # -------------\n",
    "    with tqdm(total=xin.size()[0]) as pbar:\n",
    "        for i,chunk_data in enumerate(chunker(xin, chunksize)):\n",
    "            \n",
    "            # forward pass ops\n",
    "            # ----------------\n",
    "            try:\n",
    "                chunk_data = Variable(chunk_data.data, volatile=True)\n",
    "            except:\n",
    "                chunk_data = Variable(chunk_data, volatile=True)\n",
    "                \n",
    "            if use_cuda == True:\n",
    "                \n",
    "                torch.cuda.empty_cache()\n",
    "               \n",
    "                if latent == True:\n",
    "                    try:\n",
    "                        curr_forwardpass = model.latent(chunk_data.cuda().detach())\n",
    "                    except:\n",
    "                        curr_forwardpass = model.latent(chunk_data.cuda())\n",
    "                else:\n",
    "                    try:\n",
    "                        curr_forwardpass = model(chunk_data.cuda().detach())\n",
    "                    except:\n",
    "                        curr_forwardpass = model(chunk_data.cuda())\n",
    "            else:\n",
    "                \n",
    "                if latent == True:\n",
    "                    try:\n",
    "                        curr_forwardpass = model.latent(chunk_data.cpu().detach())\n",
    "                    except:\n",
    "                        curr_forwardpass = model.latent(chunk_data.cpu())\n",
    "                else:\n",
    "                    try:\n",
    "                        curr_forwardpass = model(chunk_data.cpu().detach())\n",
    "                    except:\n",
    "                        curr_forwardpass = model(chunk_data.cpu())\n",
    "                \n",
    "            # concat ops\n",
    "            # ----------\n",
    "            try:\n",
    "                xout = torch.cat((xout,curr_forwardpass), 0)\n",
    "            except:\n",
    "                xout= curr_forwardpass\n",
    "                \n",
    "            # for memory purpose\n",
    "            # ------------------\n",
    "            if use_cuda == True:\n",
    "                curr_forwardpass = curr_forwardpass.cpu()\n",
    "                chunk_data = chunk_data.cpu()\n",
    "                del curr_forwardpass\n",
    "                del chunk_data\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            pbar.update(chunksize)\n",
    "        \n",
    "    # 2. return\n",
    "    # ---------\n",
    "    xout = Variable(xout.data, volatile=False).cpu()\n",
    "    \n",
    "\n",
    "    return xout\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCN class copied from image search notebook which worked\n",
    "# --------------------------------------------------------\n",
    "\n",
    "class fcn_ae_4_layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initialising N/W here\n",
    "        # ---------------------\n",
    "        nw_activation_conv = nn.ReLU() #nn.LeakyReLU(0.2) # nn.Tanh() nn.Softmax2d()\n",
    "        f = 3\n",
    "        s = 2\n",
    "        added_act = nn.Tanh()\n",
    "        dropout_prob = 0.1\n",
    "        dropout_node = nn.Dropout2d(p=dropout_prob)\n",
    "        \n",
    "        #  what worked - 3,64,128,256,128,64,3\n",
    "        \n",
    "        # Conv 1\n",
    "        ###\n",
    "        conv1 = 32\n",
    "        ct1 = nn.Conv2d(3,conv1,f,stride = s)\n",
    "        cb1 = nn.BatchNorm2d(conv1)\n",
    "        ca1 = nw_activation_conv\n",
    "        cl1 = [ct1,cb1,ca1,dropout_node]\n",
    "        self.convl1 = nn.Sequential(*cl1)\n",
    "        \n",
    "        # Conv 2\n",
    "        ###\n",
    "        conv2 = 64\n",
    "        ct2 = nn.Conv2d(conv1,conv2,f,stride = s)\n",
    "        cb2 = nn.BatchNorm2d(conv2)\n",
    "        ca2 = nw_activation_conv\n",
    "        cl2 = [ct2,cb2,ca2,dropout_node]\n",
    "        self.convl2 = nn.Sequential(*cl2)\n",
    "        \n",
    "        # Conv 3\n",
    "        ###\n",
    "        conv3 = 128\n",
    "        ct3 = nn.Conv2d(conv2,conv3,f,stride = s)\n",
    "        cb3 = nn.BatchNorm2d(conv3)\n",
    "        ca3 = nn.Softmax2d() #nw_activation_conv\n",
    "        cl3 = [ct3,ca3,dropout_node]\n",
    "        self.convl3 = nn.Sequential(*cl3)\n",
    "        \n",
    "        # Conv 4\n",
    "        ###\n",
    "        #conv4 = 256\n",
    "        #ct4 = nn.Conv2d(conv3,conv4,f,stride = s)\n",
    "        #cb4 = nn.BatchNorm2d(conv4)\n",
    "        #ca4 = nn.Softmax2d() #nw_activation_conv\n",
    "        #cl4 = [ct4,ca4,dropout_node]\n",
    "        #self.convl4 = nn.Sequential(*cl4) # size 6 x 4\n",
    "        \n",
    "        \n",
    "        # Pooling layer\n",
    "        mxpl =  [nn.MaxPool2d((3,3), stride=3)]\n",
    "        #avpl =  [nn.AvgPool2d((6,4), stride=1)]\n",
    "        self.pool_net = nn.Sequential(*mxpl)\n",
    "        \n",
    "        # Adding a fully connected linear layer\n",
    "        #\n",
    "        \n",
    "        # Upconv layer 0\n",
    "        ###\n",
    "        #t0 = nn.ConvTranspose2d(conv4,conv4,2,stride = 2)\n",
    "        #b0 = nn.BatchNorm2d(conv4)\n",
    "        #a0 = nw_activation_conv\n",
    "        #l0 = [t0,b0,a0]\n",
    "        #self.upcl0 = nn.Sequential(*l0)\n",
    "        \n",
    "        # Upconv layer 1\n",
    "        ###\n",
    "        up_conv1 = 128\n",
    "        t1 = nn.ConvTranspose2d(conv3,up_conv1,3,stride = 3)\n",
    "        b1 = nn.BatchNorm2d(up_conv1)\n",
    "        a1 = nw_activation_conv\n",
    "        l1 = [t1,b1,a1,dropout_node]\n",
    "        self.upcl1 = nn.Sequential(*l1)\n",
    "        \n",
    "        # Upconv layer 2\n",
    "        ###\n",
    "        up_conv2 = 64\n",
    "        t2 = nn.ConvTranspose2d(up_conv1,up_conv2,f,stride = s)\n",
    "        b2 = nn.BatchNorm2d(up_conv2)\n",
    "        a2 = nw_activation_conv\n",
    "        l2 = [t2,b2,a2,dropout_node]\n",
    "        self.upcl2 = nn.Sequential(*l2)\n",
    "        \n",
    "        # Upconv layer 3\n",
    "        ###\n",
    "        up_conv3 = 32\n",
    "        t3 = nn.ConvTranspose2d(up_conv2,up_conv3,f,stride = s)\n",
    "        b3 = nn.BatchNorm2d(up_conv3)\n",
    "        a3 = nw_activation_conv\n",
    "        l3 = [t3,b3,a3,dropout_node]\n",
    "        self.upcl3 = nn.Sequential(*l3)\n",
    "        \n",
    "        # Upconv layer 4\n",
    "        ###\n",
    "        t4 = nn.ConvTranspose2d(up_conv3,3,f,stride = s)\n",
    "        a4 = nn.Sigmoid()\n",
    "        l4 = [t4,a4]\n",
    "        self.upcl4 = nn.Sequential(*l4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Generation\n",
    "        # ----------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        #c4_out = self.convl4(c3_out)\n",
    "        c5_out = self.pool_net(c3_out)\n",
    "        \n",
    "        #f1_out = self.upcl0(c5_out)\n",
    "        f2_out = self.upcl1(c5_out)\n",
    "        f3_out = self.upcl2(f2_out)\n",
    "        f4_out = self.upcl3(f3_out)\n",
    "        f5_out = self.upcl4(f4_out)\n",
    "        \n",
    "        return f5_out\n",
    "\n",
    "    \n",
    "    def latent(self, x):\n",
    "        \n",
    "        \n",
    "        # 0. forward prop\n",
    "        # ---------------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        \n",
    "\n",
    "        # 1. Working out layer number\n",
    "        # ---------------------------\n",
    "        if self.layer_mode == 'deep':\n",
    "            forward_out = self.convl4(c3_out)\n",
    "        \n",
    "        elif self.layer_mode == 'deep_minus_2':\n",
    "            forward_out = c2_out\n",
    "        \n",
    "        else:\n",
    "            forward_out = c3_out\n",
    "\n",
    "\n",
    "        # 2. Including a pool layer - setting dims\n",
    "        # ----------------------------------------\n",
    "        if self.layer_dims_set == True:\n",
    "            \n",
    "            ih, iw, pool_stride = self.layer_f, self.layer_f, self.layer_s\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            ih,iw = forward_out.size()[2],forward_out.size()[3]\n",
    "            pool_stride = 1\n",
    "        \n",
    "        if self.pool_mode == 'avg':\n",
    "\n",
    "            # avg pool - comment/uncomment\n",
    "            # ----------------------------\n",
    "            avpl =  nn.Sequential(*[nn.AvgPool2d((ih,iw), stride=pool_stride)])\n",
    "            latent_out = avpl(forward_out)\n",
    "        \n",
    "        elif self.pool_mode == 'max':\n",
    "            \n",
    "            # maxpool - comment/uncomment\n",
    "            # ---------------------------\n",
    "            mxpl =  nn.Sequential(*[nn.MaxPool2d((ih,iw), stride=pool_stride)])\n",
    "            latent_out = mxpl(forward_out)\n",
    "            \n",
    "        elif self.pool_mode == 'both':\n",
    "            \n",
    "            # avg pool\n",
    "            # --------\n",
    "            avpl =  nn.Sequential(*[nn.AvgPool2d((ih,iw), stride=pool_stride)])\n",
    "            latent_out_avg = avpl(forward_out)\n",
    "            latent_out_avg = latent_out_avg.view(latent_out_avg.size()[0],-1)\n",
    "            \n",
    "            # maxpool\n",
    "            # -------\n",
    "            mxpl =  nn.Sequential(*[nn.MaxPool2d((ih,iw), stride=pool_stride)])\n",
    "            latent_out_max = mxpl(forward_out)\n",
    "            latent_out_max = latent_out_max.view(latent_out_max.size()[0],-1)\n",
    "            \n",
    "            # final concat\n",
    "            # ------------\n",
    "            latent_out = torch.cat((latent_out_avg, latent_out_max), 1)\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # no pooling\n",
    "            # ----------\n",
    "            latent_out = forward_out\n",
    "            \n",
    "        \n",
    "        return latent_out.view(latent_out.size()[0],-1)\n",
    "        \n",
    "    \n",
    "     \n",
    "    def set_pool_mode(self, pool_mode, layer_mode, layer_dims_set, layer_f, layer_s):\n",
    "        \n",
    "        # setting pool mode\n",
    "        # -----------------\n",
    "        self.pool_mode = pool_mode\n",
    "        self.layer_mode = layer_mode\n",
    "        self.layer_dims_set = layer_dims_set\n",
    "        self.layer_f = layer_f\n",
    "        self.layer_s = layer_s\n",
    "        \n",
    "        print('Modes set.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCN class copied from image search notebook which worked\n",
    "# --------------------------------------------------------\n",
    "\n",
    "class fcn_ae_3_layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initialising N/W here\n",
    "        # ---------------------\n",
    "        nw_activation_conv = nn.ReLU() #nn.LeakyReLU(0.2) # nn.Tanh() nn.Softmax2d()\n",
    "        f = 3\n",
    "        s = 2\n",
    "        added_act = nn.Tanh()\n",
    "        dropout_prob = 0.1\n",
    "        dropout_node = nn.Dropout2d(p=dropout_prob)\n",
    "        \n",
    "        #  what worked - 3,64,128,256,128,64,3\n",
    "        \n",
    "        # Conv 1\n",
    "        ###\n",
    "        conv1 = 64\n",
    "        ct1 = nn.Conv2d(3,conv1,f,stride = s)\n",
    "        cb1 = nn.BatchNorm2d(conv1)\n",
    "        ca1 = nw_activation_conv\n",
    "        cl1 = [ct1,cb1,ca1,dropout_node]\n",
    "        self.convl1 = nn.Sequential(*cl1)\n",
    "        \n",
    "        # Conv 2\n",
    "        ###\n",
    "        conv2 = 128\n",
    "        ct2 = nn.Conv2d(conv1,conv2,f,stride = s)\n",
    "        cb2 = nn.BatchNorm2d(conv2)\n",
    "        ca2 = nw_activation_conv\n",
    "        cl2 = [ct2,cb2,ca2,dropout_node]\n",
    "        self.convl2 = nn.Sequential(*cl2)\n",
    "        \n",
    "        # Conv 3\n",
    "        ###\n",
    "        conv3 = 256\n",
    "        ct3 = nn.Conv2d(conv2,conv3,f,stride = s)\n",
    "        cb3 = nn.BatchNorm2d(conv3)\n",
    "        ca3 = nn.Softmax2d() #nn.Softmax2d() #nw_activation_conv\n",
    "        cl3 = [ct3,ca3,dropout_node]\n",
    "        self.convl3 = nn.Sequential(*cl3)\n",
    "        \n",
    "        # Conv 4\n",
    "        ###\n",
    "        #conv4 = 256\n",
    "        #ct4 = nn.Conv2d(conv3,conv4,f,stride = s)\n",
    "        #cb4 = nn.BatchNorm2d(conv4)\n",
    "        #ca4 = nn.Softmax2d() #nw_activation_conv\n",
    "        #cl4 = [ct4,ca4,dropout_node]\n",
    "        #self.convl4 = nn.Sequential(*cl4) # size 6 x 4\n",
    "        \n",
    "        \n",
    "        # Pooling layer\n",
    "        #mxpl =  [nn.MaxPool2d((2,2), stride=2)]\n",
    "        #avpl =  [nn.AvgPool2d((6,4), stride=1)]\n",
    "        #self.pool_net = nn.Sequential(*mxpl)\n",
    "        \n",
    "        # Adding a fully connected linear layer\n",
    "        #\n",
    "        \n",
    "        # Upconv layer 0\n",
    "        ###\n",
    "        #t0 = nn.ConvTranspose2d(conv4,conv4,2,stride = 2)\n",
    "        #b0 = nn.BatchNorm2d(conv4)\n",
    "        #a0 = nw_activation_conv\n",
    "        #l0 = [t0,b0,a0]\n",
    "        #self.upcl0 = nn.Sequential(*l0)\n",
    "        \n",
    "        # Upconv layer 1\n",
    "        ###\n",
    "        #up_conv1 = 128\n",
    "        #t1 = nn.ConvTranspose2d(conv4,up_conv1,f,stride = s)\n",
    "        #b1 = nn.BatchNorm2d(up_conv1)\n",
    "        #a1 = nw_activation_conv\n",
    "        #l1 = [t1,b1,a1,dropout_node]\n",
    "        #self.upcl1 = nn.Sequential(*l1)\n",
    "        \n",
    "        # Upconv layer 2\n",
    "        ###\n",
    "        up_conv2 = 128\n",
    "        t2 = nn.ConvTranspose2d(conv3,up_conv2,f,stride = s)\n",
    "        b2 = nn.BatchNorm2d(up_conv2)\n",
    "        a2 = nw_activation_conv\n",
    "        l2 = [t2,b2,a2,dropout_node]\n",
    "        self.upcl2 = nn.Sequential(*l2)\n",
    "        \n",
    "        # Upconv layer 3\n",
    "        ###\n",
    "        up_conv3 = 64\n",
    "        t3 = nn.ConvTranspose2d(up_conv2,up_conv3,f,stride = s)\n",
    "        b3 = nn.BatchNorm2d(up_conv3)\n",
    "        a3 = nw_activation_conv\n",
    "        l3 = [t3,b3,a3,dropout_node]\n",
    "        self.upcl3 = nn.Sequential(*l3)\n",
    "        \n",
    "        # Upconv layer 4\n",
    "        ###\n",
    "        t4 = nn.ConvTranspose2d(up_conv3,3,f,stride = s)\n",
    "        a4 = nn.Sigmoid()\n",
    "        l4 = [t4,a4]\n",
    "        self.upcl4 = nn.Sequential(*l4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Generation\n",
    "        # ----------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        #c4_out = self.convl4(c3_out)\n",
    "        #c5_out = self.pool_net(c3_out)\n",
    "        \n",
    "        #f1_out = self.upcl0(c5_out)\n",
    "        #f2_out = self.upcl1(c4_out)\n",
    "        f3_out = self.upcl2(c3_out)\n",
    "        f4_out = self.upcl3(f3_out)\n",
    "        f5_out = self.upcl4(f4_out)\n",
    "        \n",
    "        return f5_out\n",
    "\n",
    "    \n",
    "    def latent(self, x):\n",
    "        \n",
    "        \n",
    "        # 0. forward prop\n",
    "        # ---------------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        \n",
    "        # 1. Working out layer number\n",
    "        # ---------------------------\n",
    "        if self.layer_mode == 'deep_minus_1':\n",
    "            forward_out = c2_out\n",
    "        \n",
    "        else:\n",
    "            forward_out = self.convl3(c2_out)\n",
    "        \n",
    "\n",
    "        # 2. Including a pool layer - setting dims\n",
    "        # ----------------------------------------\n",
    "        if self.layer_dims_set == True:\n",
    "            \n",
    "            ih, iw, pool_stride = self.layer_f, self.layer_f, self.layer_s\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            ih,iw = forward_out.size()[2],forward_out.size()[3]\n",
    "            pool_stride = 1\n",
    "        \n",
    "        if self.pool_mode == 'avg':\n",
    "\n",
    "            # avg pool - comment/uncomment\n",
    "            # ----------------------------\n",
    "            avpl =  nn.Sequential(*[nn.AvgPool2d((ih,iw), stride=pool_stride)])\n",
    "            latent_out = avpl(forward_out)\n",
    "        \n",
    "        elif self.pool_mode == 'max':\n",
    "            \n",
    "            # maxpool - comment/uncomment\n",
    "            # ---------------------------\n",
    "            mxpl =  nn.Sequential(*[nn.MaxPool2d((ih,iw), stride=pool_stride)])\n",
    "            latent_out = mxpl(forward_out)\n",
    "            \n",
    "        elif self.pool_mode == 'both':\n",
    "            \n",
    "            # avg pool\n",
    "            # --------\n",
    "            avpl =  nn.Sequential(*[nn.AvgPool2d((ih,iw), stride=pool_stride)])\n",
    "            latent_out_avg = avpl(forward_out)\n",
    "            latent_out_avg = latent_out_avg.view(latent_out_avg.size()[0],-1)\n",
    "            \n",
    "            # maxpool\n",
    "            # -------\n",
    "            mxpl =  nn.Sequential(*[nn.MaxPool2d((ih,iw), stride=pool_stride)])\n",
    "            latent_out_max = mxpl(forward_out)\n",
    "            latent_out_max = latent_out_max.view(latent_out_max.size()[0],-1)\n",
    "            \n",
    "            # final concat\n",
    "            # ------------\n",
    "            latent_out = torch.cat((latent_out_avg, latent_out_max), 1)\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # no pooling\n",
    "            # ----------\n",
    "            latent_out = forward_out\n",
    "            \n",
    "        \n",
    "        return latent_out.view(latent_out.size()[0],-1)\n",
    "        \n",
    "    \n",
    "     \n",
    "    def set_pool_mode(self, pool_mode, layer_mode, layer_dims_set, layer_f, layer_s):\n",
    "        \n",
    "        # setting pool mode\n",
    "        # -----------------\n",
    "        self.pool_mode = pool_mode\n",
    "        self.layer_mode = layer_mode\n",
    "        self.layer_dims_set = layer_dims_set\n",
    "        self.layer_f = layer_f\n",
    "        self.layer_s = layer_s\n",
    "        \n",
    "        print('Modes set.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCN class copied from image search notebook which worked\n",
    "# --------------------------------------------------------\n",
    "\n",
    "class fcn_ae_deep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initialising N/W here\n",
    "        # ---------------------\n",
    "        nw_activation_conv = nn.ReLU() #nn.LeakyReLU(0.2) # nn.Tanh() nn.Softmax2d()\n",
    "        f = 3\n",
    "        s = 2\n",
    "        added_act = nn.Tanh()\n",
    "        dropout_prob = 0.2\n",
    "        dropout_node = nn.Dropout2d(p=dropout_prob)\n",
    "        \n",
    "        #  what worked - 3,64,128,256,128,64,3\n",
    "        \n",
    "        # Conv 1\n",
    "        ###\n",
    "        conv1 = 32\n",
    "        ct1 = nn.Conv2d(3,conv1,f,stride = s)\n",
    "        cb1 = nn.BatchNorm2d(conv1)\n",
    "        ca1 = nw_activation_conv\n",
    "        cl1 = [ct1,cb1,ca1,dropout_node]\n",
    "        self.convl1 = nn.Sequential(*cl1)\n",
    "        \n",
    "        # Conv 2\n",
    "        ###\n",
    "        conv2 = 64\n",
    "        ct2 = nn.Conv2d(conv1,conv2,f,stride = s)\n",
    "        cb2 = nn.BatchNorm2d(conv2)\n",
    "        ca2 = nw_activation_conv\n",
    "        cl2 = [ct2,cb2,ca2,dropout_node]\n",
    "        self.convl2 = nn.Sequential(*cl2)\n",
    "        \n",
    "        # Conv 3\n",
    "        ###\n",
    "        conv3 = 128\n",
    "        ct3 = nn.Conv2d(conv2,conv3,f,stride = s)\n",
    "        cb3 = nn.BatchNorm2d(conv3)\n",
    "        ca3 = nw_activation_conv #nw_activation_conv\n",
    "        cl3 = [ct3,cb3,ca3,dropout_node]\n",
    "        self.convl3 = nn.Sequential(*cl3)\n",
    "        \n",
    "        # Conv 4\n",
    "        ###\n",
    "        conv4 = 256\n",
    "        ct4 = nn.Conv2d(conv3,conv4,f,stride = s)\n",
    "        cb4 = nn.BatchNorm2d(conv4)\n",
    "        ca4 = nw_activation_conv\n",
    "        cl4 = [ct4,cb4,ca4,dropout_node]\n",
    "        self.convl4 = nn.Sequential(*cl4) \n",
    "        \n",
    "        # Conv 5\n",
    "        ###\n",
    "        conv5 = 512\n",
    "        ct5 = nn.Conv2d(conv4,conv5,f,stride = s)\n",
    "        cb5 = nn.BatchNorm2d(conv5)\n",
    "        ca5 = nn.Softmax2d()\n",
    "        cl5 = [ct5,cb5,ca5,dropout_node]\n",
    "        self.convl5 = nn.Sequential(*cl5) \n",
    "        \n",
    "        \n",
    "        # Pooling layer\n",
    "        #mxpl =  [nn.MaxPool2d((2,2), stride=2)]\n",
    "        #avpl =  [nn.AvgPool2d((6,4), stride=1)]\n",
    "        #self.pool_net = nn.Sequential(*mxpl)\n",
    "        \n",
    "        # Adding a fully connected linear layer\n",
    "        #\n",
    "        \n",
    "        # Upconv layer 0\n",
    "        ###\n",
    "        up_conv0 = 256\n",
    "        t0 = nn.ConvTranspose2d(conv5,up_conv0,f,stride = s)\n",
    "        b0 = nn.BatchNorm2d(up_conv0)\n",
    "        a0 = nw_activation_conv\n",
    "        l0 = [t0,b0,a0,dropout_node]\n",
    "        self.upcl0 = nn.Sequential(*l0)\n",
    "        \n",
    "        # Upconv layer 1\n",
    "        ###\n",
    "        up_conv1 = 128\n",
    "        t1 = nn.ConvTranspose2d(up_conv0,up_conv1,f,stride = s)\n",
    "        b1 = nn.BatchNorm2d(up_conv1)\n",
    "        a1 = nw_activation_conv\n",
    "        l1 = [t1,b1,a1,dropout_node]\n",
    "        self.upcl1 = nn.Sequential(*l1)\n",
    "        \n",
    "        # Upconv layer 2\n",
    "        ###\n",
    "        up_conv2 = 64\n",
    "        t2 = nn.ConvTranspose2d(up_conv1,up_conv2,f,stride = s)\n",
    "        b2 = nn.BatchNorm2d(up_conv2)\n",
    "        a2 = nw_activation_conv\n",
    "        l2 = [t2,b2,a2,dropout_node]\n",
    "        self.upcl2 = nn.Sequential(*l2)\n",
    "        \n",
    "        # Upconv layer 3\n",
    "        ###\n",
    "        up_conv3 = 32\n",
    "        t3 = nn.ConvTranspose2d(up_conv2,up_conv3,f,stride = s)\n",
    "        b3 = nn.BatchNorm2d(up_conv3)\n",
    "        a3 = nw_activation_conv\n",
    "        l3 = [t3,b3,a3,dropout_node]\n",
    "        self.upcl3 = nn.Sequential(*l3)\n",
    "        \n",
    "        # Upconv layer 4\n",
    "        ###\n",
    "        t4 = nn.ConvTranspose2d(up_conv3,3,f,stride = s)\n",
    "        a4 = nn.Sigmoid()\n",
    "        l4 = [t4,a4]\n",
    "        self.upcl4 = nn.Sequential(*l4)\n",
    "        \n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "        # forward pass\n",
    "        # ------------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        c4_out = self.convl4(c3_out)\n",
    "        c5_out = self.convl5(c4_out)\n",
    "        \n",
    "        f1_out = self.upcl0(c5_out)\n",
    "        f2_out = self.upcl1(f1_out)\n",
    "        f3_out = self.upcl2(f2_out)\n",
    "        f4_out = self.upcl3(f3_out)\n",
    "        f5_out = self.upcl4(f4_out)\n",
    "        \n",
    "        return f5_out\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def latent(self, x):\n",
    "        \n",
    "        \n",
    "        # 0. forward prop\n",
    "        # ---------------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        c4_out = self.convl4(c3_out)\n",
    "\n",
    "        # 1. Working out layer number\n",
    "        # ---------------------------\n",
    "        if self.layer_mode == 'deep':\n",
    "            forward_out = self.convl5(c4_out)\n",
    "        \n",
    "        elif self.layer_mode == 'deep_minus_2':\n",
    "            forward_out = c3_out\n",
    "        \n",
    "        else:\n",
    "            forward_out = c4_out\n",
    "\n",
    "\n",
    "        # 2. Including a pool layer \n",
    "        # -------------------------\n",
    "        ih,iw = forward_out.size()[2],forward_out.size()[3]\n",
    "        \n",
    "        if self.pool_mode == 'avg':\n",
    "\n",
    "            # avg pool - comment/uncomment\n",
    "            # ----------------------------\n",
    "            avpl =  nn.Sequential(*[nn.AvgPool2d((ih,iw), stride=1)])\n",
    "            latent_out = avpl(forward_out)\n",
    "        \n",
    "        elif self.pool_mode == 'max':\n",
    "            \n",
    "            # maxpool - comment/uncomment\n",
    "            # ---------------------------\n",
    "            mxpl =  nn.Sequential(*[nn.MaxPool2d((ih,iw), stride=1)])\n",
    "            latent_out = mxpl(forward_out)\n",
    "            \n",
    "        elif self.pool_mode == 'both':\n",
    "            \n",
    "            # avg pool\n",
    "            # --------\n",
    "            avpl =  nn.Sequential(*[nn.AvgPool2d((ih,iw), stride=1)])\n",
    "            latent_out_avg = avpl(forward_out)\n",
    "            latent_out_avg = latent_out_avg.view(latent_out_avg.size()[0],-1)\n",
    "            \n",
    "            # maxpool\n",
    "            # -------\n",
    "            mxpl =  nn.Sequential(*[nn.MaxPool2d((ih,iw), stride=1)])\n",
    "            latent_out_max = mxpl(forward_out)\n",
    "            latent_out_max = latent_out_max.view(latent_out_max.size()[0],-1)\n",
    "            \n",
    "            # final concat\n",
    "            # ------------\n",
    "            latent_out = torch.cat((latent_out_avg, latent_out_max), 1)\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # no pooling\n",
    "            # ----------\n",
    "            latent_out = forward_out\n",
    "            \n",
    "        \n",
    "        return latent_out.view(latent_out.size()[0],-1)\n",
    "        \n",
    "    \n",
    "     \n",
    "    def set_pool_mode(self, pool_mode, layer_mode):\n",
    "        \n",
    "        # setting pool mode\n",
    "        # -----------------\n",
    "        self.pool_mode = pool_mode\n",
    "        self.layer_mode = layer_mode\n",
    "        print('Modes set.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCN class copied from image search notebook which worked\n",
    "# --------------------------------------------------------\n",
    "\n",
    "class fcn_ae_6_layer_WNET(nn.Module):\n",
    "    def __init__(self, in_channels, latent_softmax):\n",
    "        super().__init__()\n",
    "        \n",
    "        # This is WNET model\n",
    "        # ------------------\n",
    "        \n",
    "        # Showing conv up sizes - \n",
    "        # --------------------------\n",
    "        # (191,191) -- Insize\n",
    "        \n",
    "        # @conv1 - (95,95)\n",
    "        # @conv2 - (47, 47)\n",
    "        # @conv3 - (23, 23)\n",
    "        # @conv4 - (11, 11)\n",
    "        # @conv5 - (5, 5)\n",
    "        # @conv6 - (2,2)\n",
    "        # Followed by a an avg pool (2,2) to make this 1,1\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Initialising N/W here\n",
    "        # ---------------------\n",
    "        nw_activation_conv = nn.ReLU() #nn.LeakyReLU(0.2) # nn.Tanh() nn.Softmax2d()\n",
    "        f = 3\n",
    "        s = 2\n",
    "        dropout_prob = 0.2\n",
    "        dropout_node = nn.Dropout2d(p=dropout_prob)\n",
    "        \n",
    "        # CONV Down layers\n",
    "        # ----------------\n",
    "        \n",
    "        # Conv 1\n",
    "        ###\n",
    "        conv1 = 16\n",
    "        ct1 = nn.Conv2d(in_channels,conv1,f,stride = s)\n",
    "        cb1 = nn.BatchNorm2d(conv1)\n",
    "        ca1 = nw_activation_conv\n",
    "        cl1 = [ct1,cb1,ca1,dropout_node]\n",
    "        self.convl1 = nn.Sequential(*cl1)\n",
    "        \n",
    "        # Conv 2\n",
    "        ###\n",
    "        conv2 = 32\n",
    "        ct2 = nn.Conv2d(conv1,conv2,f,stride = s)\n",
    "        cb2 = nn.BatchNorm2d(conv2)\n",
    "        ca2 = nw_activation_conv\n",
    "        cl2 = [ct2,cb2,ca2,dropout_node]\n",
    "        self.convl2 = nn.Sequential(*cl2)\n",
    "        \n",
    "        # Conv 3\n",
    "        ###\n",
    "        conv3 = 64\n",
    "        ct3 = nn.Conv2d(conv2,conv3,f,stride = s)\n",
    "        cb3 = nn.BatchNorm2d(conv3)\n",
    "        ca3 = nw_activation_conv\n",
    "        cl3 = [ct3,cb3,ca3,dropout_node]\n",
    "        self.convl3 = nn.Sequential(*cl3)\n",
    "        \n",
    "        # Conv 4\n",
    "        ###\n",
    "        conv4 = 128\n",
    "        ct4 = nn.Conv2d(conv3,conv4,f,stride = s)\n",
    "        cb4 = nn.BatchNorm2d(conv4)\n",
    "        ca4 = nw_activation_conv\n",
    "        cl4 = [ct4,cb4,ca4,dropout_node]\n",
    "        self.convl4 = nn.Sequential(*cl4) \n",
    "        \n",
    "        # Conv 5\n",
    "        ###\n",
    "        conv5 = 256\n",
    "        ct5 = nn.Conv2d(conv4,conv5,f,stride = s)\n",
    "        cb5 = nn.BatchNorm2d(conv5)\n",
    "        ca5 = nw_activation_conv\n",
    "        cl5 = [ct5,cb5,ca5,dropout_node]\n",
    "        self.convl5 = nn.Sequential(*cl5) \n",
    "        \n",
    "        # Conv 6\n",
    "        ###\n",
    "        conv6 = 512\n",
    "        ct6 = nn.Conv2d(conv5,conv6,f,stride = s)\n",
    "        cb6 = nn.BatchNorm2d(conv6)\n",
    "        ca6 = nw_activation_conv\n",
    "        cl6 = [ct6,cb6,ca6,dropout_node]\n",
    "        self.convl6 = nn.Sequential(*cl6) \n",
    "        \n",
    "\n",
    "        # Pooling layer + softmax activation\n",
    "        # ----------------------------------\n",
    "        if latent_softmax == True:\n",
    "            avpl =  [nn.AvgPool2d((2,2), stride=1), nn.Softmax2d()]\n",
    "        else:\n",
    "            avpl =  [nn.AvgPool2d((2,2), stride=1)]\n",
    "        self.pool_net = nn.Sequential(*avpl)\n",
    "        \n",
    "      \n",
    "        # Transconv layers\n",
    "        # ----------------\n",
    "        # Showing conv up sizes - \n",
    "        # --------------------------\n",
    "        # Incoming input is 1 x 1 x C\n",
    "        # (5, 5)\n",
    "        # (11, 11)\n",
    "        # (23, 23)\n",
    "        # (47, 47)\n",
    "        # (95, 95)\n",
    "        # (191, 191)\n",
    "        \n",
    "        # Upconv layer 0\n",
    "        ###\n",
    "        up_conv0 = conv6\n",
    "        t0 = nn.ConvTranspose2d(conv6,up_conv0,2,stride = 1)\n",
    "        b0 = nn.BatchNorm2d(up_conv0)\n",
    "        a0 = nw_activation_conv\n",
    "        l0 = [t0,b0,a0,dropout_node]\n",
    "        self.upcl0 = nn.Sequential(*l0) # 2x2\n",
    "        \n",
    "        # Upconv layer 1\n",
    "        # concat layer\n",
    "        ###\n",
    "        up_conv1 = 256\n",
    "        t1 = nn.ConvTranspose2d(up_conv0 + conv6,up_conv1,f,stride = s)\n",
    "        b1 = nn.BatchNorm2d(up_conv1)\n",
    "        a1 = nw_activation_conv\n",
    "        l1 = [t1,b1,a1,dropout_node]\n",
    "        self.upcl1 = nn.Sequential(*l1) # 5x5\n",
    "        \n",
    "        # Upconv layer 2\n",
    "        # concat layer\n",
    "        ###\n",
    "        up_conv2 = 128\n",
    "        t2 = nn.ConvTranspose2d(up_conv1 + conv5,up_conv2,f,stride = s)\n",
    "        b2 = nn.BatchNorm2d(up_conv2)\n",
    "        a2 = nw_activation_conv\n",
    "        l2 = [t2,b2,a2,dropout_node]\n",
    "        self.upcl2 = nn.Sequential(*l2)\n",
    "        \n",
    "        # Upconv layer 3\n",
    "        # concat layer\n",
    "        ###\n",
    "        up_conv3 = 64\n",
    "        t3 = nn.ConvTranspose2d(up_conv2 + conv4,up_conv3,f,stride = s)\n",
    "        b3 = nn.BatchNorm2d(up_conv3)\n",
    "        a3 = nw_activation_conv\n",
    "        l3 = [t3,b3,a3,dropout_node]\n",
    "        self.upcl3 = nn.Sequential(*l3)\n",
    "        \n",
    "        # Upconv layer 4\n",
    "        # concat layer\n",
    "        ###\n",
    "        up_conv4 = 32\n",
    "        t4 = nn.ConvTranspose2d(up_conv3 + conv3,up_conv4,f,stride = s)\n",
    "        b4 = nn.BatchNorm2d(up_conv4)\n",
    "        a4 = nw_activation_conv\n",
    "        l4 = [t4,b4,a4,dropout_node]\n",
    "        self.upcl4 = nn.Sequential(*l4)\n",
    "        \n",
    "        # Upconv layer 5\n",
    "        # concat layer\n",
    "        ###\n",
    "        up_conv5 = 16\n",
    "        t5 = nn.ConvTranspose2d(up_conv4 + conv2,up_conv5,f,stride = s)\n",
    "        b5 = nn.BatchNorm2d(up_conv5)\n",
    "        a5 = nw_activation_conv\n",
    "        l5 = [t5,b5,a5,dropout_node]\n",
    "        self.upcl5 = nn.Sequential(*l5)\n",
    "    \n",
    "    \n",
    "        # Upconv layer 6\n",
    "        # concat layer - FINAL LAYER\n",
    "        ###\n",
    "        t6 = nn.ConvTranspose2d(up_conv5 + conv1,3,f,stride = s)\n",
    "        a6 = nn.Sigmoid()\n",
    "        l6 = [t6,a6]\n",
    "        self.upcl6 = nn.Sequential(*l6)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Conv pass\n",
    "        # ---------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        c4_out = self.convl4(c3_out)\n",
    "        c5_out = self.convl5(c4_out)\n",
    "        c6_out = self.convl6(c5_out)\n",
    "        \n",
    "        # pooling\n",
    "        # -------\n",
    "        latent_out = self.pool_net(c6_out)\n",
    "        \n",
    "        # Transconv pass\n",
    "        # --------------\n",
    "        f1_out = self.upcl0(latent_out)\n",
    "        f2_out = self.upcl1(torch.cat((f1_out,c6_out), 1))\n",
    "        f3_out = self.upcl2(torch.cat((f2_out,c5_out), 1))\n",
    "        f4_out = self.upcl3(torch.cat((f3_out,c4_out), 1))\n",
    "        f5_out = self.upcl4(torch.cat((f4_out,c3_out), 1))\n",
    "        f6_out = self.upcl5(torch.cat((f5_out,c2_out), 1))\n",
    "        f7_out = self.upcl6(torch.cat((f6_out,c1_out), 1))\n",
    "        \n",
    "        return f7_out\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCN class copied from image search notebook which worked\n",
    "# --------------------------------------------------------\n",
    "\n",
    "class standard_cnn_6_layer(nn.Module):\n",
    "    def __init__(self, in_channels, latent_softmax):\n",
    "        super().__init__()\n",
    "        \n",
    "        # This is WNET model\n",
    "        # ------------------\n",
    "        \n",
    "        # Showing conv up sizes - \n",
    "        # --------------------------\n",
    "        # (191,191) -- Insize\n",
    "        \n",
    "        # @conv1 - (95,95)\n",
    "        # @conv2 - (47, 47)\n",
    "        # @conv3 - (23, 23)\n",
    "        # @conv4 - (11, 11)\n",
    "        # @conv5 - (5, 5)\n",
    "        # @conv6 - (2,2)\n",
    "        # Followed by a an avg pool (2,2) to make this 1,1\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Initialising N/W here\n",
    "        # ---------------------\n",
    "        nw_activation_conv = nn.ReLU() #nn.LeakyReLU(0.2) # nn.Tanh() nn.Softmax2d()\n",
    "        f = 3\n",
    "        s = 2\n",
    "        dropout_prob = 0.2\n",
    "        dropout_node = nn.Dropout2d(p=dropout_prob)\n",
    "        \n",
    "        # CONV Down layers\n",
    "        # ----------------\n",
    "        \n",
    "        # Conv 1\n",
    "        ###\n",
    "        conv1 = 16\n",
    "        ct1 = nn.Conv2d(in_channels,conv1,f,stride = s)\n",
    "        cb1 = nn.BatchNorm2d(conv1)\n",
    "        ca1 = nw_activation_conv\n",
    "        cl1 = [ct1,cb1,ca1,dropout_node]\n",
    "        self.convl1 = nn.Sequential(*cl1)\n",
    "        \n",
    "        # Conv 2\n",
    "        ###\n",
    "        conv2 = 32\n",
    "        ct2 = nn.Conv2d(conv1,conv2,f,stride = s)\n",
    "        cb2 = nn.BatchNorm2d(conv2)\n",
    "        ca2 = nw_activation_conv\n",
    "        cl2 = [ct2,cb2,ca2,dropout_node]\n",
    "        self.convl2 = nn.Sequential(*cl2)\n",
    "        \n",
    "        # Conv 3\n",
    "        ###\n",
    "        conv3 = 64\n",
    "        ct3 = nn.Conv2d(conv2,conv3,f,stride = s)\n",
    "        cb3 = nn.BatchNorm2d(conv3)\n",
    "        ca3 = nw_activation_conv\n",
    "        cl3 = [ct3,cb3,ca3,dropout_node]\n",
    "        self.convl3 = nn.Sequential(*cl3)\n",
    "        \n",
    "        # Conv 4\n",
    "        ###\n",
    "        conv4 = 128\n",
    "        ct4 = nn.Conv2d(conv3,conv4,f,stride = s)\n",
    "        cb4 = nn.BatchNorm2d(conv4)\n",
    "        ca4 = nw_activation_conv\n",
    "        cl4 = [ct4,cb4,ca4,dropout_node]\n",
    "        self.convl4 = nn.Sequential(*cl4) \n",
    "        \n",
    "        # Conv 5\n",
    "        ###\n",
    "        conv5 = 256\n",
    "        ct5 = nn.Conv2d(conv4,conv5,f,stride = s)\n",
    "        cb5 = nn.BatchNorm2d(conv5)\n",
    "        ca5 = nw_activation_conv\n",
    "        cl5 = [ct5,cb5,ca5,dropout_node]\n",
    "        self.convl5 = nn.Sequential(*cl5) \n",
    "        \n",
    "        # Conv 6\n",
    "        ###\n",
    "        conv6 = 512\n",
    "        ct6 = nn.Conv2d(conv5,conv6,f,stride = s)\n",
    "        cb6 = nn.BatchNorm2d(conv6)\n",
    "        ca6 = nw_activation_conv\n",
    "        cl6 = [ct6,cb6,ca6,dropout_node]\n",
    "        self.convl6 = nn.Sequential(*cl6) \n",
    "        \n",
    "\n",
    "        # Pooling layer + softmax activation\n",
    "        # ----------------------------------\n",
    "        if latent_softmax == True:\n",
    "            avpl =  [nn.AvgPool2d((2,2), stride=1), nn.Softmax2d()]\n",
    "        else:\n",
    "            avpl =  [nn.AvgPool2d((2,2), stride=1)]\n",
    "        self.pool_net = nn.Sequential(*avpl)\n",
    "        \n",
    "        \n",
    "        # Adding linear layers\n",
    "        # -------------------\n",
    "        lnt1 = nn.Linear(conv6,256)\n",
    "        lnb1 = nn.BatchNorm1d(256)\n",
    "        lna1 = nw_activation_conv\n",
    "        ln1 = [lnt1,lnb1,lna1,dropout_node]\n",
    "        self.linear1 = nn.Sequential(*ln1) \n",
    "      \n",
    "        lnt2 = nn.Linear(256,128)\n",
    "        lnb2 = nn.BatchNorm1d(128)\n",
    "        lna2 = nw_activation_conv\n",
    "        ln2 = [lnt2,lnb2,lna2,dropout_node]\n",
    "        self.linear2 = nn.Sequential(*ln2)\n",
    "        \n",
    "        lnt3 = nn.Linear(128,64)\n",
    "        lnb3 = nn.BatchNorm1d(64)\n",
    "        lna3 = nw_activation_conv\n",
    "        ln3 = [lnt3,lnb3,lna3,dropout_node]\n",
    "        self.linear3 = nn.Sequential(*ln3)\n",
    "        \n",
    "        ln4 = [nn.Linear(64,1)]\n",
    "        self.linear4 = nn.Sequential(*ln4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Conv pass\n",
    "        # ---------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        c4_out = self.convl4(c3_out)\n",
    "        c5_out = self.convl5(c4_out)\n",
    "        c6_out = self.convl6(c5_out)\n",
    "        \n",
    "        # pooling\n",
    "        # -------\n",
    "        latent_out = self.pool_net(c6_out)\n",
    "        \n",
    "        # linear out\n",
    "        # ----------\n",
    "        linear1_out = self.linear1(latent_out.view(latent_out.size()[0],-1))\n",
    "        linear2_out = self.linear2(linear1_out)\n",
    "        linear3_out = self.linear3(linear2_out)\n",
    "        linear4_out = self.linear4(linear3_out)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return linear4_out\n",
    "\n",
    "\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCN class copied from image search notebook which worked\n",
    "# --------------------------------------------------------\n",
    "\n",
    "class standard_cnn_4_layer(nn.Module):\n",
    "    def __init__(self, in_channels, latent_softmax):\n",
    "        super().__init__()\n",
    "        \n",
    "        # This is WNET model\n",
    "        # ------------------\n",
    "        \n",
    "        # Showing conv up sizes - \n",
    "        # --------------------------\n",
    "        # (191,191) -- Insize\n",
    "        \n",
    "        # @conv1 - (95,95)\n",
    "        # @conv2 - (47, 47)\n",
    "        # @conv3 - (23, 23)\n",
    "        # @conv4 - (11, 11)\n",
    "        # @conv5 - (5, 5)\n",
    "        # @conv6 - (2,2)\n",
    "        # Followed by a an avg pool (2,2) to make this 1,1\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Initialising N/W here\n",
    "        # ---------------------\n",
    "        nw_activation_conv = nn.ReLU() #nn.LeakyReLU(0.2) # nn.Tanh() nn.Softmax2d()\n",
    "        f = 3\n",
    "        s = 2\n",
    "        dropout_prob = 0.2\n",
    "        dropout_node = nn.Dropout2d(p=dropout_prob)\n",
    "        \n",
    "        # CONV Down layers\n",
    "        # ----------------\n",
    "        \n",
    "        # Conv 1\n",
    "        ###\n",
    "        conv1 = 64\n",
    "        ct1 = nn.Conv2d(in_channels,conv1,f,stride = s)\n",
    "        cb1 = nn.BatchNorm2d(conv1)\n",
    "        ca1 = nw_activation_conv\n",
    "        cl1 = [ct1,cb1,ca1,dropout_node]\n",
    "        self.convl1 = nn.Sequential(*cl1)\n",
    "        \n",
    "        # Conv 2\n",
    "        ###\n",
    "        conv2 = 128\n",
    "        ct2 = nn.Conv2d(conv1,conv2,f,stride = s)\n",
    "        cb2 = nn.BatchNorm2d(conv2)\n",
    "        ca2 = nw_activation_conv\n",
    "        cl2 = [ct2,cb2,ca2,dropout_node]\n",
    "        self.convl2 = nn.Sequential(*cl2)\n",
    "        \n",
    "        # Conv 3\n",
    "        ###\n",
    "        conv3 = 256\n",
    "        ct3 = nn.Conv2d(conv2,conv3,f,stride = s)\n",
    "        cb3 = nn.BatchNorm2d(conv3)\n",
    "        ca3 = nw_activation_conv\n",
    "        cl3 = [ct3,cb3,ca3,dropout_node]\n",
    "        self.convl3 = nn.Sequential(*cl3)\n",
    "        \n",
    "        # Conv 4\n",
    "        ###\n",
    "        conv4 = 512\n",
    "        ct4 = nn.Conv2d(conv3,conv4,f,stride = s)\n",
    "        cb4 = nn.BatchNorm2d(conv4)\n",
    "        ca4 = nw_activation_conv\n",
    "        cl4 = [ct4,cb4,ca4,dropout_node]\n",
    "        self.convl4 = nn.Sequential(*cl4) \n",
    "    \n",
    "        \n",
    "        # Adding linear layers\n",
    "        # -------------------\n",
    "        lnt1 = nn.Linear(conv4*11*11,1024)\n",
    "        lnb1 = nn.BatchNorm1d(1024)\n",
    "        lna1 = nw_activation_conv\n",
    "        ln1 = [lnt1,lnb1,lna1,dropout_node]\n",
    "        self.linear1 = nn.Sequential(*ln1) \n",
    "      \n",
    "        lnt2 = nn.Linear(1024,512)\n",
    "        lnb2 = nn.BatchNorm1d(512)\n",
    "        lna2 = nw_activation_conv\n",
    "        ln2 = [lnt2,lnb2,lna2,dropout_node]\n",
    "        self.linear2 = nn.Sequential(*ln2)\n",
    "        \n",
    "        lnt3 = nn.Linear(512,256)\n",
    "        lnb3 = nn.BatchNorm1d(256)\n",
    "        lna3 = nw_activation_conv\n",
    "        ln3 = [lnt3,lnb3,lna3,dropout_node]\n",
    "        self.linear3 = nn.Sequential(*ln3)\n",
    "        \n",
    "        ln4 = [nn.Linear(256,1)]\n",
    "        self.linear4 = nn.Sequential(*ln4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Conv pass\n",
    "        # ---------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        c4_out = self.convl4(c3_out)\n",
    "        \n",
    "        # linear out\n",
    "        # ----------\n",
    "        linear1_out = self.linear1(c4_out.view(c4_out.size()[0],-1))\n",
    "        linear2_out = self.linear2(linear1_out)\n",
    "        linear3_out = self.linear3(linear2_out)\n",
    "        linear4_out = self.linear4(linear3_out)\n",
    "        \n",
    "        return linear4_out\n",
    "\n",
    "\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END OF CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. preparing dataset - one off task"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Creating a dict to be used later\n",
    "# --------------------------------\n",
    "\n",
    "imgurl = '/Users/venkateshmadhava/Documents/projects/vision/face_detection/WIDER_train/images/'\n",
    "csv_url = '/Users/venkateshmadhava/Documents/projects/vision/face_detection/wider_face_split/wider_face_train_bbx_gt.csv'\n",
    "\n",
    "d = create_labels_dict(csv_url,imgurl)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# creating bounding box images dict\n",
    "# ---------------------------------\n",
    "\n",
    "xc,xb,xn = final_bounding_box_dataset_pool(imgurl,d,500,500)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# priting results images\n",
    "# ----------------------\n",
    "\n",
    "randrange = list(np.random.randint(len(xc.keys()), size=(1, 5))[0,:])\n",
    "\n",
    "for i in randrange:\n",
    "    img_s = list(xc.keys())[i]\n",
    "    img_b = list(xb.keys())[i]\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(xc[img_s][0])\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(xb[img_b][0])\n",
    "    plt.show()\n",
    "    \n",
    "    if img_s == img_b:\n",
    "        print('No of faces detected - ' + str(xn[img_s]))\n",
    "        print('--------------------')\n",
    "\n",
    "    else:\n",
    "        print('ERROR')\n",
    "        print(img_s)\n",
    "        print(img_b)\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# creating numpy array from dicts\n",
    "# --------------------------------\n",
    "\n",
    "xsd,xbd,xnd = create_source_box_datasets_pool(xc,xb,xn)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# printing images for sanity\n",
    "# --------------------------\n",
    "\n",
    "randrange = list(np.random.randint(xsd.shape[0], size=(1, 5))[0,:])\n",
    "\n",
    "for i in randrange:\n",
    "    print(str(xnd[i]) + ' faces in the picture.')\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(xsd[i])\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(xbd[i])\n",
    "    plt.show()\n",
    "    print('------------')\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# shuffling and splitting dataset\n",
    "# -------------------------------\n",
    "p = np.random.permutation(xsd.shape[0])\n",
    "len(p)\n",
    "trn_strt,trn_end,val_strt,val_end,test_strt,test_end = split_sets(len(p), 0.7, 0.1)\n",
    "\n",
    "# splitting sets\n",
    "# --------------\n",
    "xs_train = xsd[0:trn_end]\n",
    "xb_train = xbd[0:trn_end]\n",
    "xn_train = xnd[0:trn_end]\n",
    "\n",
    "xs_val = xsd[val_strt:val_end]\n",
    "xb_val = xbd[val_strt:val_end]\n",
    "xn_val = xnd[val_strt:val_end]\n",
    "\n",
    "xs_test = xsd[test_strt:]\n",
    "xb_test = xbd[test_strt:]\n",
    "xn_test = xnd[test_strt:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# printing images for sanity\n",
    "# --------------------------\n",
    "\n",
    "randrange = list(np.random.randint(xb_val.shape[0], size=(1, 5))[0,:])\n",
    "\n",
    "for i in randrange:\n",
    "    print('train image - ')\n",
    "    print(str(xn_train[i]) + ' faces in the picture.')\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(xs_train[i])\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(xb_train[i])\n",
    "    plt.show()\n",
    "    print('val image - ')\n",
    "    print(str(xn_val[i]) + ' faces in the picture.')\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(xs_val[i])\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(xb_val[i])\n",
    "    plt.show()\n",
    "    print('test image - ')\n",
    "    print(str(xn_test[i]) + ' faces in the picture.')\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(xs_test[i])\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(xb_test[i])\n",
    "    plt.show()\n",
    "    print('#####################################################')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# saving h5 files\n",
    "# ---------------\n",
    "\n",
    "# Train sets\n",
    "# ----------\n",
    "master_h5_url = '/Users/venkateshmadhava/Documents/projects/vision/face_detection/WIDER_train/face_detection_xs_train.h5'\n",
    "hf = h5py.File(master_h5_url, 'w')\n",
    "hf.create_dataset('images', data = xs_train, dtype = 'uint8')\n",
    "hf.close()\n",
    "\n",
    "master_h5_url = '/Users/venkateshmadhava/Documents/projects/vision/face_detection/WIDER_train/face_detection_xb_train.h5'\n",
    "hf = h5py.File(master_h5_url, 'w')\n",
    "hf.create_dataset('images', data = xb_train, dtype = 'uint8')\n",
    "hf.close()\n",
    "\n",
    "master_h5_url = '/Users/venkateshmadhava/Documents/projects/vision/face_detection/WIDER_train/face_detection_xn_train.h5'\n",
    "hf = h5py.File(master_h5_url, 'w')\n",
    "hf.create_dataset('data', data = xn_train)\n",
    "hf.close()\n",
    "\n",
    "\n",
    "# Val sets\n",
    "# ---------\n",
    "master_h5_url = '/Users/venkateshmadhava/Documents/projects/vision/face_detection/WIDER_train/face_detection_xs_val.h5'\n",
    "hf = h5py.File(master_h5_url, 'w')\n",
    "hf.create_dataset('images', data = xs_val, dtype = 'uint8')\n",
    "hf.close()\n",
    "\n",
    "master_h5_url = '/Users/venkateshmadhava/Documents/projects/vision/face_detection/WIDER_train/face_detection_xb_val.h5'\n",
    "hf = h5py.File(master_h5_url, 'w')\n",
    "hf.create_dataset('images', data = xb_val, dtype = 'uint8')\n",
    "hf.close()\n",
    "\n",
    "master_h5_url = '/Users/venkateshmadhava/Documents/projects/vision/face_detection/WIDER_train/face_detection_xn_val.h5'\n",
    "hf = h5py.File(master_h5_url, 'w')\n",
    "hf.create_dataset('data', data = xn_val)\n",
    "hf.close()\n",
    "\n",
    "\n",
    "# Test sets\n",
    "# ---------\n",
    "master_h5_url = '/Users/venkateshmadhava/Documents/projects/vision/face_detection/WIDER_train/face_detection_xs_test.h5'\n",
    "hf = h5py.File(master_h5_url, 'w')\n",
    "hf.create_dataset('images', data = xs_test, dtype = 'uint8')\n",
    "hf.close()\n",
    "\n",
    "master_h5_url = '/Users/venkateshmadhava/Documents/projects/vision/face_detection/WIDER_train/face_detection_xb_test.h5'\n",
    "hf = h5py.File(master_h5_url, 'w')\n",
    "hf.create_dataset('images', data = xb_test, dtype = 'uint8')\n",
    "hf.close()\n",
    "\n",
    "master_h5_url = '/Users/venkateshmadhava/Documents/projects/vision/face_detection/WIDER_train/face_detection_xn_test.h5'\n",
    "hf = h5py.File(master_h5_url, 'w')\n",
    "hf.create_dataset('data', data = xn_test)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. loading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 setting up model related variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SET UP CUDA OR NOT HERE + OTHER SET UPS\n",
    "##########################################\n",
    "\n",
    "dev_env = 'local' # 'gpu' or 'local'\n",
    "\n",
    "##########################################\n",
    "##########################################\n",
    "\n",
    "# Setting CUDA\n",
    "# ------------\n",
    "if dev_env == 'gpu':\n",
    "    use_cuda = True\n",
    "else:\n",
    "    use_cuda = False\n",
    "if use_cuda == True:\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "\n",
    "# SET FILE SPECIFIC NAMES HERE\n",
    "# ----------------------------\n",
    "if dev_env == 'gpu':\n",
    "    save_path = '/home/venkateshmadhava/codes/pmate2_localgpuenv/models/'\n",
    "    parent_url = '/home/venkateshmadhava/datasets/images'\n",
    "else:\n",
    "    save_path = '/Users/venkateshmadhava/Documents/pmate2/pmate2_env/models/'\n",
    "    parent_url = '/Users/venkateshmadhava/Documents/projects/vision/face_detection/WIDER_train'\n",
    "\n",
    "\n",
    "# displaying save path\n",
    "# --------------------\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "''' too large to load '''\n",
    "\n",
    "# readinf h5 sets train\n",
    "# ---------------------\n",
    "master_h5_url = parent_url + '/face_detection_xs_train.h5'\n",
    "hfr = h5py.File(master_h5_url, 'r')\n",
    "xs_trn = np.array(hfr.get('images'))\n",
    "\n",
    "master_h5_url = parent_url + '/face_detection_xb_train.h5'\n",
    "hfr = h5py.File(master_h5_url, 'r')\n",
    "xb_trn = np.array(hfr.get('images'))\n",
    "\n",
    "master_h5_url = parent_url + '/face_detection_xn_train.h5'\n",
    "hfr = h5py.File(master_h5_url, 'r')\n",
    "xn_trn = np.array(hfr.get('data'))\n",
    "\n",
    "# readinf h5 sets val sets\n",
    "# ------------------------\n",
    "master_h5_url = parent_url + '/face_detection_xs_val.h5'\n",
    "hfr = h5py.File(master_h5_url, 'r')\n",
    "xs_vl = np.array(hfr.get('images'))\n",
    "\n",
    "master_h5_url = parent_url + '/face_detection_xb_val.h5'\n",
    "hfr = h5py.File(master_h5_url, 'r')\n",
    "xb_vl = np.array(hfr.get('images'))\n",
    "\n",
    "master_h5_url = parent_url + '/face_detection_xn_val.h5'\n",
    "hfr = h5py.File(master_h5_url, 'r')\n",
    "xn_vl = np.array(hfr.get('data'))\n",
    "\n",
    "# readinf h5 sets test set\n",
    "# ------------------------\n",
    "master_h5_url = parent_url + '/face_detection_xs_test.h5'\n",
    "hfr = h5py.File(master_h5_url, 'r')\n",
    "xs_tst = np.array(hfr.get('images'))\n",
    "\n",
    "master_h5_url = parent_url + '/face_detection_xb_test.h5'\n",
    "hfr = h5py.File(master_h5_url, 'r')\n",
    "xb_tst = np.array(hfr.get('images'))\n",
    "\n",
    "master_h5_url = parent_url + '/face_detection_xn_test.h5'\n",
    "hfr = h5py.File(master_h5_url, 'r')\n",
    "xn_tst = np.array(hfr.get('data'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Resizing images if required\n",
    "# ----------------------------\n",
    "new_h,new_w = 191,191\n",
    "resize_images = True\n",
    "\n",
    "if resize_images == True:\n",
    "    \n",
    "    xs_trn = resize_all(xs_trn,new_h,new_w)\n",
    "    xb_trn = resize_all(xb_trn,new_h,new_w)\n",
    "    \n",
    "    xs_vl = resize_all(xs_vl,new_h,new_w)\n",
    "    xb_vl = resize_all(xb_vl,new_h,new_w)\n",
    "    \n",
    "    xs_tst = resize_all(xs_tst,new_h,new_w)\n",
    "    xb_tst = resize_all(xb_tst,new_h,new_w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# printing images for sanity\n",
    "# --------------------------\n",
    "\n",
    "randrange = list(np.random.randint(xb_vl.shape[0], size=(1, 1))[0,:])\n",
    "\n",
    "for i in randrange:\n",
    "    print('train image - ')\n",
    "    print(str(xn_trn[i]) + ' faces in the picture.')\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(xs_trn[i])\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(xb_trn[i])\n",
    "    plt.show()\n",
    "    print('#####################################################')\n",
    "    print('val image - ')\n",
    "    print(str(xn_vl[i]) + ' faces in the picture.')\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(xs_vl[i])\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(xb_vl[i])\n",
    "    plt.show()\n",
    "    print('#####################################################')\n",
    "    print('test image - ')\n",
    "    print(str(xn_tst[i]) + ' faces in the picture.')\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(xs_tst[i])\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(xb_tst[i])\n",
    "    plt.show()\n",
    "    print('#####################################################')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 2. setting up & training models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# snippet to work out filter sizes\n",
    "# --------------------------------\n",
    "f = 3\n",
    "s = 2\n",
    "pad = 0\n",
    "layers = 4\n",
    "\n",
    "h = 191 # 255\n",
    "w = 191 # 255\n",
    "print('Showing conv down sizes - ')\n",
    "print('--------------------------')\n",
    "# showing out sizes after conv\n",
    "# ----------------------------\n",
    "for _ in range(layers):   \n",
    "    h,w = outsize_conv(h,w,f,s,pad)\n",
    "    print((h,w))\n",
    "    \n",
    "h = 2\n",
    "w = 2\n",
    "print('\\nShowing conv up sizes - ')\n",
    "print('--------------------------')\n",
    "# showing out sizes after conv\n",
    "# ----------------------------\n",
    "dims = []\n",
    "for _ in range(layers):   \n",
    "    h,w = outsize_upconv(h,w,f,s,pad)\n",
    "    dims.append((h,w))\n",
    "    print((h,w))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Set up train data\n",
    "# -----------------\n",
    "\n",
    "use_gray = False\n",
    "\n",
    "if use_gray == True:\n",
    "    in_channels = 1\n",
    "    xs_trn_gray = rgb2gray(copy.deepcopy(xs_trn))\n",
    "    xs_trn_gray = xs_trn_gray.reshape(xs_trn_gray.shape[0], xs_trn_gray.shape[1], xs_trn_gray.shape[2], 1)\n",
    "    xin_train = Variable(setup_image_tensor(xs_trn_gray.astype('float'))).float()\n",
    "    \n",
    "else:\n",
    "    in_channels = 3\n",
    "    xin_train = Variable(setup_image_tensor(xs_trn)).float()\n",
    "\n",
    "# setting up out\n",
    "# --------------\n",
    "xout_train = Variable(setup_image_tensor(xb_trn)).float()\n",
    "\n",
    "print(xin_train.size())\n",
    "print(xout_train.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 start of model setup and training"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Using an FCN AE system\n",
    "# Training fcn_ae_6_layer_WNET to 65 expoch brings loss to 0.014\n",
    "# ----------------------\n",
    "\n",
    "try:\n",
    "    del model_ae\n",
    "    print('Old model deleted.')\n",
    "except:\n",
    "    pass\n",
    "model_ae = fcn_ae_6_layer_WNET(in_channels,False)\n",
    "model_ae.apply(weights_init)\n",
    "model_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cn_file_name = 'ae_model_face_detection_6_layer_WNET_nonsoftmax_512.tar'\n",
    "cn_save_path = save_path + cn_file_name\n",
    "print(cn_save_path)\n",
    "\n",
    "\n",
    "model,_,epoch,loss,_ = load_saved_model_function(cn_save_path, False)\n",
    "print('Last saved epoch: ' + str(epoch))\n",
    "print('Last saved loss: ' + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training the model\n",
    "# ------------------\n",
    "\n",
    "#''' USE -1 AS EPOCHS TO LOAD SAVED MODEL WITHOUT TRAINING '''\n",
    "\n",
    "# model_train(xin,yin,xval,yval,load_mode,model,epochs,mbsize,loss_mode,flatten,use_cuda,save_state,path)\n",
    "\n",
    "#cn_file_name = 'ae_model_face_detection_6_layer_WNET_nonsoftmax_512.tar'\n",
    "#cn_save_path = save_path + cn_file_name\n",
    "#print(cn_save_path)\n",
    "\n",
    "\n",
    "#model_ae = model_train(xin_train,xout_train,None,None,'from saved',None,-1,64,'mse',False,use_cuda,True,cn_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 visualising results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking results on Train data\n",
    "# ------------------------------\n",
    "\n",
    "#xo,xg = generate_output(xin_train,model_ae,40,45,True,use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking results on Test data\n",
    "# -----------------------------\n",
    "\n",
    "#xo,xg = generate_output(Variable(setup_image_tensor(xs_tst)).float(),model_ae,1605,1610,True,use_cuda)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# random sampling\n",
    "# --------------\n",
    "\n",
    "randrange = list(np.random.randint(xs_tst.shape[0], size=(1, 1))[0,:])\n",
    "\n",
    "\n",
    "if use_gray == True:\n",
    "    in_channels = 1\n",
    "    nx_trn_gray = rgb2gray(copy.deepcopy(xs_tst[randrange]))\n",
    "    nx_trn_gray = nx_trn_gray.reshape(nx_trn_gray.shape[0], nx_trn_gray.shape[1], nx_trn_gray.shape[2], 1)\n",
    "    nx_trn = Variable(setup_image_tensor(nx_trn_gray.astype('float'))).float()\n",
    "\n",
    "else:\n",
    "    nx_trn = Variable(setup_image_tensor(xs_tst[randrange])).float()\n",
    "    \n",
    "\n",
    "\n",
    "n_output = model_ae.eval().cpu()((nx_trn/255).cpu())\n",
    "np_out = to_numpy_image(n_output.cpu().data)\n",
    "\n",
    "for i in range(np_out.shape[0]):\n",
    "    print(str(i))\n",
    "    print('Original - ')\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(xs_tst[randrange][i])\n",
    "    plt.show()\n",
    "    print('Output - ')\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(np_out[i])\n",
    "    plt.show()\n",
    "    print('#####################################################')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reading images from local folder\n",
    "# --------------------------------\n",
    "\n",
    "if dev_env == 'local':\n",
    "    \n",
    "    new_h,new_w = 191,191\n",
    "    in_folder = '/Users/venkateshmadhava/Documents/projects/vision/face_check_recognition/test'\n",
    "    x_local = create_dataset_from_folder_all(in_folder,new_h,new_w)\n",
    "    x_local_trn = Variable(setup_image_tensor(x_local)).float()\n",
    "    print(x_local_trn.size())\n",
    "\n",
    "    # forward pass ops\n",
    "    # ----------------\n",
    "    n_output = model.eval().cpu()((x_local_trn/255).cpu())\n",
    "    np_out = to_numpy_image(n_output.cpu().data)\n",
    "\n",
    "    for i in range(np_out.shape[0]):\n",
    "        print(str(i))\n",
    "        print('Original - ')\n",
    "        plt.figure(figsize=(5,5))\n",
    "        plt.imshow(x_local[i])\n",
    "        plt.show()\n",
    "        print('Output - ')\n",
    "        plt.figure(figsize=(5,5))\n",
    "        plt.imshow(np_out[i])\n",
    "        plt.show()\n",
    "        print('#####################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END OF TRAINING FCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 setting up and training number predictor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# setting ae latent pool mode\n",
    "#############################\n",
    "\n",
    "#ae_pool_mode = 'avg' # avg and max and both\n",
    "#layer_mode = 'deep' # deep - for all 3 layers, non_deep for 2 layers\n",
    "#layer_dims_set = True\n",
    "#layer_f, layer_s = 3,2 #5,2 # 7,2 and both worked nice\n",
    "#model_ae.set_pool_mode(ae_pool_mode,layer_mode,layer_dims_set,layer_f,layer_s)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# retreiving latents of train set\n",
    "# -------------------------------\n",
    "\n",
    "num_faces_out_trn = Variable(torch.from_numpy(xn_trn[0:5])).float()\n",
    "num_faces_out_trn = num_faces_out_trn.view(-1,1)\n",
    "latent_xin_train = chunk_pass(xin_train[0:5],model_ae,True,use_cuda,1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Setting up a linear model\n",
    "# -------------------------\n",
    "target_main_model_act = None\n",
    "\n",
    "try:\n",
    "    del model_num_face_net\n",
    "    print('Old model deleted.')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "dense_layers = [latent_xin_train.size()[1],48,1]\n",
    "model_num_face_net = linear_fc(dense_layers, 'relu', target_main_model_act, 0.2)\n",
    "model_num_face_net"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# training the model\n",
    "# -----------------\n",
    "\n",
    "''' USE -1 AS EPOCHS TO LOAD SAVED MODEL WITHOUT TRAINING '''\n",
    "\n",
    "# model_train(xin,yin,xval,yval,load_mode,model,epochs,mbsize,loss_mode,flatten,use_cuda,save_state,path)\n",
    "\n",
    "cn_file_name = 'number_faces_predictor_regressor.tar'\n",
    "cn_save_path = save_path + cn_file_name\n",
    "print(cn_save_path)\n",
    "\n",
    "\n",
    "model_num_face_net = model_train(latent_xin_train,num_faces_out_trn,None,None,'new',model_num_face_net,100,5,'mse',True,use_cuda,True,cn_save_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### 2.4.1 testing the accuracy of this model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Setting up test set\n",
    "# -------------------\n",
    "\n",
    "xin_test = Variable(setup_image_tensor(xs_tst)).float()\n",
    "xin_test.size()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# CHECKING ACCURACY ON TEST SET\n",
    "# -----------------------------\n",
    "\n",
    "p,t,a = check_regression_accuracy(xin_test[0:5],model_ae,False,model_num_face_net,xn_tst[0:5],0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 2.5 setting up and training CNN number predictor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Setting up training data\n",
    "# ------------------------\n",
    "\n",
    "\n",
    "x_cnn_numpred_train = Variable(setup_image_tensor(xb_trn)).float()\n",
    "y_cnn_numpred_train = Variable(torch.from_numpy(xn_trn)).float()\n",
    "\n",
    "print(x_cnn_numpred_train.size())\n",
    "print(y_cnn_numpred_train.size())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Random checking training data\n",
    "# -----------------------------\n",
    "\n",
    "randrange = list(np.random.randint(xn_trn.shape[0], size=(1, 3))[0,:])\n",
    "\n",
    "\n",
    "for i in randrange:\n",
    "    print(xn_trn[i])\n",
    "    plt.imshow(xb_trn[i])\n",
    "    plt.show()\n",
    "    print('********************')\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# initialising network\n",
    "# --------------------\n",
    "\n",
    "try:\n",
    "    del model_cnn_num_pred\n",
    "    print('Old model deleted.')\n",
    "except:\n",
    "    pass\n",
    "model_cnn_num_pred = standard_cnn_6_layer(in_channels,True)\n",
    "model_cnn_num_pred.apply(weights_init)\n",
    "model_cnn_num_pred\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# training the model\n",
    "# ------------------\n",
    "\n",
    "''' USE -1 AS EPOCHS TO LOAD SAVED MODEL WITHOUT TRAINING '''\n",
    "\n",
    "# model_train(xin,yin,xval,yval,load_mode,model,epochs,mbsize,loss_mode,flatten,use_cuda,save_state,path)\n",
    "\n",
    "cn_file_name = 'standard_cnn_num_pred_6_layer_nonsoftmax_512.tar'\n",
    "cn_save_path = save_path + cn_file_name\n",
    "print(cn_save_path)\n",
    "\n",
    "\n",
    "model_cnn_num_pred = model_train(x_cnn_numpred_train,y_cnn_numpred_train,None,None,'from saved',model_cnn_num_pred,25,64,'mse',True,use_cuda,True,cn_save_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### 2.5.1 testing accuracy of the model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Setting up test set\n",
    "# -------------------\n",
    "\n",
    "xin_test = Variable(setup_image_tensor(xb_tst)).float()\n",
    "xin_test.size()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# CHECKING ACCURACY ON TEST SET\n",
    "# -----------------------------\n",
    "\n",
    "p,t,a = check_regression_accuracy(xin_test,None,True,model_cnn_num_pred,xn_tst,0.5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 2.6 Running face detection & number of faces predictor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# random sampling - ALWAYS USE TEST SET FOR THIS\n",
    "# ----------------------------------------------\n",
    "\n",
    "randrange = list(np.random.randint(xs_tst.shape[0], size=(1, 10))[0,:])\n",
    "\n",
    "\n",
    "if use_gray == True:\n",
    "    in_channels = 1\n",
    "    nx_trn_gray = rgb2gray(copy.deepcopy(xs_tst[randrange]))\n",
    "    nx_trn_gray = nx_trn_gray.reshape(nx_trn_gray.shape[0], nx_trn_gray.shape[1], nx_trn_gray.shape[2], 1)\n",
    "    nx_trn = Variable(setup_image_tensor(nx_trn_gray.astype('float'))).float()\n",
    "\n",
    "else:\n",
    "    nx_trn = Variable(setup_image_tensor(xs_tst[randrange])).float()\n",
    "    \n",
    "\n",
    "# getting numface prediction\n",
    "# --------------------------\n",
    "\n",
    "num_face_pred,_,_ = check_regression_accuracy(nx_trn,None,True,model_cnn_num_pred,xn_tst[randrange],0.75)\n",
    "\n",
    "\n",
    "# getting the output of model ae\n",
    "# ------------------------------\n",
    "n_output = model_ae.eval().cpu()((nx_trn/255).cpu())\n",
    "np_out = to_numpy_image(n_output.cpu().data)\n",
    "\n",
    "for i in range(np_out.shape[0]):\n",
    "    print(str(i))\n",
    "    print('Original - ')\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(xs_tst[randrange][i])\n",
    "    plt.show()\n",
    "    print('Output - ')\n",
    "    print('# faces predicted in this picture - ' + str(np.round(num_face_pred[i,0])))\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(np_out[i])\n",
    "    plt.show()\n",
    "    print('#####################################################')\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# reading images from local folder\n",
    "# --------------------------------\n",
    "\n",
    "in_folder = '/Users/venkateshmadhava/Desktop/test'\n",
    "x_local = create_dataset_from_folder_all(in_folder,new_h,new_w)\n",
    "x_local_trn = Variable(setup_image_tensor(x_local)).float()\n",
    "print(x_local_trn.size())\n",
    "\n",
    "\n",
    "# number of faces ops\n",
    "# -------------------\n",
    "latent_xlocal = chunk_pass(x_local_trn,model_ae,True,use_cuda,1)\n",
    "pred_out = chunk_pass(latent_xlocal,model_num_face_net,False,use_cuda,1)\n",
    "pred_out = pred_out.data.cpu().numpy()\n",
    "\n",
    "# forward pass ops\n",
    "# ----------------\n",
    "n_output = model_ae.eval().cpu()((x_local_trn/255).cpu())\n",
    "np_out = to_numpy_image(n_output.cpu().data)\n",
    "\n",
    "for i in range(np_out.shape[0]):\n",
    "    print(str(i))\n",
    "    print('Original - ')\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(x_local[i])\n",
    "    plt.show()\n",
    "    print('Output - ')\n",
    "    print('# faces predicted in this picture - ' + str(np.round(pred_out[i,0])))\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(np_out[i])\n",
    "    plt.show()\n",
    "    print('#####################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pmate2_env",
   "language": "python",
   "name": "pmate2_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
