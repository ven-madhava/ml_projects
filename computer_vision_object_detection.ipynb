{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "One shot multiple object detection using deep FCN\n",
    "-----------------------------------------------\n",
    "\n",
    "1. We will use a FCN to directly draw bounding boxes on detected faces\n",
    "2. We are not using cascaded CNN methods for now.\n",
    "3. We are using BDD/COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# -------\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import csv\n",
    "import cv2\n",
    "import h5py\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from scipy.ndimage import label\n",
    "from skimage import measure\n",
    "import json\n",
    "\n",
    "# torch related imports\n",
    "# ---------------------\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import save_image\n",
    "import torch.optim as optim\n",
    "\n",
    "# local settings\n",
    "# --------------\n",
    "import warnings\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    \n",
    "# storage related imports\n",
    "# -----------------------\n",
    "import tempfile\n",
    "from tempfile import TemporaryFile\n",
    "from google.cloud import storage\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = '/home/venkateshmadhava/datasets/ven-ml-project-387fdf3f596f.json'\n",
    "\n",
    "%matplotlib inline\n",
    "%env JOBLIB_TEMP_FOLDER=/tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting file from google cloud storage\n",
    "# ---------------------------------------\n",
    "\n",
    "def get_file_from_google_storage(file_name):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    1. takes an input google cloud storage file name\n",
    "    2. downloads to temp file\n",
    "    3. returns local temp file path\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 0. initialising bucket\n",
    "    # ----------------------\n",
    "    print('0. initialising bucket..')\n",
    "    bucket_name = 'gpu_datatset_bucket'\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    \n",
    "    # 1. retrieveing blob\n",
    "    # -------------------\n",
    "    print('1. retrieving blob..')\n",
    "    blob = bucket.blob(file_name)\n",
    "    \n",
    "    # 2. downloading blob to temp file\n",
    "    # --------------------------------\n",
    "    print('2. downloading blob to temp file, this may take a while..')\n",
    "    with tempfile.NamedTemporaryFile(mode='w', delete=False) as gcs_tempfile:\n",
    "        blob.download_to_filename(gcs_tempfile.name)\n",
    "        \n",
    "    # 3. final return\n",
    "    # ---------------\n",
    "    print('Done.')\n",
    "    return gcs_tempfile.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pool function to create a dataset from input folder\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def create_dataset_from_folder_all(infolder,n_h,n_w):\n",
    "    \n",
    "    # 0. initialisations\n",
    "    # ------------------\n",
    "    image_list = [f for f in listdir(infolder) if isfile(join(infolder, f)) and '.jpg' in f.lower()]\n",
    "    assert len(image_list) > 0, 'No images found in the folder'\n",
    "    xout = np.zeros((len(image_list),n_h,n_w,3), dtype='uint8')\n",
    "    \n",
    "    # 1. building args\n",
    "    # ----------------\n",
    "    all_args = []\n",
    "    for i in range(xout.shape[0]):\n",
    "        all_args.append((i,xout,infolder,image_list,n_h,n_w))\n",
    "    \n",
    "    # 2. calling resize function across multiprocessing pool\n",
    "    # ------------------------------------------------------\n",
    "    pool = ThreadPool(5)\n",
    "    pool.starmap(create_dataset_from_folder_single, all_args)\n",
    "    print('Done creating a dataset with ' + str(xout.shape[0]) + ' images.')\n",
    "    \n",
    "    return xout\n",
    "\n",
    "    \n",
    "# FUNCTION 2\n",
    "# GENERIC FUNCTION - to resize a single image\n",
    "# ------------------------------------------\n",
    "def create_dataset_from_folder_single(i,xout,infolder,image_list,n_h,n_w):\n",
    "    \n",
    "    # snippet\n",
    "    # -------\n",
    "    name = image_list[i]\n",
    "    img = cv2.imread(join(infolder, name))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (n_w,n_h))\n",
    "    xout[i] = img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pool function to resize images\n",
    "# ------------------------------\n",
    "\n",
    "def resize_all(ximgs,n_h,n_w):\n",
    "    \n",
    "    # 0. initialisations\n",
    "    # ------------------\n",
    "    c = ximgs.shape[3]\n",
    "    x_images_resized = np.zeros((ximgs.shape[0],new_h,new_w,c), dtype='uint8')\n",
    "    \n",
    "    # 1. building args\n",
    "    # ----------------\n",
    "    all_args = []\n",
    "    for i in range(ximgs.shape[0]):\n",
    "        all_args.append((i,ximgs,x_images_resized,n_h,n_w))\n",
    "    \n",
    "    # 2. calling resize function across multiprocessing pool\n",
    "    # ------------------------------------------------------\n",
    "    pool = ThreadPool(5)\n",
    "    pool.starmap(resize_image_single, all_args)\n",
    "    print('Done resizing ' + str(ximgs.shape[0]) + ' images.')\n",
    "    \n",
    "    return x_images_resized\n",
    "\n",
    "    \n",
    "# FUNCTION 2\n",
    "# GENERIC FUNCTION - to resize a single image\n",
    "# ------------------------------------------\n",
    "def resize_image_single(i,x_in,x_out,new_h,new_w):\n",
    "    \n",
    "    # simple code\n",
    "    # -----------\n",
    "    img = x_in[i]\n",
    "    img = cv2.resize(img, (new_w,new_h))\n",
    "    x_out[i] = img\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLE FUNTION TO CONVERT RGB TO GRAYSCALE\n",
    "# -------------------------------------------\n",
    "def rgb2gray(x):\n",
    "    \n",
    "\n",
    "    x[:,:,:,0] = x[:,:,:,0] * 0.2989\n",
    "    x[:,:,:,1] = x[:,:,:,0] * 0.5870\n",
    "    x[:,:,:,2] = x[:,:,:,0] * 0.1140\n",
    "    xout = np.sum(x,axis = 3)\n",
    "    \n",
    "\n",
    "    #r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    #gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "\n",
    "    return xout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to set all cats list\n",
    "# -----------------------------\n",
    "\n",
    "''' THIS HAS TO BE CONSISTENT BETWEEN TRAIN, VAL AND TEST SETS '''\n",
    "\n",
    "def build_class_list(jsonin_url):\n",
    "    \n",
    "    \n",
    "    # 0. initialisations\n",
    "    # ------------------\n",
    "    all_classes = []    \n",
    "    \n",
    "    \n",
    "    # 1. import JSON file and load it - loads into a list of dicts! easy to parse\n",
    "    # ---------------------------------------------------------------------------\n",
    "    print('1. loading jsons..')\n",
    "    with open(jsonin_url) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # sanity print\n",
    "    ##\n",
    "    print('2. total jsons loaded: ' + str(len(data)))\n",
    "    \n",
    "\n",
    "    # 2. looping\n",
    "    # ----------\n",
    "    print('3. looping and build classes set..')\n",
    "    for each in data:\n",
    "        for each_l in each['labels']:\n",
    "            if 'box2d' in each_l.keys():\n",
    "                all_classes.append(each_l['category'])\n",
    "\n",
    "\n",
    "    # 3. creating a set of categories\n",
    "    # --------------------------------\n",
    "    all_cats = list(set(all_classes))\n",
    "    print('4. there are ' + str(len(all_cats)) + ' classes of objects in this dataset with bounding box - \\n*****')\n",
    "    print(all_cats)\n",
    "    del data\n",
    "    \n",
    "    # 4. final return\n",
    "    # ---------------\n",
    "    return all_cats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function that returns dict for building h5 dataset\n",
    "# -------------------------------------------------------\n",
    "\n",
    "def build_datasets(all_classes,jsonin_url,img_folder_in,n_h,n_w):\n",
    "    \n",
    "    # 0. initialisations\n",
    "    # ------------------\n",
    "    global img_folder\n",
    "    img_folder = img_folder_in\n",
    "    global json_dict\n",
    "    json_dict = {}\n",
    "    no_classes = len(all_classes)\n",
    "    counter = 0\n",
    "    cutoff = 7500\n",
    "    \n",
    "    # 1. importing json\n",
    "    # -----------------\n",
    "    print('1. loading jsons..')\n",
    "    with open(jsonin_url) as f:\n",
    "        data = json.load(f)\n",
    "    print('2. total jsons loaded: ' + str(len(data)))\n",
    "    \n",
    "    \n",
    "    # 2. parsing json into a custom dict\n",
    "    # ----------------------------------\n",
    "    print('3. building custom dict for easy parsing..')\n",
    "    for each in data:\n",
    "        boxflag = 0\n",
    "        for each_l in each['labels']:\n",
    "            if 'box2d' in each_l.keys():\n",
    "                boxflag = 1\n",
    "\n",
    "        # creating new json_dict\n",
    "        # ----------------------\n",
    "        if boxflag == 1:\n",
    "            json_dict[each['name']] = each\n",
    "    \n",
    "    # 2.1 deleting data\n",
    "    # -----------------\n",
    "    del data\n",
    "    \n",
    "    # 3. getting list of images and filtering them\n",
    "    # --------------------------------------------\n",
    "    img_list_all = [imgs for imgs in os.listdir(img_folder) if '.jpg' in imgs.lower()]\n",
    "    \n",
    "    \n",
    "    # 4. setting up global variables to use with pool function\n",
    "    # --------------------------------------------------------\n",
    "    global img_list\n",
    "    img_list = [imgs for imgs in img_list_all if imgs in list(json_dict.keys())]\n",
    "    m = len(img_list)\n",
    "    \n",
    "    global x_source\n",
    "    x_source = np.zeros((m,n_h,n_w,3), dtype = 'uint8')\n",
    "    \n",
    "    global x_target\n",
    "    x_target = np.zeros((m,n_h,n_w,len(all_classes)), dtype = 'uint8')\n",
    "    \n",
    "    global new_h\n",
    "    new_h = n_h\n",
    "    \n",
    "    global new_w\n",
    "    new_w = n_w\n",
    "    \n",
    "    global gb_all_classes\n",
    "    gb_all_classes = all_classes\n",
    "    \n",
    "    \n",
    "    # 5. start of threaded function\n",
    "    # -----------------------------\n",
    "    print('4. starting threading function..')\n",
    "    pool = ThreadPool(5)\n",
    "    pool.map(build_datasets_single, list(range(len(img_list))))\n",
    "    print('Done with ' + str(x_source.shape[0]) + ' images. Access them at global x_source amd x_target.')\n",
    "    \n",
    "    \n",
    "    \n",
    "# a single function for the above\n",
    "# -------------------------------\n",
    "    \n",
    "def build_datasets_single(i):\n",
    "    \n",
    "    # 0. getting all global variables\n",
    "    # -------------------------------\n",
    "    global img_list\n",
    "    global x_source\n",
    "    global x_target\n",
    "    global new_h\n",
    "    global new_w\n",
    "    global gb_all_classes\n",
    "    global json_dict\n",
    "    global img_folder\n",
    "    \n",
    "    \n",
    "    # 1. local initialisations\n",
    "    # -------------------------\n",
    "    imgname = img_list[i]\n",
    "    \n",
    "    # 2. main ops\n",
    "    # -----------\n",
    "    img = cv2.imread(join(img_folder, imgname))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # initialising target image for each individual image since each image is of different size\n",
    "    # -----------------------------------------------------------------------------------------\n",
    "    h,w,_ = img.shape\n",
    "    curr_target = (np.ones((h,w,len(gb_all_classes)))*255).astype('uint8')/255\n",
    "\n",
    "    # setting 0 in the target channel\n",
    "    # -------------------------------\n",
    "    for each_label in json_dict[imgname]['labels']:\n",
    "\n",
    "        if 'box2d' in each_label.keys():\n",
    "\n",
    "            # getting box co-ordinates\n",
    "            # ------------------------\n",
    "            curr_cat = each_label['category']\n",
    "            curr_index = gb_all_classes.index(curr_cat)\n",
    "            curr_x1 = int(each_label['box2d']['x1'])\n",
    "            curr_x2 = int(each_label['box2d']['x2'])\n",
    "            curr_y1 = int(each_label['box2d']['y1'])\n",
    "            curr_y2 = int(each_label['box2d']['y2'])\n",
    "\n",
    "            # setting target channel\n",
    "            # ----------------------\n",
    "            curr_target[curr_y1:curr_y2,curr_x1:curr_x2,curr_index] = 0\n",
    "\n",
    "    # resizing images before saving to dict\n",
    "    # -------------------------------------\n",
    "    img = cv2.resize(img, (new_w,new_h))\n",
    "    curr_target = cv2.resize(curr_target, (new_w,new_h))\n",
    "\n",
    "    # some correction\n",
    "    # ---------------\n",
    "    curr_target[curr_target < 0.75] = 0\n",
    "    curr_target[curr_target >= 0.75] = 1\n",
    "\n",
    "    # reshaping\n",
    "    # ---------\n",
    "    x_source[i] = img\n",
    "    x_target[i] = curr_target\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COCO dataset build functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# need a way to create datasets from input dict after resizing\n",
    "###\n",
    "\n",
    "def create_single_dataset_from_indict(d,n_h,n_w):\n",
    "    \n",
    "    ''' creates a numpy dataset from dict where dict[key] = img '''\n",
    "    \n",
    "    # 0. initialisations\n",
    "    # ------------------\n",
    "    m = len(d)\n",
    "    keys_list = list(d.keys())\n",
    "    c = d[list(d.keys())[0]].shape[2]\n",
    "    xout = np.zeros((m,n_h,n_w,c), dtype = 'uint8')\n",
    "    \n",
    "    # 1. using a standard for loop\n",
    "    # ----------------------------\n",
    "    for i in range(m):\n",
    "        \n",
    "        # resize ops\n",
    "        # ----------\n",
    "        xout[i] = cv2.resize(d[keys_list[i]], (n_w,n_h))\n",
    "        print('Done with image ' + str(i+1) + ' of around ' + str(m) + '..', end = '\\r')\n",
    "    \n",
    "    \n",
    "    # 2. final return\n",
    "    # ---------------\n",
    "    return xout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific function to list cats\n",
    "# ------------------------------\n",
    "\n",
    "def run_stats_coco(data):\n",
    "    \n",
    "    # 0. initialisations\n",
    "    # ------------------\n",
    "    d = {}\n",
    "    super_d = {}\n",
    "    super_d_list = {}\n",
    "    cats = {}\n",
    "    sorted_list = []\n",
    "    sorted_super_d_list = []\n",
    "    \n",
    "    # 1.0 build simple cats dict\n",
    "    # --------------------------\n",
    "    for each in data['categories']:\n",
    "        cats[each['id']] = each['name']\n",
    "        try:\n",
    "            super_d[each['supercategory']].append(each['id'])\n",
    "        except:\n",
    "            super_d[each['supercategory']] = []\n",
    "            super_d[each['supercategory']].append(each['id'])\n",
    "    \n",
    "    \n",
    "    # 1. looping thru data annotations\n",
    "    # --------------------------------\n",
    "    for each in data['annotations']:\n",
    "        \n",
    "        # super cat wise count\n",
    "        # --------------------\n",
    "        for keys in super_d:\n",
    "            if each['category_id'] in super_d[keys]:\n",
    "                try:\n",
    "                    super_d_list[keys].append(each['image_id'])\n",
    "                except:\n",
    "                    super_d_list[keys] = []\n",
    "                    super_d_list[keys].append(each['image_id'])\n",
    "                \n",
    "                # a final correction\n",
    "                # ------------------\n",
    "                super_d_list[keys] = list(set(super_d_list[keys]))\n",
    "                \n",
    "            \n",
    "        # cat wise count\n",
    "        # --------------\n",
    "        try:\n",
    "            d[each['category_id']].append(each['image_id'])\n",
    "            \n",
    "        except:\n",
    "            d[each['category_id']] = []\n",
    "            d[each['category_id']].append(each['image_id'])\n",
    "        \n",
    "        # final correcttion\n",
    "        # -----------------\n",
    "        d[each['category_id']] = list(set(d[each['category_id']]))\n",
    "            \n",
    "        \n",
    "    \n",
    "    # 2. for printing results\n",
    "    # -----------------------\n",
    "    for keys in d:\n",
    "        sorted_list.append((len(d[keys]),cats[keys]))\n",
    "        \n",
    "    for keys in super_d_list:\n",
    "        sorted_super_d_list.append((len(super_d_list[keys]), keys))\n",
    "    \n",
    "    \n",
    "    # 3. final prints\n",
    "    # ---------------\n",
    "    print('Printing cat wise count:')\n",
    "    sorted_list.sort()\n",
    "    for each in list(reversed(sorted_list)):\n",
    "        print(each)\n",
    "        \n",
    "    print('\\n\\nPrinting super cat wise count:')\n",
    "    sorted_super_d_list.sort()\n",
    "    for each in list(reversed(sorted_super_d_list)):\n",
    "        print(each)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO training set creation\n",
    "##\n",
    "\n",
    "def build_coco_dataset_all(json_url, img_folder, mode, interested_cats):\n",
    "    \n",
    "    ''' \n",
    "    \n",
    "    1. this function requires the interested categories to be provided by the user\n",
    "    \n",
    "    2. default interested cats that can be used - \n",
    "    ['person','chair','car','dining table','cup','bottle','bowl']\n",
    "    \n",
    "    3. default interested super cats that can be used - \n",
    "    ['person','furniture','vehicle','animal','food','electronic']\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 0. loading json\n",
    "    # ---------------\n",
    "    with open(json_url) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # 0.1 initialisations\n",
    "    # -------------------\n",
    "    no_cats = len(interested_cats)\n",
    "    xcoco_src_dict = {}\n",
    "    xcoco_tgt_dict = {}\n",
    "    img_list_all = [imgs for imgs in os.listdir(img_folder) if '.jpg' in imgs.lower()]\n",
    "    cats_dict = {}\n",
    "    super_d = {}\n",
    "    \n",
    "    # 0.2 setting up cats and super cat dict\n",
    "    # --------------------------------------\n",
    "    for each in data['categories']:\n",
    "        cats_dict[each['id']] = each['name']\n",
    "        \n",
    "        try:\n",
    "            super_d[each['supercategory']].append(each['id'])\n",
    "        except:\n",
    "            super_d[each['supercategory']] = []\n",
    "            super_d[each['supercategory']].append(each['id'])\n",
    "        \n",
    "        \n",
    "    # 1. main for loop\n",
    "    # ----------------\n",
    "    for i in range(len(data['annotations'])):\n",
    "        \n",
    "        print('At annotation ' + str(i+1) + ' of around ' + str(len(data['annotations'])) + '...', end='\\r')\n",
    "\n",
    "        # other initialisations\n",
    "        # ---------------------\n",
    "        curr_name = str(data['annotations'][i]['image_id'])\n",
    "        if mode == 'cats':\n",
    "            \n",
    "            # mode is cats\n",
    "            # ------------\n",
    "            curr_cat_name = cats_dict[data['annotations'][i]['category_id']]\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # mode is super cats\n",
    "            # ------------------\n",
    "            for keys in super_d:\n",
    "                if data['annotations'][i]['category_id'] in super_d[keys]:\n",
    "                    curr_cat_name = keys\n",
    "                    break\n",
    "\n",
    "        # 1. main check point\n",
    "        # -------------------\n",
    "        if curr_cat_name in interested_cats:\n",
    "\n",
    "            # setting current channel\n",
    "            # -----------------------\n",
    "            curr_channel = interested_cats.index(curr_cat_name)\n",
    "\n",
    "            # setting local variables\n",
    "            # -----------------------\n",
    "            curr_w1 = int(data['annotations'][i]['bbox'][0])\n",
    "            curr_h1 = int(data['annotations'][i]['bbox'][1])\n",
    "\n",
    "            curr_w2 = curr_w1 + int(data['annotations'][i]['bbox'][2])\n",
    "            curr_h2 = curr_h1 + int(data['annotations'][i]['bbox'][3])\n",
    "\n",
    "            # 1.1 main ops - setting initial images\n",
    "            # ------------------------------------\n",
    "            if curr_name in xcoco_src_dict.keys():\n",
    "\n",
    "                # setting target channel in the if clause\n",
    "                # ---------------------------------------\n",
    "                xcoco_tgt_dict[curr_name][curr_h1:curr_h2,curr_w1:curr_w2,curr_channel] = 0\n",
    "\n",
    "            else:\n",
    "\n",
    "                # need to create src and tgt images\n",
    "                # ---------------------------------\n",
    "                temp_imgname = [each_x for each_x in img_list_all if curr_name in each_x]\n",
    "\n",
    "                if len(temp_imgname) == 1:\n",
    "\n",
    "                    # processing only if one image from the folder matches with current annotation\n",
    "                    # ----------------------------------------------------------------------------\n",
    "                    img = cv2.imread(join(img_folder, temp_imgname[0]))\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    xcoco_src_dict[curr_name] = img\n",
    "\n",
    "                    # initialising curr target\n",
    "                    # ------------------------\n",
    "                    h,w,_ = img.shape\n",
    "                    curr_target = (np.ones((h,w,no_cats))*255).astype('uint8')/255\n",
    "                    curr_target[curr_h1:curr_h2,curr_w1:curr_w2,curr_channel] = 0\n",
    "                    xcoco_tgt_dict[curr_name] = curr_target\n",
    "\n",
    "    \n",
    "    # final return\n",
    "    # ------------\n",
    "    return xcoco_src_dict,xcoco_tgt_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN related code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check accuracy on regression model\n",
    "# ----------------------------------------------\n",
    "\n",
    "def check_regression_accuracy(x_in,model_ae,direct_mode,model_num_face_net,y_target_in,proximity_percent):\n",
    "    \n",
    "    # 0. Some initialisations\n",
    "    # -----------------------\n",
    "    if direct_mode == False:\n",
    "        latent_xin = chunk_pass(x_in,model_ae,True,use_cuda,1)\n",
    "        pred_xin = chunk_pass(latent_xin,model_num_face_net,False,use_cuda,1)\n",
    "        y_out_np = pred_xin.data.cpu().numpy()\n",
    "    else:\n",
    "        pred_xin = chunk_pass(x_in,model_num_face_net,False,use_cuda,1)\n",
    "        y_out_np = pred_xin.data.cpu().numpy()\n",
    "        \n",
    "    y_target_np = y_target_in.reshape(y_out_np.shape)\n",
    "    \n",
    "    # 1. similarity ops\n",
    "    # -----------------\n",
    "    similarity = np.minimum(y_out_np,y_target_np)/np.maximum(y_out_np,y_target_np)\n",
    "    sim_thresheld = (similarity >= proximity_percent).astype('int')\n",
    "    total_got_right = np.sum(sim_thresheld)\n",
    "    avg_distance = np.sum(sim_thresheld*similarity)/total_got_right\n",
    "    percent_got_right = round((total_got_right/x_in.size()[0])*100,2)\n",
    "    \n",
    "    # info print\n",
    "    # ----------\n",
    "    print('The accuracy for given distance threshold is ' + str(percent_got_right) + ' %.')\n",
    "    \n",
    "    # 2. final return\n",
    "    # ---------------\n",
    "    return y_out_np, total_got_right, avg_distance\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple function to generate output from latent\n",
    "# ------------------------------------------------\n",
    "\n",
    "def generate_output(xin,model,start_ind,end_ind,print_images,use_cuda):\n",
    "    \n",
    "    \n",
    "    # 1. generating output\n",
    "    # --------------------\n",
    "    xout = chunk_pass(xin[start_ind:end_ind],model.eval(),False,use_cuda,1)\n",
    "    \n",
    "    # images dataset\n",
    "    # --------------\n",
    "    xout_gen = to_numpy_image(xout.cpu().data)#.astype('uint8')\n",
    "    xout_orig = to_numpy_image(xin[start_ind:end_ind].cpu().data).astype('uint8')\n",
    "        \n",
    " \n",
    "    # 4. priniting images\n",
    "    # -------------------\n",
    "    if print_images == True:\n",
    "        for i in range(xout_orig.shape[0]):\n",
    "            print('Example ' + str(i) + '..')\n",
    "            print('----------------------')\n",
    "            print('Original - ')\n",
    "            plt.figure(figsize=(5,5))\n",
    "            plt.imshow(xout_orig[i])\n",
    "            plt.show()\n",
    "            print('Generated - ')\n",
    "            plt.figure(figsize=(5,5))\n",
    "            plt.imshow(xout_gen[i])\n",
    "            plt.show()\n",
    "            print('\\n----------------\\n')\n",
    "    \n",
    "    # returns\n",
    "    # -------\n",
    "    return xout_orig, xout_gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super helpful chunker function that returns seq chunks correctly sized even at ends\n",
    "# -----------------------------------------------------------------------------------\n",
    "# GENERIC function to calculate conv outsize\n",
    "# ------------------------------------------\n",
    "def outsize_conv(n_H,n_W,f,s,pad):\n",
    "    \n",
    "    h = ((n_H - f + (2*pad))/s) + 1\n",
    "    w = ((n_W - f + (2*pad))/s) + 1\n",
    "    return h,w\n",
    "    \n",
    "    \n",
    "# GENERIC function to calculate upconv outsize\n",
    "# --------------------------------------------    \n",
    "def outsize_upconv(h,w,f,s,p):\n",
    "    hout = (h-1)*s - 2*p + f\n",
    "    wout = (w-1)*s - 2*p + f\n",
    "    return hout, wout\n",
    "\n",
    "\n",
    "\n",
    "def chunker(seq, size):\n",
    "    \n",
    "    # from http://stackoverflow.com/a/434328\n",
    "    # not touch this code\n",
    "    # -------------------\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "\n",
    "\n",
    "# GENERIC - initialises weights for a NN\n",
    "# --------------------------------------\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "    #    print(classname)\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    #elif classname.find('Linear') != -1:\n",
    "    #    print(classname)\n",
    "    #    m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "        \n",
    "        \n",
    "# GENERIC - change an torch image to numoy image\n",
    "# ----------------------------------------------\n",
    "def to_numpy_image(xin):\n",
    "    \n",
    "    try:\n",
    "        xin = xin.data.numpy()\n",
    "    except:\n",
    "        xin = xin.numpy()\n",
    "    \n",
    "    \n",
    "    xout = np.swapaxes(xin,1,2)\n",
    "    xout = np.swapaxes(xout,2,3)\n",
    "    \n",
    "    # returns axes swapped numpy images\n",
    "    # ---------------------------------\n",
    "    return xout       \n",
    "\n",
    "\n",
    "\n",
    "# GENERIC - converts numpy images to torch tensors for training\n",
    "# -------------------------------------------------------------\n",
    "def setup_image_tensor(xin):\n",
    "    xout = np.swapaxes(xin,1,3)\n",
    "    xout = np.swapaxes(xout,2,3)\n",
    "    \n",
    "    # returns axes swapped torch tensor\n",
    "    # ---------------------------------\n",
    "    xout = torch.from_numpy(xout)\n",
    "    return xout.float()\n",
    "\n",
    "\n",
    "# A functino to get linemarkings\n",
    "# -------------------------------\n",
    "\n",
    "def get_ae_output_image(x,net,use_cuda):\n",
    "    \n",
    "    # 0. Setting up input as torch\n",
    "    # ----------------------------\n",
    "    x_t = Variable(setup_image_tensor(x)).float()\n",
    "        \n",
    "        \n",
    "    # 1. Using chunk pass to get linemarkings\n",
    "    # ----------------------------------------\n",
    "    xout = chunk_pass(x_t,net.eval(),False,use_cuda,1)\n",
    "    xout = to_numpy_image(xout.cpu().data)\n",
    "    xout = (xout * 255).astype('uint8')\n",
    "    \n",
    "    # 2. final return\n",
    "    # ---------------\n",
    "    return xout\n",
    "    \n",
    "    \n",
    "# GENERIC class that inherits nn module and makes a sequential object a model\n",
    "# ---------------------------------------------------------------------------\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,sequencelist):\n",
    "        super().__init__() # Initializing nn.Module construtors\n",
    "        self.forwardpass = sequencelist\n",
    "        \n",
    "    def forward(self,x):\n",
    "        xout = self.forwardpass(x)\n",
    "        return xout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build a lineaf FC model\n",
    "# -----------------------------------\n",
    "\n",
    "def linear_fc(layers, nw_activations, target_activation, dropout_p):\n",
    "    \n",
    "    'The first value in the layers list is the input dimensions of the input'\n",
    "    \n",
    "    # 0. initialisations\n",
    "    # ------------------\n",
    "    seq_list = []\n",
    "    \n",
    "    # setting N/W activations\n",
    "    # -------------------\n",
    "    if nw_activations == 'relu':\n",
    "        nw_act = nn.ReLU()\n",
    "    elif nw_activations == 'lrelu':\n",
    "        nw_act = nn.LeakyReLU(0.2)\n",
    "    elif nw_activations == 'sigmoid':\n",
    "        nw_act = nn.Sigmoid()\n",
    "    elif nw_activations == 'tanh':\n",
    "        nw_act = nn.Tanh()\n",
    "    else:\n",
    "        nw_act = nn.ReLU()\n",
    "    \n",
    "    # setting target activations\n",
    "    # --------------------------\n",
    "    if target_activation == 'sigmoid':\n",
    "        target_act = nn.Sigmoid()\n",
    "    elif target_activation == 'softmax':\n",
    "        target_act = nn.Softmax()\n",
    "    else:\n",
    "        target_act = None\n",
    "    \n",
    "    # 1. building n/w's layer list\n",
    "    # ----------------------------\n",
    "    network = []\n",
    "    for k in range(len(layers)):\n",
    "        try:\n",
    "            network.append((layers[k],layers[k+1]))\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "\n",
    "    \n",
    "    # 2. constructing encoder n/w\n",
    "    # ----------------------------\n",
    "    for i in range(len(network)):\n",
    "        \n",
    "        # 2.1 adding linear layers to encoder\n",
    "        # ------------------------------------\n",
    "        curr_dims = network[i]\n",
    "        seq_mod = nn.Linear(curr_dims[0],curr_dims[1])\n",
    "        seq_list.append(seq_mod)\n",
    "        \n",
    "        # checking last layer or not\n",
    "        # --------------------------\n",
    "        if i+1 == len(network):\n",
    "            \n",
    "            # at last layer\n",
    "            # -------------\n",
    "            if target_act == None:\n",
    "                pass\n",
    "            else:\n",
    "                seq_list.append(target_act)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # batchnorm\n",
    "            # ---------\n",
    "            seq_list.append(nn.BatchNorm1d(curr_dims[1]))\n",
    "          \n",
    "            # non linear activation\n",
    "            # ---------------------\n",
    "            seq_list.append(nw_act)\n",
    "            \n",
    "            # dropout\n",
    "            # -------\n",
    "            seq_list.append(nn.Dropout(p = dropout_p))\n",
    "           \n",
    "            \n",
    "    \n",
    "    # 3. returning model\n",
    "    # ------------------\n",
    "    seq_list = nn.Sequential(*seq_list)\n",
    "    seq_list.apply(weights_init)\n",
    "\n",
    "    model = Net(seq_list)\n",
    "    model = model.train()\n",
    "    \n",
    "    return model\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERIC model function to train the networks\n",
    "# --------------------------------------------\n",
    "\n",
    "def model_train(xin,yin,xval,yval,load_mode,model,epochs,mbsize,loss_mode,use_cuda,save_state,path):\n",
    "    \n",
    "    # 0. initialisations\n",
    "    # ------------------\n",
    "    loss_train = []\n",
    "    loss_val = []\n",
    "    norm_flag = 0\n",
    "\n",
    "    \n",
    "\n",
    "    # normalising input to 0-1 while making sure this is an image\n",
    "    # -----------------------------------------------------------\n",
    "    if len(xin.size()) > 3:\n",
    "            \n",
    "        # if the input and output are images - try will go through with the statement\n",
    "        # ----------------------------------------------------------------------------\n",
    "        if len(xin.size()) > 3 and len(yin.size()) > 3:\n",
    "\n",
    "            assert torch.mean(xin).item() > 1 and torch.mean(yin).item() > 1, 'Input data is already in range 0-1. Not consistent with flow.'\n",
    "            \n",
    "\n",
    "            # both need to be normalised\n",
    "            # --------------------------\n",
    "            #xin = xin/255\n",
    "            #yin = yin/255\n",
    "            norm_flag = 1\n",
    "            print('Input and Output dataset will be normalised to 0-1')\n",
    "\n",
    "        \n",
    "        # incase input and output both are NOT images\n",
    "        # -------------------------------------------\n",
    "        else:\n",
    "\n",
    "            assert torch.mean(xin).item() > 1, 'Input data is already in range 0-1. Not consistent with flow.'\n",
    "\n",
    "            # normalising input\n",
    "            # -----------------\n",
    "            #xin = xin/255\n",
    "            norm_flag = 2\n",
    "            print('Input dataset will be normalised to 0-1')\n",
    "            \n",
    "            \n",
    "    \n",
    "    # ensuring xval and yval are None\n",
    "    # -------------------------------\n",
    "    assert xval == None and yval == None, 'xval and yval provided, but there is no code to normalise'\n",
    "    \n",
    "    \n",
    "    if load_mode == 'from saved':\n",
    "        \n",
    "        # loading from saved\n",
    "        # ------------------\n",
    "        model,optimizer,saved_epoch,saved_loss,saved_loss_mode = load_saved_model_function(path,use_cuda)\n",
    "        model = model.train()\n",
    "        loss_mode = saved_loss_mode\n",
    "        print('Loading model from saved state...')\n",
    "        print('Last saved loss - ' + str(saved_loss))\n",
    "        print('Last saved epoch - ' + str(saved_epoch))\n",
    "        epochs += int(saved_epoch)\n",
    "        start_epoch = int(saved_epoch)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # building new\n",
    "        # ------------\n",
    "        start_epoch = 1\n",
    "        model = model.train()\n",
    "        optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad,model.parameters()))\n",
    "        #optimizer = torch.optim.Adadelta(filter(lambda p: p.requires_grad,model.parameters()))\n",
    "        #optimizer = torch.optim.RMSprop(filter(lambda p: p.requires_grad,model.parameters()))\n",
    "        #optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad,model.parameters()), lr=0.1, momentum=0.9)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    # model set up as per cuda\n",
    "    # ------------------------\n",
    "    if use_cuda == True:\n",
    "        torch.cuda.empty_cache()\n",
    "        model = model.cuda()        \n",
    "    \n",
    "    \n",
    "    # setting loss criterion\n",
    "    # ----------------------\n",
    "    if loss_mode == 'MSE':\n",
    "        criterion = nn.MSELoss()\n",
    "    elif loss_mode == 'BCE':\n",
    "        criterion = nn.BCELoss()\n",
    "    elif loss_mode == 'NLL':\n",
    "        criterion = nn.NLLLoss()\n",
    "    elif loss_mode == 'crossentropy':\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        yin = torch.max(yin.long(),1)[1]\n",
    "    else:\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "    \n",
    "    # 1. Setting up minibatch features\n",
    "    # --------------------------------\n",
    "    m = xin.size()[0]\n",
    "    mb_list = []\n",
    "    mb_list = list(range(int(m/mbsize)))\n",
    "    if m % mbsize == 0: # if the minibatches can be split up perfectly.\n",
    "        'do nothing'\n",
    "    else:\n",
    "        mb_list.append(mb_list[len(mb_list)-1] + 1)\n",
    "        \n",
    "    # 2. Actual iters\n",
    "    # ----------------\n",
    "    for i in range(start_epoch,epochs+1):\n",
    "            \n",
    "        for p in mb_list:\n",
    "            \n",
    "            # Mini batch operations\n",
    "            # ---------------------\n",
    "            start_index = p*mbsize\n",
    "            end_index = m if p == mb_list[len(mb_list)-1] else p*mbsize + mbsize\n",
    "            m_curr = end_index - start_index\n",
    "            \n",
    "            Xin_mb = xin[start_index:end_index]\n",
    "            Yin_mb = yin[start_index:end_index]\n",
    "            \n",
    "            if use_cuda == True:\n",
    "                Xin_mb = Xin_mb.cuda()\n",
    "                Yin_mb = Yin_mb.cuda()\n",
    "                \n",
    "            # normalising ops\n",
    "            # --------------\n",
    "            if norm_flag == 1:\n",
    "                \n",
    "                # normalise both input and target\n",
    "                # -------------------------------\n",
    "                Xin_mb = copy.deepcopy(Xin_mb)/255\n",
    "                Yin_mb = copy.deepcopy(Yin_mb)/255\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                # normalise only input\n",
    "                # --------------------\n",
    "                Xin_mb = copy.deepcopy(Xin_mb)/255\n",
    "                \n",
    "                \n",
    "            # Network ops\n",
    "            # -----------\n",
    "            model_out = model(Xin_mb)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model_out, Yin_mb) # loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train.append(loss.item())\n",
    "            \n",
    "            # deleting curr variables\n",
    "            # -----------------------\n",
    "            if use_cuda == True:\n",
    "                Xin_mb = Xin_mb.cpu()\n",
    "                Yin_mb = Yin_mb.cpu()\n",
    "                model_out = model_out.cpu()\n",
    "                \n",
    "                del Xin_mb\n",
    "                del Yin_mb\n",
    "                del model_out\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            # printing loss\n",
    "            # -------------\n",
    "            print('Epoch ' + str(i) + ', minibatch ' + str(p+1) + ' of '  +  str(len(mb_list)) + ' -- Model loss: ' + str(loss.item()))\n",
    "            \n",
    "\n",
    "    # 3. outside for loop saving model state\n",
    "    # --------------------------------------\n",
    "    if save_state == True and epochs+1 > start_epoch:\n",
    "        \n",
    "        # 3.1 initialising save dict\n",
    "        # --------------------------\n",
    "        save_dict = {}\n",
    "        save_dict['epoch'] = str(i)\n",
    "        save_dict['model_state_dict'] = model.cpu().state_dict()\n",
    "        save_dict['optimizer_state_dict'] = optimizer.state_dict()\n",
    "        save_dict['loss'] = str(loss.cpu().item())\n",
    "        save_dict['loss_mode'] = loss_mode\n",
    "        \n",
    "        \n",
    "        # 3.2 saving\n",
    "        # ----------\n",
    "        torch.save(save_dict,path)\n",
    "        \n",
    "        # saving full model to initialise a new model later on\n",
    "        # ----------------------------------------------------\n",
    "        torch.save(model.cpu(),path.replace('.tar','_MODEL.tar'))\n",
    "        \n",
    "        print('Saved.')\n",
    "        \n",
    "    \n",
    "    # 4. return model in order to use elsewhere in the code\n",
    "    # -----------------------------------------------------\n",
    "    return model\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to load a saved model\n",
    "# --------------------------------\n",
    "\n",
    "def load_saved_model_function(path, use_cuda):\n",
    "    \n",
    "    \n",
    "    ''' path = /folder1/folder2/model_ae.tar format'''\n",
    "    \n",
    "    # 1. loading full model\n",
    "    # ---------------------\n",
    "    model = torch.load(path.replace('.tar','_MODEL.tar'))\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad,model.parameters()))\n",
    "    \n",
    "    # 2. Applying state dict\n",
    "    # ----------------------\n",
    "    if use_cuda == True:\n",
    "        \n",
    "        # loads to GPU\n",
    "        # ------------\n",
    "        checkpoint = torch.load(path)\n",
    "        \n",
    "    else:\n",
    "        # loads to CPU\n",
    "        # ------------\n",
    "        checkpoint = torch.load(path, map_location=lambda storage, loc: storage)\n",
    "        \n",
    "        \n",
    "    # loading checkpoint\n",
    "    # -------------------\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # loading optimizer\n",
    "    # -----------------\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    if use_cuda == True:\n",
    "        for state in optimizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    state[k] = v.cuda()\n",
    "            \n",
    "            \n",
    "            \n",
    "    # loading other stuff\n",
    "    # -------------------\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    loss_mode = checkpoint['loss_mode']\n",
    "    \n",
    "    return model, optimizer, epoch, loss, loss_mode\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function to do a forward pass by chunks\n",
    "# ----------------------------------------------\n",
    "\n",
    "def chunk_pass(xin,model,latent,use_cuda,chunksize):\n",
    "    \n",
    "    # 0. some initialisations\n",
    "    # -----------------------\n",
    "    model = model.eval()\n",
    "    if use_cuda == True:\n",
    "        torch.cuda.empty_cache()\n",
    "        model = model.cuda()\n",
    "        \n",
    "    \n",
    "    # sanity assertion\n",
    "    # ----------------\n",
    "    if len(xin.size()) > 3:\n",
    "        \n",
    "        # normalising data\n",
    "        # ----------------\n",
    "        assert torch.mean(xin).data[0] > 1, 'Input data is already in range 0-1. Not consistent with flow.'\n",
    "        xin = xin/255\n",
    "        print(\"Normalised data to 0-1\")\n",
    "       \n",
    "\n",
    "    # 1. chuck loop\n",
    "    # -------------\n",
    "    with tqdm(total=xin.size()[0]) as pbar:\n",
    "        for i,chunk_data in enumerate(chunker(xin, chunksize)):\n",
    "            \n",
    "            # forward pass ops\n",
    "            # ----------------\n",
    "            try:\n",
    "                chunk_data = Variable(chunk_data.data, volatile=True)\n",
    "            except:\n",
    "                chunk_data = Variable(chunk_data, volatile=True)\n",
    "                \n",
    "            if use_cuda == True:\n",
    "                \n",
    "                torch.cuda.empty_cache()\n",
    "               \n",
    "                if latent == True:\n",
    "                    try:\n",
    "                        curr_forwardpass = model.latent(chunk_data.cuda().detach())\n",
    "                    except:\n",
    "                        curr_forwardpass = model.latent(chunk_data.cuda())\n",
    "                else:\n",
    "                    try:\n",
    "                        curr_forwardpass = model(chunk_data.cuda().detach())\n",
    "                    except:\n",
    "                        curr_forwardpass = model(chunk_data.cuda())\n",
    "            else:\n",
    "                \n",
    "                if latent == True:\n",
    "                    try:\n",
    "                        curr_forwardpass = model.latent(chunk_data.cpu().detach())\n",
    "                    except:\n",
    "                        curr_forwardpass = model.latent(chunk_data.cpu())\n",
    "                else:\n",
    "                    try:\n",
    "                        curr_forwardpass = model(chunk_data.cpu().detach())\n",
    "                    except:\n",
    "                        curr_forwardpass = model(chunk_data.cpu())\n",
    "                \n",
    "            # concat ops\n",
    "            # ----------\n",
    "            try:\n",
    "                xout = torch.cat((xout,curr_forwardpass), 0)\n",
    "            except:\n",
    "                xout= curr_forwardpass\n",
    "                \n",
    "            # for memory purpose\n",
    "            # ------------------\n",
    "            if use_cuda == True:\n",
    "                curr_forwardpass = curr_forwardpass.cpu()\n",
    "                chunk_data = chunk_data.cpu()\n",
    "                del curr_forwardpass\n",
    "                del chunk_data\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            pbar.update(chunksize)\n",
    "        \n",
    "    # 2. return\n",
    "    # ---------\n",
    "    xout = Variable(xout.data, volatile=False).cpu()\n",
    "    \n",
    "\n",
    "    return xout\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCN class copied from image search notebook which worked\n",
    "# --------------------------------------------------------\n",
    "\n",
    "class fcn_ae_4_layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initialising N/W here\n",
    "        # ---------------------\n",
    "        nw_activation_conv = nn.ReLU() #nn.LeakyReLU(0.2) # nn.Tanh() nn.Softmax2d()\n",
    "        f = 3\n",
    "        s = 2\n",
    "        added_act = nn.Tanh()\n",
    "        dropout_prob = 0.1\n",
    "        dropout_node = nn.Dropout2d(p=dropout_prob)\n",
    "        \n",
    "        #  what worked - 3,64,128,256,128,64,3\n",
    "        \n",
    "        # Conv 1\n",
    "        ###\n",
    "        conv1 = 32\n",
    "        ct1 = nn.Conv2d(3,conv1,f,stride = s)\n",
    "        cb1 = nn.BatchNorm2d(conv1)\n",
    "        ca1 = nw_activation_conv\n",
    "        cl1 = [ct1,cb1,ca1,dropout_node]\n",
    "        self.convl1 = nn.Sequential(*cl1)\n",
    "        \n",
    "        # Conv 2\n",
    "        ###\n",
    "        conv2 = 64\n",
    "        ct2 = nn.Conv2d(conv1,conv2,f,stride = s)\n",
    "        cb2 = nn.BatchNorm2d(conv2)\n",
    "        ca2 = nw_activation_conv\n",
    "        cl2 = [ct2,cb2,ca2,dropout_node]\n",
    "        self.convl2 = nn.Sequential(*cl2)\n",
    "        \n",
    "        # Conv 3\n",
    "        ###\n",
    "        conv3 = 128\n",
    "        ct3 = nn.Conv2d(conv2,conv3,f,stride = s)\n",
    "        cb3 = nn.BatchNorm2d(conv3)\n",
    "        ca3 = nn.Softmax2d() #nw_activation_conv\n",
    "        cl3 = [ct3,ca3,dropout_node]\n",
    "        self.convl3 = nn.Sequential(*cl3)\n",
    "        \n",
    "        # Conv 4\n",
    "        ###\n",
    "        #conv4 = 256\n",
    "        #ct4 = nn.Conv2d(conv3,conv4,f,stride = s)\n",
    "        #cb4 = nn.BatchNorm2d(conv4)\n",
    "        #ca4 = nn.Softmax2d() #nw_activation_conv\n",
    "        #cl4 = [ct4,ca4,dropout_node]\n",
    "        #self.convl4 = nn.Sequential(*cl4) # size 6 x 4\n",
    "        \n",
    "        \n",
    "        # Pooling layer\n",
    "        mxpl =  [nn.MaxPool2d((3,3), stride=3)]\n",
    "        #avpl =  [nn.AvgPool2d((6,4), stride=1)]\n",
    "        self.pool_net = nn.Sequential(*mxpl)\n",
    "        \n",
    "        # Adding a fully connected linear layer\n",
    "        #\n",
    "        \n",
    "        # Upconv layer 0\n",
    "        ###\n",
    "        #t0 = nn.ConvTranspose2d(conv4,conv4,2,stride = 2)\n",
    "        #b0 = nn.BatchNorm2d(conv4)\n",
    "        #a0 = nw_activation_conv\n",
    "        #l0 = [t0,b0,a0]\n",
    "        #self.upcl0 = nn.Sequential(*l0)\n",
    "        \n",
    "        # Upconv layer 1\n",
    "        ###\n",
    "        up_conv1 = 128\n",
    "        t1 = nn.ConvTranspose2d(conv3,up_conv1,3,stride = 3)\n",
    "        b1 = nn.BatchNorm2d(up_conv1)\n",
    "        a1 = nw_activation_conv\n",
    "        l1 = [t1,b1,a1,dropout_node]\n",
    "        self.upcl1 = nn.Sequential(*l1)\n",
    "        \n",
    "        # Upconv layer 2\n",
    "        ###\n",
    "        up_conv2 = 64\n",
    "        t2 = nn.ConvTranspose2d(up_conv1,up_conv2,f,stride = s)\n",
    "        b2 = nn.BatchNorm2d(up_conv2)\n",
    "        a2 = nw_activation_conv\n",
    "        l2 = [t2,b2,a2,dropout_node]\n",
    "        self.upcl2 = nn.Sequential(*l2)\n",
    "        \n",
    "        # Upconv layer 3\n",
    "        ###\n",
    "        up_conv3 = 32\n",
    "        t3 = nn.ConvTranspose2d(up_conv2,up_conv3,f,stride = s)\n",
    "        b3 = nn.BatchNorm2d(up_conv3)\n",
    "        a3 = nw_activation_conv\n",
    "        l3 = [t3,b3,a3,dropout_node]\n",
    "        self.upcl3 = nn.Sequential(*l3)\n",
    "        \n",
    "        # Upconv layer 4\n",
    "        ###\n",
    "        t4 = nn.ConvTranspose2d(up_conv3,3,f,stride = s)\n",
    "        a4 = nn.Sigmoid()\n",
    "        l4 = [t4,a4]\n",
    "        self.upcl4 = nn.Sequential(*l4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Generation\n",
    "        # ----------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        #c4_out = self.convl4(c3_out)\n",
    "        c5_out = self.pool_net(c3_out)\n",
    "        \n",
    "        #f1_out = self.upcl0(c5_out)\n",
    "        f2_out = self.upcl1(c5_out)\n",
    "        f3_out = self.upcl2(f2_out)\n",
    "        f4_out = self.upcl3(f3_out)\n",
    "        f5_out = self.upcl4(f4_out)\n",
    "        \n",
    "        return f5_out\n",
    "\n",
    "    \n",
    "    def latent(self, x):\n",
    "        \n",
    "        \n",
    "        # 0. forward prop\n",
    "        # ---------------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        \n",
    "\n",
    "        # 1. Working out layer number\n",
    "        # ---------------------------\n",
    "        if self.layer_mode == 'deep':\n",
    "            forward_out = self.convl4(c3_out)\n",
    "        \n",
    "        elif self.layer_mode == 'deep_minus_2':\n",
    "            forward_out = c2_out\n",
    "        \n",
    "        else:\n",
    "            forward_out = c3_out\n",
    "\n",
    "\n",
    "        # 2. Including a pool layer - setting dims\n",
    "        # ----------------------------------------\n",
    "        if self.layer_dims_set == True:\n",
    "            \n",
    "            ih, iw, pool_stride = self.layer_f, self.layer_f, self.layer_s\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            ih,iw = forward_out.size()[2],forward_out.size()[3]\n",
    "            pool_stride = 1\n",
    "        \n",
    "        if self.pool_mode == 'avg':\n",
    "\n",
    "            # avg pool - comment/uncomment\n",
    "            # ----------------------------\n",
    "            avpl =  nn.Sequential(*[nn.AvgPool2d((ih,iw), stride=pool_stride)])\n",
    "            latent_out = avpl(forward_out)\n",
    "        \n",
    "        elif self.pool_mode == 'max':\n",
    "            \n",
    "            # maxpool - comment/uncomment\n",
    "            # ---------------------------\n",
    "            mxpl =  nn.Sequential(*[nn.MaxPool2d((ih,iw), stride=pool_stride)])\n",
    "            latent_out = mxpl(forward_out)\n",
    "            \n",
    "        elif self.pool_mode == 'both':\n",
    "            \n",
    "            # avg pool\n",
    "            # --------\n",
    "            avpl =  nn.Sequential(*[nn.AvgPool2d((ih,iw), stride=pool_stride)])\n",
    "            latent_out_avg = avpl(forward_out)\n",
    "            latent_out_avg = latent_out_avg.view(latent_out_avg.size()[0],-1)\n",
    "            \n",
    "            # maxpool\n",
    "            # -------\n",
    "            mxpl =  nn.Sequential(*[nn.MaxPool2d((ih,iw), stride=pool_stride)])\n",
    "            latent_out_max = mxpl(forward_out)\n",
    "            latent_out_max = latent_out_max.view(latent_out_max.size()[0],-1)\n",
    "            \n",
    "            # final concat\n",
    "            # ------------\n",
    "            latent_out = torch.cat((latent_out_avg, latent_out_max), 1)\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # no pooling\n",
    "            # ----------\n",
    "            latent_out = forward_out\n",
    "            \n",
    "        \n",
    "        return latent_out.view(latent_out.size()[0],-1)\n",
    "        \n",
    "    \n",
    "     \n",
    "    def set_pool_mode(self, pool_mode, layer_mode, layer_dims_set, layer_f, layer_s):\n",
    "        \n",
    "        # setting pool mode\n",
    "        # -----------------\n",
    "        self.pool_mode = pool_mode\n",
    "        self.layer_mode = layer_mode\n",
    "        self.layer_dims_set = layer_dims_set\n",
    "        self.layer_f = layer_f\n",
    "        self.layer_s = layer_s\n",
    "        \n",
    "        print('Modes set.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCN class copied from image search notebook which worked\n",
    "# --------------------------------------------------------\n",
    "\n",
    "class fcn_ae_3_layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initialising N/W here\n",
    "        # ---------------------\n",
    "        nw_activation_conv = nn.ReLU() #nn.LeakyReLU(0.2) # nn.Tanh() nn.Softmax2d()\n",
    "        f = 3\n",
    "        s = 2\n",
    "        added_act = nn.Tanh()\n",
    "        dropout_prob = 0.1\n",
    "        dropout_node = nn.Dropout2d(p=dropout_prob)\n",
    "        \n",
    "        #  what worked - 3,64,128,256,128,64,3\n",
    "        \n",
    "        # Conv 1\n",
    "        ###\n",
    "        conv1 = 64\n",
    "        ct1 = nn.Conv2d(3,conv1,f,stride = s)\n",
    "        cb1 = nn.BatchNorm2d(conv1)\n",
    "        ca1 = nw_activation_conv\n",
    "        cl1 = [ct1,cb1,ca1,dropout_node]\n",
    "        self.convl1 = nn.Sequential(*cl1)\n",
    "        \n",
    "        # Conv 2\n",
    "        ###\n",
    "        conv2 = 128\n",
    "        ct2 = nn.Conv2d(conv1,conv2,f,stride = s)\n",
    "        cb2 = nn.BatchNorm2d(conv2)\n",
    "        ca2 = nw_activation_conv\n",
    "        cl2 = [ct2,cb2,ca2,dropout_node]\n",
    "        self.convl2 = nn.Sequential(*cl2)\n",
    "        \n",
    "        # Conv 3\n",
    "        ###\n",
    "        conv3 = 256\n",
    "        ct3 = nn.Conv2d(conv2,conv3,f,stride = s)\n",
    "        cb3 = nn.BatchNorm2d(conv3)\n",
    "        ca3 = nn.Softmax2d() #nn.Softmax2d() #nw_activation_conv\n",
    "        cl3 = [ct3,ca3,dropout_node]\n",
    "        self.convl3 = nn.Sequential(*cl3)\n",
    "        \n",
    "        # Conv 4\n",
    "        ###\n",
    "        #conv4 = 256\n",
    "        #ct4 = nn.Conv2d(conv3,conv4,f,stride = s)\n",
    "        #cb4 = nn.BatchNorm2d(conv4)\n",
    "        #ca4 = nn.Softmax2d() #nw_activation_conv\n",
    "        #cl4 = [ct4,ca4,dropout_node]\n",
    "        #self.convl4 = nn.Sequential(*cl4) # size 6 x 4\n",
    "        \n",
    "        \n",
    "        # Pooling layer\n",
    "        #mxpl =  [nn.MaxPool2d((2,2), stride=2)]\n",
    "        #avpl =  [nn.AvgPool2d((6,4), stride=1)]\n",
    "        #self.pool_net = nn.Sequential(*mxpl)\n",
    "        \n",
    "        # Adding a fully connected linear layer\n",
    "        #\n",
    "        \n",
    "        # Upconv layer 0\n",
    "        ###\n",
    "        #t0 = nn.ConvTranspose2d(conv4,conv4,2,stride = 2)\n",
    "        #b0 = nn.BatchNorm2d(conv4)\n",
    "        #a0 = nw_activation_conv\n",
    "        #l0 = [t0,b0,a0]\n",
    "        #self.upcl0 = nn.Sequential(*l0)\n",
    "        \n",
    "        # Upconv layer 1\n",
    "        ###\n",
    "        #up_conv1 = 128\n",
    "        #t1 = nn.ConvTranspose2d(conv4,up_conv1,f,stride = s)\n",
    "        #b1 = nn.BatchNorm2d(up_conv1)\n",
    "        #a1 = nw_activation_conv\n",
    "        #l1 = [t1,b1,a1,dropout_node]\n",
    "        #self.upcl1 = nn.Sequential(*l1)\n",
    "        \n",
    "        # Upconv layer 2\n",
    "        ###\n",
    "        up_conv2 = 128\n",
    "        t2 = nn.ConvTranspose2d(conv3,up_conv2,f,stride = s)\n",
    "        b2 = nn.BatchNorm2d(up_conv2)\n",
    "        a2 = nw_activation_conv\n",
    "        l2 = [t2,b2,a2,dropout_node]\n",
    "        self.upcl2 = nn.Sequential(*l2)\n",
    "        \n",
    "        # Upconv layer 3\n",
    "        ###\n",
    "        up_conv3 = 64\n",
    "        t3 = nn.ConvTranspose2d(up_conv2,up_conv3,f,stride = s)\n",
    "        b3 = nn.BatchNorm2d(up_conv3)\n",
    "        a3 = nw_activation_conv\n",
    "        l3 = [t3,b3,a3,dropout_node]\n",
    "        self.upcl3 = nn.Sequential(*l3)\n",
    "        \n",
    "        # Upconv layer 4\n",
    "        ###\n",
    "        t4 = nn.ConvTranspose2d(up_conv3,3,f,stride = s)\n",
    "        a4 = nn.Sigmoid()\n",
    "        l4 = [t4,a4]\n",
    "        self.upcl4 = nn.Sequential(*l4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Generation\n",
    "        # ----------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        #c4_out = self.convl4(c3_out)\n",
    "        #c5_out = self.pool_net(c3_out)\n",
    "        \n",
    "        #f1_out = self.upcl0(c5_out)\n",
    "        #f2_out = self.upcl1(c4_out)\n",
    "        f3_out = self.upcl2(c3_out)\n",
    "        f4_out = self.upcl3(f3_out)\n",
    "        f5_out = self.upcl4(f4_out)\n",
    "        \n",
    "        return f5_out\n",
    "\n",
    "    \n",
    "    def latent(self, x):\n",
    "        \n",
    "        \n",
    "        # 0. forward prop\n",
    "        # ---------------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        \n",
    "        # 1. Working out layer number\n",
    "        # ---------------------------\n",
    "        if self.layer_mode == 'deep_minus_1':\n",
    "            forward_out = c2_out\n",
    "        \n",
    "        else:\n",
    "            forward_out = self.convl3(c2_out)\n",
    "        \n",
    "\n",
    "        # 2. Including a pool layer - setting dims\n",
    "        # ----------------------------------------\n",
    "        if self.layer_dims_set == True:\n",
    "            \n",
    "            ih, iw, pool_stride = self.layer_f, self.layer_f, self.layer_s\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            ih,iw = forward_out.size()[2],forward_out.size()[3]\n",
    "            pool_stride = 1\n",
    "        \n",
    "        if self.pool_mode == 'avg':\n",
    "\n",
    "            # avg pool - comment/uncomment\n",
    "            # ----------------------------\n",
    "            avpl =  nn.Sequential(*[nn.AvgPool2d((ih,iw), stride=pool_stride)])\n",
    "            latent_out = avpl(forward_out)\n",
    "        \n",
    "        elif self.pool_mode == 'max':\n",
    "            \n",
    "            # maxpool - comment/uncomment\n",
    "            # ---------------------------\n",
    "            mxpl =  nn.Sequential(*[nn.MaxPool2d((ih,iw), stride=pool_stride)])\n",
    "            latent_out = mxpl(forward_out)\n",
    "            \n",
    "        elif self.pool_mode == 'both':\n",
    "            \n",
    "            # avg pool\n",
    "            # --------\n",
    "            avpl =  nn.Sequential(*[nn.AvgPool2d((ih,iw), stride=pool_stride)])\n",
    "            latent_out_avg = avpl(forward_out)\n",
    "            latent_out_avg = latent_out_avg.view(latent_out_avg.size()[0],-1)\n",
    "            \n",
    "            # maxpool\n",
    "            # -------\n",
    "            mxpl =  nn.Sequential(*[nn.MaxPool2d((ih,iw), stride=pool_stride)])\n",
    "            latent_out_max = mxpl(forward_out)\n",
    "            latent_out_max = latent_out_max.view(latent_out_max.size()[0],-1)\n",
    "            \n",
    "            # final concat\n",
    "            # ------------\n",
    "            latent_out = torch.cat((latent_out_avg, latent_out_max), 1)\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # no pooling\n",
    "            # ----------\n",
    "            latent_out = forward_out\n",
    "            \n",
    "        \n",
    "        return latent_out.view(latent_out.size()[0],-1)\n",
    "        \n",
    "    \n",
    "     \n",
    "    def set_pool_mode(self, pool_mode, layer_mode, layer_dims_set, layer_f, layer_s):\n",
    "        \n",
    "        # setting pool mode\n",
    "        # -----------------\n",
    "        self.pool_mode = pool_mode\n",
    "        self.layer_mode = layer_mode\n",
    "        self.layer_dims_set = layer_dims_set\n",
    "        self.layer_f = layer_f\n",
    "        self.layer_s = layer_s\n",
    "        \n",
    "        print('Modes set.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCN class copied from image search notebook which worked\n",
    "# --------------------------------------------------------\n",
    "\n",
    "class fcn_ae_deep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initialising N/W here\n",
    "        # ---------------------\n",
    "        nw_activation_conv = nn.ReLU() #nn.LeakyReLU(0.2) # nn.Tanh() nn.Softmax2d()\n",
    "        f = 3\n",
    "        s = 2\n",
    "        added_act = nn.Tanh()\n",
    "        dropout_prob = 0.2\n",
    "        dropout_node = nn.Dropout2d(p=dropout_prob)\n",
    "        \n",
    "        #  what worked - 3,64,128,256,128,64,3\n",
    "        \n",
    "        # Conv 1\n",
    "        ###\n",
    "        conv1 = 32\n",
    "        ct1 = nn.Conv2d(3,conv1,f,stride = s)\n",
    "        cb1 = nn.BatchNorm2d(conv1)\n",
    "        ca1 = nw_activation_conv\n",
    "        cl1 = [ct1,cb1,ca1,dropout_node]\n",
    "        self.convl1 = nn.Sequential(*cl1)\n",
    "        \n",
    "        # Conv 2\n",
    "        ###\n",
    "        conv2 = 64\n",
    "        ct2 = nn.Conv2d(conv1,conv2,f,stride = s)\n",
    "        cb2 = nn.BatchNorm2d(conv2)\n",
    "        ca2 = nw_activation_conv\n",
    "        cl2 = [ct2,cb2,ca2,dropout_node]\n",
    "        self.convl2 = nn.Sequential(*cl2)\n",
    "        \n",
    "        # Conv 3\n",
    "        ###\n",
    "        conv3 = 128\n",
    "        ct3 = nn.Conv2d(conv2,conv3,f,stride = s)\n",
    "        cb3 = nn.BatchNorm2d(conv3)\n",
    "        ca3 = nw_activation_conv #nw_activation_conv\n",
    "        cl3 = [ct3,cb3,ca3,dropout_node]\n",
    "        self.convl3 = nn.Sequential(*cl3)\n",
    "        \n",
    "        # Conv 4\n",
    "        ###\n",
    "        conv4 = 256\n",
    "        ct4 = nn.Conv2d(conv3,conv4,f,stride = s)\n",
    "        cb4 = nn.BatchNorm2d(conv4)\n",
    "        ca4 = nw_activation_conv\n",
    "        cl4 = [ct4,cb4,ca4,dropout_node]\n",
    "        self.convl4 = nn.Sequential(*cl4) \n",
    "        \n",
    "        # Conv 5\n",
    "        ###\n",
    "        conv5 = 512\n",
    "        ct5 = nn.Conv2d(conv4,conv5,f,stride = s)\n",
    "        cb5 = nn.BatchNorm2d(conv5)\n",
    "        ca5 = nn.Softmax2d()\n",
    "        cl5 = [ct5,cb5,ca5,dropout_node]\n",
    "        self.convl5 = nn.Sequential(*cl5) \n",
    "        \n",
    "        \n",
    "        # Pooling layer\n",
    "        #mxpl =  [nn.MaxPool2d((2,2), stride=2)]\n",
    "        #avpl =  [nn.AvgPool2d((6,4), stride=1)]\n",
    "        #self.pool_net = nn.Sequential(*mxpl)\n",
    "        \n",
    "        # Adding a fully connected linear layer\n",
    "        #\n",
    "        \n",
    "        # Upconv layer 0\n",
    "        ###\n",
    "        up_conv0 = 256\n",
    "        t0 = nn.ConvTranspose2d(conv5,up_conv0,f,stride = s)\n",
    "        b0 = nn.BatchNorm2d(up_conv0)\n",
    "        a0 = nw_activation_conv\n",
    "        l0 = [t0,b0,a0,dropout_node]\n",
    "        self.upcl0 = nn.Sequential(*l0)\n",
    "        \n",
    "        # Upconv layer 1\n",
    "        ###\n",
    "        up_conv1 = 128\n",
    "        t1 = nn.ConvTranspose2d(up_conv0,up_conv1,f,stride = s)\n",
    "        b1 = nn.BatchNorm2d(up_conv1)\n",
    "        a1 = nw_activation_conv\n",
    "        l1 = [t1,b1,a1,dropout_node]\n",
    "        self.upcl1 = nn.Sequential(*l1)\n",
    "        \n",
    "        # Upconv layer 2\n",
    "        ###\n",
    "        up_conv2 = 64\n",
    "        t2 = nn.ConvTranspose2d(up_conv1,up_conv2,f,stride = s)\n",
    "        b2 = nn.BatchNorm2d(up_conv2)\n",
    "        a2 = nw_activation_conv\n",
    "        l2 = [t2,b2,a2,dropout_node]\n",
    "        self.upcl2 = nn.Sequential(*l2)\n",
    "        \n",
    "        # Upconv layer 3\n",
    "        ###\n",
    "        up_conv3 = 32\n",
    "        t3 = nn.ConvTranspose2d(up_conv2,up_conv3,f,stride = s)\n",
    "        b3 = nn.BatchNorm2d(up_conv3)\n",
    "        a3 = nw_activation_conv\n",
    "        l3 = [t3,b3,a3,dropout_node]\n",
    "        self.upcl3 = nn.Sequential(*l3)\n",
    "        \n",
    "        # Upconv layer 4\n",
    "        ###\n",
    "        t4 = nn.ConvTranspose2d(up_conv3,3,f,stride = s)\n",
    "        a4 = nn.Sigmoid()\n",
    "        l4 = [t4,a4]\n",
    "        self.upcl4 = nn.Sequential(*l4)\n",
    "        \n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "        # forward pass\n",
    "        # ------------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        c4_out = self.convl4(c3_out)\n",
    "        c5_out = self.convl5(c4_out)\n",
    "        \n",
    "        f1_out = self.upcl0(c5_out)\n",
    "        f2_out = self.upcl1(f1_out)\n",
    "        f3_out = self.upcl2(f2_out)\n",
    "        f4_out = self.upcl3(f3_out)\n",
    "        f5_out = self.upcl4(f4_out)\n",
    "        \n",
    "        return f5_out\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def latent(self, x):\n",
    "        \n",
    "        \n",
    "        # 0. forward prop\n",
    "        # ---------------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        c4_out = self.convl4(c3_out)\n",
    "\n",
    "        # 1. Working out layer number\n",
    "        # ---------------------------\n",
    "        if self.layer_mode == 'deep':\n",
    "            forward_out = self.convl5(c4_out)\n",
    "        \n",
    "        elif self.layer_mode == 'deep_minus_2':\n",
    "            forward_out = c3_out\n",
    "        \n",
    "        else:\n",
    "            forward_out = c4_out\n",
    "\n",
    "\n",
    "        # 2. Including a pool layer \n",
    "        # -------------------------\n",
    "        ih,iw = forward_out.size()[2],forward_out.size()[3]\n",
    "        \n",
    "        if self.pool_mode == 'avg':\n",
    "\n",
    "            # avg pool - comment/uncomment\n",
    "            # ----------------------------\n",
    "            avpl =  nn.Sequential(*[nn.AvgPool2d((ih,iw), stride=1)])\n",
    "            latent_out = avpl(forward_out)\n",
    "        \n",
    "        elif self.pool_mode == 'max':\n",
    "            \n",
    "            # maxpool - comment/uncomment\n",
    "            # ---------------------------\n",
    "            mxpl =  nn.Sequential(*[nn.MaxPool2d((ih,iw), stride=1)])\n",
    "            latent_out = mxpl(forward_out)\n",
    "            \n",
    "        elif self.pool_mode == 'both':\n",
    "            \n",
    "            # avg pool\n",
    "            # --------\n",
    "            avpl =  nn.Sequential(*[nn.AvgPool2d((ih,iw), stride=1)])\n",
    "            latent_out_avg = avpl(forward_out)\n",
    "            latent_out_avg = latent_out_avg.view(latent_out_avg.size()[0],-1)\n",
    "            \n",
    "            # maxpool\n",
    "            # -------\n",
    "            mxpl =  nn.Sequential(*[nn.MaxPool2d((ih,iw), stride=1)])\n",
    "            latent_out_max = mxpl(forward_out)\n",
    "            latent_out_max = latent_out_max.view(latent_out_max.size()[0],-1)\n",
    "            \n",
    "            # final concat\n",
    "            # ------------\n",
    "            latent_out = torch.cat((latent_out_avg, latent_out_max), 1)\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # no pooling\n",
    "            # ----------\n",
    "            latent_out = forward_out\n",
    "            \n",
    "        \n",
    "        return latent_out.view(latent_out.size()[0],-1)\n",
    "        \n",
    "    \n",
    "     \n",
    "    def set_pool_mode(self, pool_mode, layer_mode):\n",
    "        \n",
    "        # setting pool mode\n",
    "        # -----------------\n",
    "        self.pool_mode = pool_mode\n",
    "        self.layer_mode = layer_mode\n",
    "        print('Modes set.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCN class copied from image search notebook which worked\n",
    "# --------------------------------------------------------\n",
    "\n",
    "class fcn_ae_6_layer_WNET(nn.Module):\n",
    "    def __init__(self, in_channels, latent_softmax):\n",
    "        super().__init__()\n",
    "        \n",
    "        # This is WNET model\n",
    "        # ------------------\n",
    "        \n",
    "        # Showing conv up sizes - \n",
    "        # --------------------------\n",
    "        # (191,191) -- Insize\n",
    "        \n",
    "        # @conv1 - (95,95)\n",
    "        # @conv2 - (47, 47)\n",
    "        # @conv3 - (23, 23)\n",
    "        # @conv4 - (11, 11)\n",
    "        # @conv5 - (5, 5)\n",
    "        # @conv6 - (2,2)\n",
    "        # Followed by a an avg pool (2,2) to make this 1,1\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Initialising N/W here\n",
    "        # ---------------------\n",
    "        nw_activation_conv = nn.ReLU() #nn.LeakyReLU(0.2) # nn.Tanh() nn.Softmax2d()\n",
    "        f = 3\n",
    "        s = 2\n",
    "        dropout_prob = 0.2\n",
    "        dropout_node = nn.Dropout2d(p=dropout_prob)\n",
    "        \n",
    "        # CONV Down layers\n",
    "        # ----------------\n",
    "        \n",
    "        # Conv 1\n",
    "        ###\n",
    "        conv1 = 16\n",
    "        ct1 = nn.Conv2d(in_channels,conv1,f,stride = s)\n",
    "        cb1 = nn.BatchNorm2d(conv1)\n",
    "        ca1 = nw_activation_conv\n",
    "        cl1 = [ct1,cb1,ca1,dropout_node]\n",
    "        self.convl1 = nn.Sequential(*cl1)\n",
    "        \n",
    "        # Conv 2\n",
    "        ###\n",
    "        conv2 = 32\n",
    "        ct2 = nn.Conv2d(conv1,conv2,f,stride = s)\n",
    "        cb2 = nn.BatchNorm2d(conv2)\n",
    "        ca2 = nw_activation_conv\n",
    "        cl2 = [ct2,cb2,ca2,dropout_node]\n",
    "        self.convl2 = nn.Sequential(*cl2)\n",
    "        \n",
    "        # Conv 3\n",
    "        ###\n",
    "        conv3 = 64\n",
    "        ct3 = nn.Conv2d(conv2,conv3,f,stride = s)\n",
    "        cb3 = nn.BatchNorm2d(conv3)\n",
    "        ca3 = nw_activation_conv\n",
    "        cl3 = [ct3,cb3,ca3,dropout_node]\n",
    "        self.convl3 = nn.Sequential(*cl3)\n",
    "        \n",
    "        # Conv 4\n",
    "        ###\n",
    "        conv4 = 128\n",
    "        ct4 = nn.Conv2d(conv3,conv4,f,stride = s)\n",
    "        cb4 = nn.BatchNorm2d(conv4)\n",
    "        ca4 = nw_activation_conv\n",
    "        cl4 = [ct4,cb4,ca4,dropout_node]\n",
    "        self.convl4 = nn.Sequential(*cl4) \n",
    "        \n",
    "        # Conv 5\n",
    "        ###\n",
    "        conv5 = 256\n",
    "        ct5 = nn.Conv2d(conv4,conv5,f,stride = s)\n",
    "        cb5 = nn.BatchNorm2d(conv5)\n",
    "        ca5 = nw_activation_conv\n",
    "        cl5 = [ct5,cb5,ca5,dropout_node]\n",
    "        self.convl5 = nn.Sequential(*cl5) \n",
    "        \n",
    "        # Conv 6\n",
    "        ###\n",
    "        conv6 = 512\n",
    "        ct6 = nn.Conv2d(conv5,conv6,f,stride = s)\n",
    "        cb6 = nn.BatchNorm2d(conv6)\n",
    "        ca6 = nw_activation_conv\n",
    "        cl6 = [ct6,cb6,ca6,dropout_node]\n",
    "        self.convl6 = nn.Sequential(*cl6) \n",
    "        \n",
    "\n",
    "        # Pooling layer + softmax activation\n",
    "        # ----------------------------------\n",
    "        if latent_softmax == True:\n",
    "            avpl =  [nn.AvgPool2d((2,2), stride=1), nn.Softmax2d()]\n",
    "        else:\n",
    "            avpl =  [nn.AvgPool2d((2,2), stride=1)]\n",
    "        self.pool_net = nn.Sequential(*avpl)\n",
    "        \n",
    "      \n",
    "        # Transconv layers\n",
    "        # ----------------\n",
    "        # Showing conv up sizes - \n",
    "        # --------------------------\n",
    "        # Incoming input is 1 x 1 x C\n",
    "        # (5, 5)\n",
    "        # (11, 11)\n",
    "        # (23, 23)\n",
    "        # (47, 47)\n",
    "        # (95, 95)\n",
    "        # (191, 191)\n",
    "        \n",
    "        # Upconv layer 0\n",
    "        ###\n",
    "        up_conv0 = conv6\n",
    "        t0 = nn.ConvTranspose2d(conv6,up_conv0,2,stride = 1)\n",
    "        b0 = nn.BatchNorm2d(up_conv0)\n",
    "        a0 = nw_activation_conv\n",
    "        l0 = [t0,b0,a0,dropout_node]\n",
    "        self.upcl0 = nn.Sequential(*l0) # 2x2\n",
    "        \n",
    "        # Upconv layer 1\n",
    "        # concat layer\n",
    "        ###\n",
    "        up_conv1 = 256\n",
    "        t1 = nn.ConvTranspose2d(up_conv0 + conv6,up_conv1,f,stride = s)\n",
    "        b1 = nn.BatchNorm2d(up_conv1)\n",
    "        a1 = nw_activation_conv\n",
    "        l1 = [t1,b1,a1,dropout_node]\n",
    "        self.upcl1 = nn.Sequential(*l1) # 5x5\n",
    "        \n",
    "        # Upconv layer 2\n",
    "        # concat layer\n",
    "        ###\n",
    "        up_conv2 = 128\n",
    "        t2 = nn.ConvTranspose2d(up_conv1 + conv5,up_conv2,f,stride = s)\n",
    "        b2 = nn.BatchNorm2d(up_conv2)\n",
    "        a2 = nw_activation_conv\n",
    "        l2 = [t2,b2,a2,dropout_node]\n",
    "        self.upcl2 = nn.Sequential(*l2)\n",
    "        \n",
    "        # Upconv layer 3\n",
    "        # concat layer\n",
    "        ###\n",
    "        up_conv3 = 64\n",
    "        t3 = nn.ConvTranspose2d(up_conv2 + conv4,up_conv3,f,stride = s)\n",
    "        b3 = nn.BatchNorm2d(up_conv3)\n",
    "        a3 = nw_activation_conv\n",
    "        l3 = [t3,b3,a3,dropout_node]\n",
    "        self.upcl3 = nn.Sequential(*l3)\n",
    "        \n",
    "        # Upconv layer 4\n",
    "        # concat layer\n",
    "        ###\n",
    "        up_conv4 = 32\n",
    "        t4 = nn.ConvTranspose2d(up_conv3 + conv3,up_conv4,f,stride = s)\n",
    "        b4 = nn.BatchNorm2d(up_conv4)\n",
    "        a4 = nw_activation_conv\n",
    "        l4 = [t4,b4,a4,dropout_node]\n",
    "        self.upcl4 = nn.Sequential(*l4)\n",
    "        \n",
    "        # Upconv layer 5\n",
    "        # concat layer\n",
    "        ###\n",
    "        up_conv5 = 16\n",
    "        t5 = nn.ConvTranspose2d(up_conv4 + conv2,up_conv5,f,stride = s)\n",
    "        b5 = nn.BatchNorm2d(up_conv5)\n",
    "        a5 = nw_activation_conv\n",
    "        l5 = [t5,b5,a5,dropout_node]\n",
    "        self.upcl5 = nn.Sequential(*l5)\n",
    "    \n",
    "    \n",
    "        # Upconv layer 6\n",
    "        # concat layer - FINAL LAYER\n",
    "        ###\n",
    "        t6 = nn.ConvTranspose2d(up_conv5 + conv1,3,f,stride = s)\n",
    "        a6 = nn.Sigmoid()\n",
    "        l6 = [t6,a6]\n",
    "        self.upcl6 = nn.Sequential(*l6)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Conv pass\n",
    "        # ---------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        c4_out = self.convl4(c3_out)\n",
    "        c5_out = self.convl5(c4_out)\n",
    "        c6_out = self.convl6(c5_out)\n",
    "        \n",
    "        # pooling\n",
    "        # -------\n",
    "        latent_out = self.pool_net(c6_out)\n",
    "        \n",
    "        # Transconv pass\n",
    "        # --------------\n",
    "        f1_out = self.upcl0(latent_out)\n",
    "        f2_out = self.upcl1(torch.cat((f1_out,c6_out), 1))\n",
    "        f3_out = self.upcl2(torch.cat((f2_out,c5_out), 1))\n",
    "        f4_out = self.upcl3(torch.cat((f3_out,c4_out), 1))\n",
    "        f5_out = self.upcl4(torch.cat((f4_out,c3_out), 1))\n",
    "        f6_out = self.upcl5(torch.cat((f5_out,c2_out), 1))\n",
    "        f7_out = self.upcl6(torch.cat((f6_out,c1_out), 1))\n",
    "        \n",
    "        return f7_out\n",
    "\n",
    "    \n",
    "    def latent(self, x):\n",
    "        \n",
    "        \n",
    "        # Conv pass\n",
    "        # ---------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        c4_out = self.convl4(c3_out)\n",
    "        c5_out = self.convl5(c4_out)\n",
    "        c6_out = self.convl6(c5_out)\n",
    "        \n",
    "        # pooling\n",
    "        # -------\n",
    "        latent_out = self.pool_net(c6_out)\n",
    "\n",
    "        return latent_out.view(latent_out.size()[0],-1)\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCN class copied from image search notebook which worked\n",
    "# --------------------------------------------------------\n",
    "\n",
    "class standard_cnn_6_layer(nn.Module):\n",
    "    def __init__(self, in_channels, latent_softmax):\n",
    "        super().__init__()\n",
    "        \n",
    "        # This is WNET model\n",
    "        # ------------------\n",
    "        \n",
    "        # Showing conv up sizes - \n",
    "        # --------------------------\n",
    "        # (191,191) -- Insize\n",
    "        \n",
    "        # @conv1 - (95,95)\n",
    "        # @conv2 - (47, 47)\n",
    "        # @conv3 - (23, 23)\n",
    "        # @conv4 - (11, 11)\n",
    "        # @conv5 - (5, 5)\n",
    "        # @conv6 - (2,2)\n",
    "        # Followed by a an avg pool (2,2) to make this 1,1\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Initialising N/W here\n",
    "        # ---------------------\n",
    "        nw_activation_conv = nn.ReLU() #nn.LeakyReLU(0.2) # nn.Tanh() nn.Softmax2d()\n",
    "        f = 3\n",
    "        s = 2\n",
    "        dropout_prob = 0.2\n",
    "        dropout_node = nn.Dropout2d(p=dropout_prob)\n",
    "        \n",
    "        # CONV Down layers\n",
    "        # ----------------\n",
    "        \n",
    "        # Conv 1\n",
    "        ###\n",
    "        conv1 = 16\n",
    "        ct1 = nn.Conv2d(in_channels,conv1,f,stride = s)\n",
    "        cb1 = nn.BatchNorm2d(conv1)\n",
    "        ca1 = nw_activation_conv\n",
    "        cl1 = [ct1,cb1,ca1,dropout_node]\n",
    "        self.convl1 = nn.Sequential(*cl1)\n",
    "        \n",
    "        # Conv 2\n",
    "        ###\n",
    "        conv2 = 32\n",
    "        ct2 = nn.Conv2d(conv1,conv2,f,stride = s)\n",
    "        cb2 = nn.BatchNorm2d(conv2)\n",
    "        ca2 = nw_activation_conv\n",
    "        cl2 = [ct2,cb2,ca2,dropout_node]\n",
    "        self.convl2 = nn.Sequential(*cl2)\n",
    "        \n",
    "        # Conv 3\n",
    "        ###\n",
    "        conv3 = 64\n",
    "        ct3 = nn.Conv2d(conv2,conv3,f,stride = s)\n",
    "        cb3 = nn.BatchNorm2d(conv3)\n",
    "        ca3 = nw_activation_conv\n",
    "        cl3 = [ct3,cb3,ca3,dropout_node]\n",
    "        self.convl3 = nn.Sequential(*cl3)\n",
    "        \n",
    "        # Conv 4\n",
    "        ###\n",
    "        conv4 = 128\n",
    "        ct4 = nn.Conv2d(conv3,conv4,f,stride = s)\n",
    "        cb4 = nn.BatchNorm2d(conv4)\n",
    "        ca4 = nw_activation_conv\n",
    "        cl4 = [ct4,cb4,ca4,dropout_node]\n",
    "        self.convl4 = nn.Sequential(*cl4) \n",
    "        \n",
    "        # Conv 5\n",
    "        ###\n",
    "        conv5 = 256\n",
    "        ct5 = nn.Conv2d(conv4,conv5,f,stride = s)\n",
    "        cb5 = nn.BatchNorm2d(conv5)\n",
    "        ca5 = nw_activation_conv\n",
    "        cl5 = [ct5,cb5,ca5,dropout_node]\n",
    "        self.convl5 = nn.Sequential(*cl5) \n",
    "        \n",
    "        # Conv 6\n",
    "        ###\n",
    "        conv6 = 512\n",
    "        ct6 = nn.Conv2d(conv5,conv6,f,stride = s)\n",
    "        cb6 = nn.BatchNorm2d(conv6)\n",
    "        ca6 = nw_activation_conv\n",
    "        cl6 = [ct6,cb6,ca6,dropout_node]\n",
    "        self.convl6 = nn.Sequential(*cl6) \n",
    "        \n",
    "\n",
    "        # Pooling layer + softmax activation\n",
    "        # ----------------------------------\n",
    "        if latent_softmax == True:\n",
    "            avpl =  [nn.AvgPool2d((2,2), stride=1), nn.Softmax2d()]\n",
    "        else:\n",
    "            avpl =  [nn.AvgPool2d((2,2), stride=1)]\n",
    "        self.pool_net = nn.Sequential(*avpl)\n",
    "        \n",
    "        \n",
    "        # Adding linear layers\n",
    "        # -------------------\n",
    "        lnt1 = nn.Linear(conv6,256)\n",
    "        lnb1 = nn.BatchNorm1d(256)\n",
    "        lna1 = nw_activation_conv\n",
    "        ln1 = [lnt1,lnb1,lna1,dropout_node]\n",
    "        self.linear1 = nn.Sequential(*ln1) \n",
    "      \n",
    "        lnt2 = nn.Linear(256,128)\n",
    "        lnb2 = nn.BatchNorm1d(128)\n",
    "        lna2 = nw_activation_conv\n",
    "        ln2 = [lnt2,lnb2,lna2,dropout_node]\n",
    "        self.linear2 = nn.Sequential(*ln2)\n",
    "        \n",
    "        lnt3 = nn.Linear(128,64)\n",
    "        lnb3 = nn.BatchNorm1d(64)\n",
    "        lna3 = nw_activation_conv\n",
    "        ln3 = [lnt3,lnb3,lna3,dropout_node]\n",
    "        self.linear3 = nn.Sequential(*ln3)\n",
    "        \n",
    "        ln4 = [nn.Linear(64,1)]\n",
    "        self.linear4 = nn.Sequential(*ln4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Conv pass\n",
    "        # ---------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        c4_out = self.convl4(c3_out)\n",
    "        c5_out = self.convl5(c4_out)\n",
    "        c6_out = self.convl6(c5_out)\n",
    "        \n",
    "        # pooling\n",
    "        # -------\n",
    "        latent_out = self.pool_net(c6_out)\n",
    "        \n",
    "        # linear out\n",
    "        # ----------\n",
    "        linear1_out = self.linear1(latent_out.view(latent_out.size()[0],-1))\n",
    "        linear2_out = self.linear2(linear1_out)\n",
    "        linear3_out = self.linear3(linear2_out)\n",
    "        linear4_out = self.linear4(linear3_out)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return linear4_out\n",
    "\n",
    "\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCN class copied from image search notebook which worked\n",
    "# --------------------------------------------------------\n",
    "\n",
    "class standard_cnn_4_layer(nn.Module):\n",
    "    def __init__(self, in_channels, latent_softmax):\n",
    "        super().__init__()\n",
    "        \n",
    "        # This is WNET model\n",
    "        # ------------------\n",
    "        \n",
    "        # Showing conv up sizes - \n",
    "        # --------------------------\n",
    "        # (191,191) -- Insize\n",
    "        \n",
    "        # @conv1 - (95,95)\n",
    "        # @conv2 - (47, 47)\n",
    "        # @conv3 - (23, 23)\n",
    "        # @conv4 - (11, 11)\n",
    "        # @conv5 - (5, 5)\n",
    "        # @conv6 - (2,2)\n",
    "        # Followed by a an avg pool (2,2) to make this 1,1\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Initialising N/W here\n",
    "        # ---------------------\n",
    "        nw_activation_conv = nn.ReLU() #nn.LeakyReLU(0.2) # nn.Tanh() nn.Softmax2d()\n",
    "        f = 3\n",
    "        s = 2\n",
    "        dropout_prob = 0.2\n",
    "        dropout_node = nn.Dropout2d(p=dropout_prob)\n",
    "        \n",
    "        # CONV Down layers\n",
    "        # ----------------\n",
    "        \n",
    "        # Conv 1\n",
    "        ###\n",
    "        conv1 = 64\n",
    "        ct1 = nn.Conv2d(in_channels,conv1,f,stride = s)\n",
    "        cb1 = nn.BatchNorm2d(conv1)\n",
    "        ca1 = nw_activation_conv\n",
    "        cl1 = [ct1,cb1,ca1,dropout_node]\n",
    "        self.convl1 = nn.Sequential(*cl1)\n",
    "        \n",
    "        # Conv 2\n",
    "        ###\n",
    "        conv2 = 128\n",
    "        ct2 = nn.Conv2d(conv1,conv2,f,stride = s)\n",
    "        cb2 = nn.BatchNorm2d(conv2)\n",
    "        ca2 = nw_activation_conv\n",
    "        cl2 = [ct2,cb2,ca2,dropout_node]\n",
    "        self.convl2 = nn.Sequential(*cl2)\n",
    "        \n",
    "        # Conv 3\n",
    "        ###\n",
    "        conv3 = 256\n",
    "        ct3 = nn.Conv2d(conv2,conv3,f,stride = s)\n",
    "        cb3 = nn.BatchNorm2d(conv3)\n",
    "        ca3 = nw_activation_conv\n",
    "        cl3 = [ct3,cb3,ca3,dropout_node]\n",
    "        self.convl3 = nn.Sequential(*cl3)\n",
    "        \n",
    "        # Conv 4\n",
    "        ###\n",
    "        conv4 = 512\n",
    "        ct4 = nn.Conv2d(conv3,conv4,f,stride = s)\n",
    "        cb4 = nn.BatchNorm2d(conv4)\n",
    "        ca4 = nw_activation_conv\n",
    "        cl4 = [ct4,cb4,ca4,dropout_node]\n",
    "        self.convl4 = nn.Sequential(*cl4) \n",
    "    \n",
    "        \n",
    "        # Adding linear layers\n",
    "        # -------------------\n",
    "        lnt1 = nn.Linear(conv4*11*11,1024)\n",
    "        lnb1 = nn.BatchNorm1d(1024)\n",
    "        lna1 = nw_activation_conv\n",
    "        ln1 = [lnt1,lnb1,lna1,dropout_node]\n",
    "        self.linear1 = nn.Sequential(*ln1) \n",
    "      \n",
    "        lnt2 = nn.Linear(1024,512)\n",
    "        lnb2 = nn.BatchNorm1d(512)\n",
    "        lna2 = nw_activation_conv\n",
    "        ln2 = [lnt2,lnb2,lna2,dropout_node]\n",
    "        self.linear2 = nn.Sequential(*ln2)\n",
    "        \n",
    "        lnt3 = nn.Linear(512,256)\n",
    "        lnb3 = nn.BatchNorm1d(256)\n",
    "        lna3 = nw_activation_conv\n",
    "        ln3 = [lnt3,lnb3,lna3,dropout_node]\n",
    "        self.linear3 = nn.Sequential(*ln3)\n",
    "        \n",
    "        ln4 = [nn.Linear(256,1)]\n",
    "        self.linear4 = nn.Sequential(*ln4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Conv pass\n",
    "        # ---------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        c4_out = self.convl4(c3_out)\n",
    "        \n",
    "        # linear out\n",
    "        # ----------\n",
    "        linear1_out = self.linear1(c4_out.view(c4_out.size()[0],-1))\n",
    "        linear2_out = self.linear2(linear1_out)\n",
    "        linear3_out = self.linear3(linear2_out)\n",
    "        linear4_out = self.linear4(linear3_out)\n",
    "        \n",
    "        return linear4_out\n",
    "\n",
    "\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCN class copied from image search notebook which worked\n",
    "# --------------------------------------------------------\n",
    "\n",
    "class fcn_ae_6_layer_UNET_multiple_outchannels(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, latent_softmax):\n",
    "        super().__init__()\n",
    "        \n",
    "        # This is WNET model\n",
    "        # ------------------\n",
    "        \n",
    "        # Showing conv up sizes - \n",
    "        # --------------------------\n",
    "        # (191,319) -- Insize\n",
    "        \n",
    "        # @conv1 - (95,159)\n",
    "        # @conv2 - (47, 79)\n",
    "        # @conv3 - (23, 39)\n",
    "        # @conv4 - (11, 19)\n",
    "        # @conv5 - (5, 9)\n",
    "        # @conv6 - (2,4)\n",
    "        # Followed by a an avg pool (2,4) to make this 1,1\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Initialising N/W here\n",
    "        # ---------------------\n",
    "        nw_activation_conv = nn.ReLU() #nn.LeakyReLU(0.2) # nn.Tanh() nn.Softmax2d()\n",
    "        f = 3\n",
    "        s = 2\n",
    "        dropout_prob = 0.2\n",
    "        dropout_node = nn.Dropout2d(p=dropout_prob)\n",
    "        \n",
    "        # CONV Down layers\n",
    "        # ----------------\n",
    "        \n",
    "        # Conv 1\n",
    "        ###\n",
    "        conv1 = 16\n",
    "        ct1 = nn.Conv2d(in_channels,conv1,f,stride = s)\n",
    "        cb1 = nn.BatchNorm2d(conv1)\n",
    "        ca1 = nw_activation_conv\n",
    "        cl1 = [ct1,cb1,ca1,dropout_node]\n",
    "        self.convl1 = nn.Sequential(*cl1)\n",
    "        \n",
    "        # Conv 2\n",
    "        ###\n",
    "        conv2 = 32\n",
    "        ct2 = nn.Conv2d(conv1,conv2,f,stride = s)\n",
    "        cb2 = nn.BatchNorm2d(conv2)\n",
    "        ca2 = nw_activation_conv\n",
    "        cl2 = [ct2,cb2,ca2,dropout_node]\n",
    "        self.convl2 = nn.Sequential(*cl2)\n",
    "        \n",
    "        # Conv 3\n",
    "        ###\n",
    "        conv3 = 64\n",
    "        ct3 = nn.Conv2d(conv2,conv3,f,stride = s)\n",
    "        cb3 = nn.BatchNorm2d(conv3)\n",
    "        ca3 = nw_activation_conv\n",
    "        cl3 = [ct3,cb3,ca3,dropout_node]\n",
    "        self.convl3 = nn.Sequential(*cl3)\n",
    "        \n",
    "        # Conv 4\n",
    "        ###\n",
    "        conv4 = 128\n",
    "        ct4 = nn.Conv2d(conv3,conv4,f,stride = s)\n",
    "        cb4 = nn.BatchNorm2d(conv4)\n",
    "        ca4 = nw_activation_conv\n",
    "        cl4 = [ct4,cb4,ca4,dropout_node]\n",
    "        self.convl4 = nn.Sequential(*cl4) \n",
    "        \n",
    "        # Conv 5\n",
    "        ###\n",
    "        conv5 = 256\n",
    "        ct5 = nn.Conv2d(conv4,conv5,f,stride = s)\n",
    "        cb5 = nn.BatchNorm2d(conv5)\n",
    "        ca5 = nw_activation_conv\n",
    "        cl5 = [ct5,cb5,ca5,dropout_node]\n",
    "        self.convl5 = nn.Sequential(*cl5) \n",
    "        \n",
    "        # Conv 6\n",
    "        ###\n",
    "        conv6 = 512\n",
    "        ct6 = nn.Conv2d(conv5,conv6,f,stride = s)\n",
    "        cb6 = nn.BatchNorm2d(conv6)\n",
    "        ca6 = nw_activation_conv\n",
    "        cl6 = [ct6,cb6,ca6,dropout_node]\n",
    "        self.convl6 = nn.Sequential(*cl6) \n",
    "        \n",
    "\n",
    "        # Pooling layer + softmax activation\n",
    "        # ----------------------------------\n",
    "        pool_dims = (2,2)\n",
    "        if latent_softmax == True:\n",
    "            avpl =  [nn.AvgPool2d(pool_dims, stride=1), nn.Softmax2d()]\n",
    "        else:\n",
    "            avpl =  [nn.AvgPool2d(pool_dims, stride=1)]\n",
    "        self.pool_net = nn.Sequential(*avpl)\n",
    "        \n",
    "      \n",
    "        # Transconv layers\n",
    "        # ----------------\n",
    "        # Showing conv up sizes - \n",
    "        # --------------------------\n",
    "        # Incoming input is 1 x 1 x C\n",
    "        # (5, 5)\n",
    "        # (11, 11)\n",
    "        # (23, 23)\n",
    "        # (47, 47)\n",
    "        # (95, 95)\n",
    "        # (191, 191)\n",
    "        \n",
    "        # Upconv layer 0\n",
    "        ###\n",
    "        up_conv0 = conv6\n",
    "        t0 = nn.ConvTranspose2d(conv6,up_conv0,pool_dims,stride = 1)\n",
    "        b0 = nn.BatchNorm2d(up_conv0)\n",
    "        a0 = nw_activation_conv\n",
    "        l0 = [t0,b0,a0,dropout_node]\n",
    "        self.upcl0 = nn.Sequential(*l0) # 2x2\n",
    "        \n",
    "        # Upconv layer 1\n",
    "        # concat layer\n",
    "        ###\n",
    "        up_conv1 = 256\n",
    "        t1 = nn.ConvTranspose2d(up_conv0 + conv6,up_conv1,f,stride = s)\n",
    "        b1 = nn.BatchNorm2d(up_conv1)\n",
    "        a1 = nw_activation_conv\n",
    "        l1 = [t1,b1,a1,dropout_node]\n",
    "        self.upcl1 = nn.Sequential(*l1) # 5x5\n",
    "        \n",
    "        # Upconv layer 2\n",
    "        # concat layer\n",
    "        ###\n",
    "        up_conv2 = 128\n",
    "        t2 = nn.ConvTranspose2d(up_conv1 + conv5,up_conv2,f,stride = s)\n",
    "        b2 = nn.BatchNorm2d(up_conv2)\n",
    "        a2 = nw_activation_conv\n",
    "        l2 = [t2,b2,a2,dropout_node]\n",
    "        self.upcl2 = nn.Sequential(*l2)\n",
    "        \n",
    "        # Upconv layer 3\n",
    "        # concat layer\n",
    "        ###\n",
    "        up_conv3 = 64\n",
    "        t3 = nn.ConvTranspose2d(up_conv2 + conv4,up_conv3,f,stride = s)\n",
    "        b3 = nn.BatchNorm2d(up_conv3)\n",
    "        a3 = nw_activation_conv\n",
    "        l3 = [t3,b3,a3,dropout_node]\n",
    "        self.upcl3 = nn.Sequential(*l3)\n",
    "        \n",
    "        # Upconv layer 4\n",
    "        # concat layer\n",
    "        ###\n",
    "        up_conv4 = 32\n",
    "        t4 = nn.ConvTranspose2d(up_conv3 + conv3,up_conv4,f,stride = s)\n",
    "        b4 = nn.BatchNorm2d(up_conv4)\n",
    "        a4 = nw_activation_conv\n",
    "        l4 = [t4,b4,a4,dropout_node]\n",
    "        self.upcl4 = nn.Sequential(*l4)\n",
    "        \n",
    "        # Upconv layer 5\n",
    "        # concat layer\n",
    "        ###\n",
    "        up_conv5 = 16\n",
    "        t5 = nn.ConvTranspose2d(up_conv4 + conv2,up_conv5,f,stride = s)\n",
    "        b5 = nn.BatchNorm2d(up_conv5)\n",
    "        a5 = nw_activation_conv\n",
    "        l5 = [t5,b5,a5,dropout_node]\n",
    "        self.upcl5 = nn.Sequential(*l5)\n",
    "    \n",
    "    \n",
    "        # Upconv layer 6\n",
    "        # concat layer - FINAL LAYER\n",
    "        ###\n",
    "        t6 = nn.ConvTranspose2d(up_conv5 + conv1,out_channels,f,stride = s)\n",
    "        a6 = nn.Sigmoid()\n",
    "        l6 = [t6,a6]\n",
    "        self.upcl6 = nn.Sequential(*l6)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Conv pass\n",
    "        # ---------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        c4_out = self.convl4(c3_out)\n",
    "        c5_out = self.convl5(c4_out)\n",
    "        c6_out = self.convl6(c5_out)\n",
    "        \n",
    "        # pooling\n",
    "        # -------\n",
    "        latent_out = self.pool_net(c6_out)\n",
    "        \n",
    "        # Transconv pass\n",
    "        # --------------\n",
    "        f1_out = self.upcl0(latent_out)\n",
    "        f2_out = self.upcl1(torch.cat((f1_out,c6_out), 1))\n",
    "        f3_out = self.upcl2(torch.cat((f2_out,c5_out), 1))\n",
    "        f4_out = self.upcl3(torch.cat((f3_out,c4_out), 1))\n",
    "        f5_out = self.upcl4(torch.cat((f4_out,c3_out), 1))\n",
    "        f6_out = self.upcl5(torch.cat((f5_out,c2_out), 1))\n",
    "        f7_out = self.upcl6(torch.cat((f6_out,c1_out), 1))\n",
    "        \n",
    "        return f7_out\n",
    "\n",
    "    \n",
    "    def latent(self, x):\n",
    "        \n",
    "        \n",
    "        # Conv pass\n",
    "        # ---------\n",
    "        c1_out = self.convl1(x)\n",
    "        c2_out = self.convl2(c1_out)\n",
    "        c3_out = self.convl3(c2_out)\n",
    "        c4_out = self.convl4(c3_out)\n",
    "        c5_out = self.convl5(c4_out)\n",
    "        c6_out = self.convl6(c5_out)\n",
    "        \n",
    "        # pooling\n",
    "        # -------\n",
    "        latent_out = self.pool_net(c6_out)\n",
    "\n",
    "        return latent_out.view(latent_out.size()[0],-1)\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END OF CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. preparing dataset - one off task"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 0. inputs to the below functions\n",
    "# ---------------------------------\n",
    "\n",
    "json_url = '/Users/venkateshmadhava/Documents/projects/vision/object_detection/bdd100k/labels/bdd100k_labels_images_val.json'\n",
    "img_folder = '/Users/venkateshmadhava/Documents/projects/vision/object_detection/bdd100k/images/100k/test_2500'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 1. building a set of classes first\n",
    "# ----------------------------------\n",
    "\n",
    "'''\n",
    "there are 10 classes of objects in this dataset with bounding box - \n",
    "['rider', 'train', 'person', 'traffic light', 'bus', 'truck', 'motor', 'bike', 'car', 'traffic sign']\n",
    "'''\n",
    "\n",
    "#final_classes = build_class_list(json_url)\n",
    "final_classes = ['rider', 'train', 'person', 'traffic light', 'bus', 'truck', 'motor', 'bike', 'car', 'traffic sign']\n",
    "final_classes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 2. building final dict for dataset resize\n",
    "# -----------------------------------------\n",
    "\n",
    "build_datasets(final_classes,json_url,img_folder,225,400)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 3. saving the datasets - source\n",
    "# -------------------------------\n",
    "\n",
    "global x_source\n",
    "master_h5_url = '/Users/venkateshmadhava/Documents/projects/vision/object_detection/bdd100k/images/100k/bdd_object_detection_test2500_source.h5'\n",
    "hf = h5py.File(master_h5_url, 'w')\n",
    "hf.create_dataset('images', data = x_source, dtype = 'uint8')\n",
    "hf.close()\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 4. saving the datasets - target\n",
    "# -------------------------------\n",
    "\n",
    "global x_target\n",
    "master_h5_url = '/Users/venkateshmadhava/Documents/projects/vision/object_detection/bdd100k/images/100k/bdd_object_detection_test2500_target.h5'\n",
    "hf = h5py.File(master_h5_url, 'w')\n",
    "hf.create_dataset('images', data = x_target, dtype = 'uint8')\n",
    "hf.close()\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 5. test reading the h5 files\n",
    "# ----------------------------\n",
    "\n",
    "master_h5_url = '/Users/venkateshmadhava/Documents/projects/vision/object_detection/bdd100k/images/100k/bdd_object_detection_test2500_source.h5'\n",
    "hfr = h5py.File(master_h5_url, 'r')\n",
    "xsrch5 = np.array(hfr.get('images'))\n",
    "\n",
    "master_h5_url = '/Users/venkateshmadhava/Documents/projects/vision/object_detection/bdd100k/images/100k/bdd_object_detection_test2500_target.h5'\n",
    "hfr = h5py.File(master_h5_url, 'r')\n",
    "xtgth5 = np.array(hfr.get('images'))\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 6. showing shapes for sanity\n",
    "# ----------------------------\n",
    "xsrch5.shape, xtgth5.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 7. sanity showing of random images\n",
    "# -----------------------------------\n",
    "randrange = list(np.random.randint(x_source.shape[0], size=(1, 5))[0,:])\n",
    "\n",
    "# looping\n",
    "##\n",
    "for j in randrange:\n",
    "\n",
    "    for i in range(len(final_classes)):\n",
    "        print(final_classes[i])\n",
    "        \n",
    "        plt.imshow(xsrch5[j])\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(xtgth5[j,:,:,i])\n",
    "        plt.show()\n",
    "        print('------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. prepaing COCO dataset - one off task"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Step 1. COCO dataset setup - setting up dicts\n",
    "# ---------------------------------------------\n",
    "\n",
    "\n",
    "# initialisations\n",
    "# ---------------\n",
    "jsonurl = '/Users/venkateshmadhava/Documents/projects/vision/object_detection/coco/annotations/instances_val2017.json'\n",
    "imgfolder = '/Users/venkateshmadhava/Documents/projects/vision/object_detection/coco/val2017'\n",
    "mode = 'super_cats'\n",
    "int_cats = ['person','furniture','vehicle','food']\n",
    "\n",
    "\n",
    "# building dicts\n",
    "# --------------\n",
    "xs,xt = build_coco_dataset_all(jsonurl,imgfolder,mode,int_cats)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Step 2. COCO dataset setup - converting dicts to datasets to save them as h5\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "new_h, new_w = 250,250\n",
    "\n",
    "x_src = create_single_dataset_from_indict(xs,new_h,new_w)\n",
    "x_tgt = create_single_dataset_from_indict(xt,new_h,new_w)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# sanity checking images\n",
    "# -----------------------\n",
    "randrange = list(np.random.randint(x_src.shape[0], size=(1, 3))[0,:])\n",
    "\n",
    "# looping and showing\n",
    "# -------------------\n",
    "for i in randrange:\n",
    "    \n",
    "    for j in range(x_tgt.shape[3]):\n",
    "        print('original - ')\n",
    "        plt.imshow(x_src[i])\n",
    "        plt.show()\n",
    "        print(str(int_cats[j]))\n",
    "        plt.imshow(x_tgt[i,:,:,j])\n",
    "        plt.show()\n",
    "        print('--------')\n",
    "    \n",
    "    print('\\n******************\\n')\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Step 3. COCO dataset setup - Save these as h5 files\n",
    "# ---------------------------------------------------\n",
    "\n",
    "save_folder = '/Users/venkateshmadhava/Documents/projects/vision/object_detection/coco/'\n",
    "\n",
    "# build h5 names\n",
    "# --------------\n",
    "cats_combined = mode + '_'\n",
    "for each in int_cats:\n",
    "    cats_combined += each + '_'\n",
    "\n",
    "# setting up names\n",
    "# ----------------\n",
    "h5_src_name = save_folder + 'val_x_src_' + cats_combined + 'dataset.h5'  \n",
    "h5_tgt_name = save_folder + 'val_x_tgt_' + cats_combined + 'dataset.h5'  \n",
    "print(h5_src_name)\n",
    "print(h5_tgt_name)\n",
    "\n",
    "# saving files - src\n",
    "# ------------------\n",
    "hf = h5py.File(h5_src_name, 'w')\n",
    "hf.create_dataset('images', data = x_src, dtype = 'uint8')\n",
    "hf.close()\n",
    "print('Done.')\n",
    "\n",
    "# saving files - tgt\n",
    "# ------------------\n",
    "hf = h5py.File(h5_tgt_name, 'w')\n",
    "hf.create_dataset('images', data = x_tgt, dtype = 'uint8')\n",
    "hf.close()\n",
    "print('Done.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. loading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 setting up model related variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SET UP CUDA OR NOT HERE + OTHER SET UPS\n",
    "##########################################\n",
    "\n",
    "dev_env = 'local' # 'gpu' or 'local'\n",
    "\n",
    "##########################################\n",
    "##########################################\n",
    "\n",
    "# Setting CUDA\n",
    "# ------------\n",
    "if dev_env == 'gpu':\n",
    "    use_cuda = True\n",
    "else:\n",
    "    use_cuda = False\n",
    "if use_cuda == True:\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "\n",
    "# SET FILE SPECIFIC NAMES HERE\n",
    "# ----------------------------\n",
    "if dev_env == 'gpu':\n",
    "    save_path = '/home/venkateshmadhava/codes/pmate2_localgpuenv/models/'\n",
    "    parent_url = '/home/venkateshmadhava/datasets/images'\n",
    "else:\n",
    "    save_path = '/Users/venkateshmadhava/Documents/pmate2/pmate2_env/models/'\n",
    "    parent_url = '/Users/venkateshmadhava/Documents/projects/vision/object_detection/coco/'\n",
    "\n",
    "    \n",
    "# Setting up final classes as well - for BDD dataset\n",
    "# --------------------------------------------------\n",
    "#final_classes = ['rider', 'train', 'person', 'traffic light', 'bus', 'truck', 'motor', 'bike', 'car', 'traffic sign']\n",
    "#print('\\n***')\n",
    "#print(final_classes)\n",
    "\n",
    "\n",
    "# displaying save path\n",
    "# --------------------\n",
    "print('***\\n')\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 loading BDD dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# reading h5 sets from google bucket\n",
    "# ----------------------------------\n",
    "blob_name = 'images/bdd_object_detection_train10k_source.h5'\n",
    "h5url = get_file_from_google_storage(blob_name)\n",
    "hfr = h5py.File(h5url, 'r')\n",
    "xtrn_src = np.array(hfr.get('images'))\n",
    "print('got training source..\\n')\n",
    "\n",
    "blob_name = 'images/bdd_object_detection_train10k_target.h5'\n",
    "h5url = get_file_from_google_storage(blob_name)\n",
    "hfr = h5py.File(h5url, 'r')\n",
    "xtrn_tgt = np.array(hfr.get('images'))\n",
    "print('got training target..\\n')\n",
    "\n",
    "blob_name = 'images/bdd_object_detection_test2500_source.h5'\n",
    "h5url = get_file_from_google_storage(blob_name)\n",
    "hfr = h5py.File(h5url, 'r')\n",
    "xtst_src = np.array(hfr.get('images'))\n",
    "print('got test source..\\n')\n",
    "\n",
    "blob_name = 'images/bdd_object_detection_test2500_target.h5'\n",
    "h5url = get_file_from_google_storage(blob_name)\n",
    "hfr = h5py.File(h5url, 'r')\n",
    "xtst_tgt = np.array(hfr.get('images'))\n",
    "print('got test target..\\n')\n",
    "\n",
    "# printing shapes for sanity\n",
    "# --------------------------\n",
    "print(xtrn_src.shape)\n",
    "print(xtrn_tgt.shape)\n",
    "print(xtst_src.shape)\n",
    "print(xtst_tgt.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# readinf h5 sets train\n",
    "# ---------------------\n",
    "master_h5_url = parent_url + '/bdd_object_detection_train10k_source.h5'\n",
    "hfr = h5py.File(master_h5_url, 'r')\n",
    "xtrn_src = np.array(hfr.get('images'))\n",
    "\n",
    "master_h5_url = parent_url + '/bdd_object_detection_train10k_target.h5'\n",
    "hfr = h5py.File(master_h5_url, 'r')\n",
    "xtrn_tgt = np.array(hfr.get('images'))\n",
    "\n",
    "\n",
    "# readinf h5 sets test set\n",
    "# ------------------------\n",
    "master_h5_url = parent_url + '/bdd_object_detection_test2500_source.h5'\n",
    "hfr = h5py.File(master_h5_url, 'r')\n",
    "xtst_src = np.array(hfr.get('images'))\n",
    "\n",
    "master_h5_url = parent_url + '/bdd_object_detection_test2500_target.h5'\n",
    "hfr = h5py.File(master_h5_url, 'r')\n",
    "xtst_tgt = np.array(hfr.get('images'))\n",
    "\n",
    "# printing shapes for sanity\n",
    "# --------------------------\n",
    "print(xtrn_src.shape)\n",
    "print(xtrn_tgt.shape)\n",
    "print(xtst_src.shape)\n",
    "print(xtst_tgt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 loading COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading COCO dataset\n",
    "# --------------------\n",
    "\n",
    "source_h5name = 'val_x_src_super_cats_person_furniture_vehicle_food_dataset.h5'\n",
    "tgt_h5name = 'val_x_tgt_super_cats_person_furniture_vehicle_food_dataset.h5'\n",
    "final_classes = ['person','furniture','vehicle','food']\n",
    "\n",
    "# reading h5 file\n",
    "# ---------------\n",
    "hfr = h5py.File(parent_url + source_h5name, 'r')\n",
    "xtrn_src_main = np.array(hfr.get('images'))\n",
    "\n",
    "hfr = h5py.File(parent_url + tgt_h5name, 'r')\n",
    "xtrn_tgt_main = np.array(hfr.get('images'))\n",
    "\n",
    "print(xtrn_src_main.shape)\n",
    "print(xtrn_tgt_main.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting set on local machine\n",
    "# ------------------------------\n",
    "\n",
    "if dev_env == 'local':\n",
    "    \n",
    "\n",
    "    xtrn_src = xtrn_src_main[0:3500]\n",
    "    xtrn_tgt = xtrn_tgt_main[0:3500]\n",
    "    xtst_src = xtrn_src_main[3500:]\n",
    "    xtst_tgt = xtrn_tgt_main[3500:]\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing images if required\n",
    "# ----------------------------\n",
    "resize_images = True\n",
    "new_h,new_w = 191,191\n",
    "\n",
    "if resize_images == True:\n",
    "    \n",
    "    xtrn_src = resize_all(xtrn_src,new_h,new_w)\n",
    "    xtrn_tgt = resize_all(xtrn_tgt,new_h,new_w)\n",
    "    \n",
    "    xtst_src = resize_all(xtst_src,new_h,new_w)\n",
    "    xtst_tgt = resize_all(xtst_tgt,new_h,new_w)\n",
    "    \n",
    "# printing shapes for sanity\n",
    "# --------------------------\n",
    "print(xtrn_src.shape)\n",
    "print(xtrn_tgt.shape)\n",
    "print(xtst_src.shape)\n",
    "print(xtst_tgt.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualising images for sanity\n",
    "# -----------------------------\n",
    "randrange = list(np.random.randint(xtst_src.shape[0], size=(1, 1))[0,:])\n",
    "\n",
    "for j in randrange:\n",
    "    \n",
    "    print('>> Showing a training image..')\n",
    "    for i in range(len(final_classes)):\n",
    "        print(final_classes[i])\n",
    "        plt.imshow(xtrn_src[j])\n",
    "        plt.show()\n",
    "        plt.imshow(xtrn_tgt[j,:,:,i])\n",
    "        plt.show()\n",
    "        print('------------')\n",
    "    \n",
    "    print('>> Showing a test image..')\n",
    "    for i in range(len(final_classes)):\n",
    "        print(final_classes[i])\n",
    "        plt.imshow(xtst_src[j])\n",
    "        plt.show()\n",
    "        plt.imshow(xtst_tgt[j,:,:,i])\n",
    "        plt.show()\n",
    "        print('------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 2. setting up & training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snippet to work out filter sizes\n",
    "# --------------------------------\n",
    "f = 3\n",
    "s = 2\n",
    "pad = 0\n",
    "layers = 6\n",
    "\n",
    "h = 191 # 255\n",
    "w = 191 # 255\n",
    "print('Showing conv down sizes - ')\n",
    "print('--------------------------')\n",
    "\n",
    "# showing out sizes after conv\n",
    "# ----------------------------\n",
    "for _ in range(layers):   \n",
    "    h,w = outsize_conv(h,w,f,s,pad)\n",
    "    print((h,w))\n",
    "    \n",
    "h = 1\n",
    "w = 1\n",
    "print('\\nShowing conv up sizes - ')\n",
    "print('--------------------------')\n",
    "\n",
    "# showing out sizes after conv\n",
    "# ----------------------------\n",
    "dims = []\n",
    "for _ in range(layers):   \n",
    "    h,w = outsize_upconv(h,w,f,s,pad)\n",
    "    dims.append((h,w))\n",
    "    print((h,w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up train data\n",
    "# -----------------\n",
    "xin_train = Variable(setup_image_tensor(xtrn_src)).float()\n",
    "xout_train = Variable(setup_image_tensor(xtrn_tgt)).float() * 255\n",
    "\n",
    "print(xin_train.size())\n",
    "print(xout_train.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 start of model setup and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using an FCN AE system\n",
    "# Training fcn_ae_6_layer_WNET to 65 expoch brings loss to 0.014\n",
    "# ----------------------\n",
    "\n",
    "try:\n",
    "    del model_ae\n",
    "    print('Old model deleted.')\n",
    "except:\n",
    "    pass\n",
    "model_ae = fcn_ae_6_layer_UNET_multiple_outchannels(3,len(final_classes),False)\n",
    "model_ae.apply(weights_init)\n",
    "model_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training the model\n",
    "# ------------------\n",
    "\n",
    "''' USE -1 AS EPOCHS TO LOAD SAVED MODEL WITHOUT TRAINING '''\n",
    "\n",
    "# model_train(xin,yin,xval,yval,load_mode,model,epochs,mbsize,loss_mode,flatten,use_cuda,save_state,path)\n",
    "\n",
    "cn_file_name = 'fcn_coco_object_detection_6_layer_UNET_multichannelout_nonsoftmax_512.tar'\n",
    "cn_save_path = save_path + cn_file_name\n",
    "print(cn_save_path)\n",
    "\n",
    "\n",
    "model_ae = model_train(xin_train,xout_train,None,None,'from saved',model_ae,-1,64,'mse',use_cuda,True,cn_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 visualising results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# random sampling\n",
    "# --------------\n",
    "randrange = list(np.random.randint(xtst_src.shape[0], size=(1, 1))[0,:])\n",
    "\n",
    "# sampling\n",
    "# --------\n",
    "nx_trn = Variable(setup_image_tensor(xtst_src[randrange])).float()\n",
    "n_output = model_ae.eval().cpu()((nx_trn/255).cpu())\n",
    "np_out = to_numpy_image(n_output.cpu().data)\n",
    "\n",
    "for i in range(np_out.shape[0]):\n",
    "    print(str(i))\n",
    "    for j in range(len(final_classes)):\n",
    "        print('Original - ')\n",
    "        plt.imshow(xtst_src[randrange][i])\n",
    "        plt.show()\n",
    "        print(final_classes[j])\n",
    "        plt.imshow(np_out[i,:,:,j])\n",
    "        plt.show()\n",
    "        print('------------------------')\n",
    "    print('#####################################################')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reading images from local folder\n",
    "# --------------------------------\n",
    "\n",
    "if dev_env == 'local':\n",
    "\n",
    "    in_folder = '/Users/venkateshmadhava/Desktop/test'\n",
    "    x_local = create_dataset_from_folder_all(in_folder,new_h,new_w)\n",
    "    x_local_trn = Variable(setup_image_tensor(x_local)).float()\n",
    "    print(x_local_trn.size())\n",
    "\n",
    "    # forward pass ops\n",
    "    # ----------------\n",
    "    n_output = model_ae.eval().cpu()((x_local_trn/255).cpu())\n",
    "    np_out = to_numpy_image(n_output.cpu().data)\n",
    "    \n",
    "    # showing results\n",
    "    # ---------------\n",
    "    for i in range(np_out.shape[0]):\n",
    "        print(str(i))\n",
    "        for j in range(len(final_classes)):\n",
    "            print('Original - ')\n",
    "            plt.imshow(x_local[i])\n",
    "            plt.show()\n",
    "            print(final_classes[j])\n",
    "            plt.imshow(np_out[i,:,:,j])\n",
    "            plt.show()\n",
    "            print('------------------------')\n",
    "        print('#####################################################')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END OF TRAINING FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jsonurl = '/Users/venkateshmadhava/Documents/projects/vision/object_detection/coco/annotations/captions_val2017.json'\n",
    "\n",
    "#with open(jsonurl) as f:\n",
    "#    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['annotations'][3651]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pmate2_env",
   "language": "python",
   "name": "pmate2_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
